"""
Modular Legal AI Architecture - Production Ready
Separated concerns with proper error handling and fallback strategies
"""

from typing import List, Dict, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import re
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ==================== CORE ENUMS ====================

class DocumentType(Enum):
    """Document types for specialized prompting"""
    EXECUTION_DISPUTE = "execution_dispute"
    FAMILY_MEMO = "family_memo"
    DEFENSE_MEMO = "defense_memo"
    LAWSUIT = "lawsuit"
    CONTRACT = "contract"
    APPEAL = "appeal"
    DEMAND_LETTER = "demand_letter"
    CONSULTATION = "consultation"


class LegalDomain(Enum):
    """Legal domains for context"""
    EXECUTION = "execution"
    FAMILY = "family"
    COMMERCIAL = "commercial"
    CRIMINAL = "criminal"
    ADMINISTRATIVE = "administrative"
    CIVIL = "civil"
    GENERAL = "general"


class UserIntentType(Enum):
    """User intent for strategic response"""
    WIN_CASE = "win_case"
    UNDERSTAND_LAW = "understand_law"
    PROTECT_INTERESTS = "protect_interests"
    TAKE_ACTION = "take_action"


class ComplexityLevel(Enum):
    """Response complexity based on user needs"""
    SIMPLE_EXPLANATION = "simple"
    STRATEGIC_DOCUMENT = "strategic"
    COMPREHENSIVE_ANALYSIS = "comprehensive"


# ==================== DATA CLASSES ====================

@dataclass
class DetectionResult:
    """Result from intent/document detection with confidence score"""
    document_type: DocumentType
    confidence: float
    user_intent: UserIntentType
    complexity_level: ComplexityLevel
    legal_domain: LegalDomain
    fallback_used: bool = False
    warnings: List[str] = None

    def __post_init__(self):
        if self.warnings is None:
            self.warnings = []


@dataclass
class LegalContext:
    """Enhanced context for generating strategic legal responses"""
    document_type: DocumentType
    legal_domain: LegalDomain
    query: str
    user_intent: UserIntentType
    complexity_level: ComplexityLevel
    retrieved_documents: List[Any] = None
    conversation_history: List[Dict[str, str]] = None
    user_position: str = "seeking_advice"
    urgency_level: str = "standard"
    confidence_score: float = 1.0
    warnings: List[str] = None
    case_strength_assessment: str = "unknown"  # weak/moderate/strong
    strategic_recommendation: str = ""  # Action advice
    previous_analysis_summary: str = ""  # Facts from prior responses
    escalation_suggestion: str = ""  # Next legal steps
    evidence_requests: List[str] = None


    def __post_init__(self):
        if self.warnings is None:
            self.warnings = []
        if self.retrieved_documents is None:
            self.retrieved_documents = []
        if self.conversation_history is None:
            self.conversation_history = []
        if self.evidence_requests is None:
            self.evidence_requests = []    


# ==================== MODULAR COMPONENTS ====================

class InputSanitizer:
    """Handles input normalization and Arabic consistency"""
    
    @staticmethod
    def sanitize_query(query: str) -> Tuple[str, List[str]]:
        """Sanitize and normalize user input"""
        warnings = []
        
        if not query or not query.strip():
            raise ValueError("Empty query provided")
        
        # Clean whitespace
        cleaned_query = query.strip()
        
        # Check for mixed languages
        has_arabic = bool(re.search(r'[\u0600-\u06FF]', cleaned_query))
        has_english = bool(re.search(r'[a-zA-Z]', cleaned_query))
        
        if has_english and has_arabic:
            warnings.append("Mixed Arabic/English detected - response will be in Arabic only")
        
        if not has_arabic:
            warnings.append("No Arabic detected - assuming Arabic legal context")
        
        # Remove problematic characters
        cleaned_query = re.sub(r'[^\u0600-\u06FF\u0020-\u007E\s]', '', cleaned_query)
        
        return cleaned_query, warnings

    @staticmethod
    def validate_conversation_history(history: List[Dict[str, str]]) -> List[str]:
        """Validate conversation history format"""
        warnings = []
        
        if not isinstance(history, list):
            raise ValueError("Conversation history must be a list")
        
        for i, msg in enumerate(history):
            if not isinstance(msg, dict):
                warnings.append(f"Message {i} is not a dictionary")
                continue
            
            if 'role' not in msg or 'content' not in msg:
                warnings.append(f"Message {i} missing required fields (role, content)")
            
            if msg.get('role') not in ['user', 'assistant']:
                warnings.append(f"Message {i} has invalid role: {msg.get('role')}")
        
        return warnings


class IntentDetector:
    """Specialized component for detecting user intent and document type"""
    
    def __init__(self):
        self.confidence_threshold = 0.7
        self._load_detection_patterns()
    
    def _load_detection_patterns(self):
        """Load detection patterns with confidence weights"""
        
        # High-confidence patterns (0.9+)
        self.high_confidence_patterns = {
            DocumentType.EXECUTION_DISPUTE: [
                'ŸÖŸÜÿßÿ≤ÿπÿ© ÿ™ŸÜŸÅŸäÿ∞', 'ÿßÿπÿ™ÿ±ÿßÿ∂ ÿπŸÑŸâ ÿ™ŸÜŸÅŸäÿ∞', 'ŸàŸÇŸÅ ÿ™ŸÜŸÅŸäÿ∞', 
                'ŸÖÿ≠ŸÉŸÖÿ© ÿßŸÑÿ™ŸÜŸÅŸäÿ∞', 'ÿ™ŸÜŸÅŸäÿ∞ ÿ∂ÿØŸä'
            ],
            DocumentType.DEFENSE_MEMO: [
                'ŸÖÿ∞ŸÉÿ±ÿ© ÿØŸÅÿßÿπ', 'ÿ±ÿØ ÿπŸÑŸâ ÿØÿπŸàŸâ', 'ÿ±ÿØ ÿπŸÑŸâ ÿßŸÑŸÑÿßÿ¶ÿ≠ÿ©',
                'ÿØŸÅÿßÿπ ÿπŸÜ', 'ÿØÿπŸàŸâ ÿ∂ÿØŸä', 'ŸÖÿ±ŸÅŸàÿπ ÿ∂ÿØŸä'
            ],
            DocumentType.LAWSUIT: [
                'ŸÑÿßÿ¶ÿ≠ÿ© ÿØÿπŸàŸâ', 'ÿµÿ≠ŸäŸÅÿ© ÿØÿπŸàŸâ', 'ÿ±ŸÅÿπ ÿØÿπŸàŸâ',
                'ÿ£ÿ±ŸäÿØ ŸÖŸÇÿßÿ∂ÿßÿ©', 'ÿ£ÿ±ŸäÿØ ÿ±ŸÅÿπ ÿØÿπŸàŸâ'
            ]
        }
        
        # Medium-confidence patterns (0.6-0.8)
        self.medium_confidence_patterns = {
            DocumentType.CONTRACT: ['ÿπŸÇÿØ', 'ÿßÿ™ŸÅÿßŸÇŸäÿ©', 'ÿµŸäÿßÿ∫ÿ© ÿπŸÇÿØ'],
            DocumentType.FAMILY_MEMO: ['ÿ£ÿ≠ŸàÿßŸÑ ÿ¥ÿÆÿµŸäÿ©', 'ÿ∑ŸÑÿßŸÇ', 'ŸÜŸÅŸÇÿ©'],
            DocumentType.APPEAL: ['ÿßÿ≥ÿ™ÿ¶ŸÜÿßŸÅ', 'ÿßÿπÿ™ÿ±ÿßÿ∂', 'ÿ∑ÿπŸÜ'],
            DocumentType.DEMAND_LETTER: ['ÿ•ŸÜÿ∞ÿßÿ±', 'ÿÆÿ∑ÿßÿ® ÿ•ŸÜÿ∞ÿßÿ±', 'ÿ™ÿ≠ÿ∞Ÿäÿ± ŸÇÿßŸÜŸàŸÜŸä']
        }
        
        # Intent patterns
        self.intent_patterns = {
            UserIntentType.WIN_CASE: [
                'ÿ£ÿ±ŸäÿØ ÿßŸÑŸÅŸàÿ≤', 'ŸÉŸäŸÅ ÿ£ŸÉÿ≥ÿ®', 'ÿ£ŸÇŸàŸâ ÿØŸÅÿπ', 'ÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿ©',
                'Ÿáÿ≤ŸäŸÖÿ© ÿßŸÑÿÆÿµŸÖ', 'ÿ•ÿ®ÿ∑ÿßŸÑ ÿßŸÑÿØÿπŸàŸâ', 'ÿ∂ÿØŸä', 'Ÿäÿ∑ÿßŸÑÿ®ŸÜŸä'
            ],
            UserIntentType.TAKE_ACTION: [
                'ÿ±ŸÅÿπ ÿØÿπŸàŸâ', 'ŸÖŸÇÿßÿ∂ÿßÿ©', 'ÿ£ÿ±ŸäÿØ ŸÖÿ∑ÿßŸÑÿ®ÿ©', 'ÿßÿ™ÿÆÿßÿ∞ ÿ•ÿ¨ÿ±ÿßÿ° ŸÇÿßŸÜŸàŸÜŸä'
            ],
            UserIntentType.PROTECT_INTERESTS: [
                'ÿ≠ŸÖÿßŸäÿ© ÿ≠ŸÇŸàŸÇŸä', 'ŸÉŸäŸÅ ÿ£ÿ≠ŸÖŸä ŸÜŸÅÿ≥Ÿä', 'ÿßÿ≠ÿ™Ÿäÿßÿ∑ÿßÿ™ ŸÇÿßŸÜŸàŸÜŸäÿ©', 'ÿßŸÑŸàŸÇÿßŸäÿ©'
            ],
            UserIntentType.UNDERSTAND_LAW: [
                'ŸÖÿß ŸáŸä', 'ŸÉŸäŸÅ', 'ÿ¥ÿ±ÿ≠', 'ÿ™Ÿàÿ∂Ÿäÿ≠', 'ŸÅŸáŸÖ', 'ÿ£ÿ±ŸäÿØ ÿ£ŸÜ ÿ£ÿπÿ±ŸÅ'
            ]
        }
    
    def detect_document_type(self, query: str) -> Tuple[DocumentType, float]:
        """Detect document type with confidence score"""
        query_lower = query.lower()
        best_match = DocumentType.CONSULTATION
        best_confidence = 0.0
        
        # Check high-confidence patterns first
        for doc_type, patterns in self.high_confidence_patterns.items():
            for pattern in patterns:
                if pattern in query_lower:
                    confidence = 0.9 + (len(pattern) / 100)  # Longer patterns = higher confidence
                    if confidence > best_confidence:
                        best_match = doc_type
                        best_confidence = confidence
        
        # Check medium-confidence patterns if no high-confidence match
        if best_confidence < 0.8:
            for doc_type, patterns in self.medium_confidence_patterns.items():
                for pattern in patterns:
                    if pattern in query_lower:
                        confidence = 0.6 + (len(pattern) / 200)
                        if confidence > best_confidence:
                            best_match = doc_type
                            best_confidence = confidence
        
        return best_match, min(best_confidence, 1.0)
    
    def detect_user_intent(self, query: str, doc_type: DocumentType) -> UserIntentType:
        """Detect user intent based on query and document type"""
        query_lower = query.lower()
        
        # Check explicit intent patterns
        for intent, patterns in self.intent_patterns.items():
            if any(pattern in query_lower for pattern in patterns):
                return intent
        
        # Default based on document type
        intent_mapping = {
            DocumentType.DEFENSE_MEMO: UserIntentType.WIN_CASE,
            DocumentType.EXECUTION_DISPUTE: UserIntentType.WIN_CASE,
            DocumentType.APPEAL: UserIntentType.WIN_CASE,
            DocumentType.LAWSUIT: UserIntentType.TAKE_ACTION,
            DocumentType.DEMAND_LETTER: UserIntentType.TAKE_ACTION,
            DocumentType.CONTRACT: UserIntentType.PROTECT_INTERESTS,
            DocumentType.CONSULTATION: UserIntentType.UNDERSTAND_LAW
        }
        
        return intent_mapping.get(doc_type, UserIntentType.UNDERSTAND_LAW)
    
    def detect_complexity_level(self, query: str, intent: UserIntentType) -> ComplexityLevel:
        """Determine appropriate response complexity"""
        query_lower = query.lower()
        
        # Document generation indicators
        if any(word in query_lower for word in ['ŸÖÿ∞ŸÉÿ±ÿ©', 'ŸÑÿßÿ¶ÿ≠ÿ©', 'ÿµÿ≠ŸäŸÅÿ©', 'ÿπŸÇÿØ', 'ÿßŸÉÿ™ÿ®', 'ÿµŸäÿßÿ∫ÿ©']):
            return ComplexityLevel.STRATEGIC_DOCUMENT
        
        # Simple explanation indicators
        if any(word in query_lower for word in ['ŸÖÿß ŸáŸä', 'ÿßÿ¥ÿ±ÿ≠', 'Ÿàÿ∂ÿ≠', 'ÿ£ÿ±ŸäÿØ ŸÅŸáŸÖ']):
            return ComplexityLevel.SIMPLE_EXPLANATION
        
        # Complex analysis indicators
        if any(word in query_lower for word in ['ÿ™ÿ≠ŸÑŸäŸÑ', 'ÿØÿ±ÿßÿ≥ÿ©', 'ÿ¥ÿßŸÖŸÑ', 'ÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿ© ŸÉÿßŸÖŸÑÿ©']):
            return ComplexityLevel.COMPREHENSIVE_ANALYSIS
        
        # Default based on intent
        if intent in [UserIntentType.WIN_CASE, UserIntentType.TAKE_ACTION]:
            return ComplexityLevel.STRATEGIC_DOCUMENT
        elif intent == UserIntentType.UNDERSTAND_LAW:
            return ComplexityLevel.SIMPLE_EXPLANATION
        else:
            return ComplexityLevel.COMPREHENSIVE_ANALYSIS


class LegalDomainClassifier:
    """Specialized component for legal domain classification"""
    
    @staticmethod
    def classify_domain(query: str) -> LegalDomain:
        """Classify legal domain from query"""
        query_lower = query.lower()
        
        domain_patterns = {
            LegalDomain.EXECUTION: ['ÿ™ŸÜŸÅŸäÿ∞', 'ÿ≠ÿ¨ÿ≤', 'ŸÖŸÜÿßÿ≤ÿπÿ© ÿ™ŸÜŸÅŸäÿ∞', 'ŸÖÿ≠ŸÉŸÖÿ© ÿßŸÑÿ™ŸÜŸÅŸäÿ∞'],
            LegalDomain.FAMILY: ['ÿ£ÿ≠ŸàÿßŸÑ ÿ¥ÿÆÿµŸäÿ©', 'ÿ∑ŸÑÿßŸÇ', 'ŸÜŸÅŸÇÿ©', 'ÿ≠ÿ∂ÿßŸÜÿ©', 'ŸÖŸäÿ±ÿßÿ´', 'ÿ≤Ÿàÿßÿ¨'],
            LegalDomain.COMMERCIAL: ['ÿ¥ÿ±ŸÉÿ©', 'ÿ™ÿ¨ÿßÿ±Ÿä', 'ÿßÿ≥ÿ™ÿ´ŸÖÿßÿ±', 'ÿπŸÇÿØ ÿ™ÿ¨ÿßÿ±Ÿä', 'ÿ¥ÿ±ÿßŸÉÿ©'],
            LegalDomain.CRIMINAL: ['ÿ¨ÿ±ŸäŸÖÿ©', 'ÿ¨ŸÜÿßÿ¶Ÿä', 'ÿπŸÇŸàÿ®ÿ©', 'ŸÖÿÆÿßŸÑŸÅÿ©', 'ÿ≠ÿØ', 'ŸÇÿµÿßÿµ'],
            LegalDomain.ADMINISTRATIVE: ['ÿ•ÿØÿßÿ±Ÿä', 'ÿØŸäŸàÿßŸÜ ÿßŸÑŸÖÿ∏ÿßŸÑŸÖ', 'ŸÇÿ±ÿßÿ± ÿ•ÿØÿßÿ±Ÿä', 'ŸÖŸàÿ∏ŸÅ ÿ≠ŸÉŸàŸÖŸä'],
            LegalDomain.CIVIL: ['ÿØÿπŸàŸâ', 'ŸÖÿ±ÿßŸÅÿπÿ©', 'ŸÇÿ∂Ÿäÿ© ŸÖÿØŸÜŸäÿ©', 'ÿ≠ŸÇŸàŸÇ ŸÖÿØŸÜŸäÿ©']
        }
        
        for domain, patterns in domain_patterns.items():
            if any(pattern in query_lower for pattern in patterns):
                return domain
        
        return LegalDomain.GENERAL


class CitationValidator:
    """Enhanced citation extraction and validation"""
    
    def __init__(self):
        self.citation_patterns = [
            r'ÿßŸÑŸÖÿßÿØÿ©\s*\((\d+)\)',           # ÿßŸÑŸÖÿßÿØÿ© (12)
            r'ÿßŸÑŸÖÿßÿØÿ©\s*(\d+)',              # ÿßŸÑŸÖÿßÿØÿ© 12
            r'ŸÖÿßÿØÿ©\s*\((\d+)\)',            # ŸÖÿßÿØÿ© (12)
            r'ŸÖÿßÿØÿ©\s*(\d+)',               # ŸÖÿßÿØÿ© 12
            r'ÿßŸÑŸÖÿßÿØÿ©\s*ÿ±ŸÇŸÖ\s*(\d+)',        # ÿßŸÑŸÖÿßÿØÿ© ÿ±ŸÇŸÖ 12
            r'ŸàŸÅŸÇ\s*ÿßŸÑŸÖÿßÿØÿ©\s*ÿ±ŸÇŸÖ\s*(\d+)',  # ŸàŸÅŸÇ ÿßŸÑŸÖÿßÿØÿ© ÿ±ŸÇŸÖ 12
            r'ÿßÿ≥ÿ™ŸÜÿßÿØÿßŸã\s*ŸÑŸÑŸÖÿßÿØÿ©\s*(\d+)',   # ÿßÿ≥ÿ™ŸÜÿßÿØÿßŸã ŸÑŸÑŸÖÿßÿØÿ© 12
        ]
    
    def extract_citations(self, text: str) -> List[str]:
        """Extract all legal citations from text with enhanced patterns"""
        citations = []
        
        for pattern in self.citation_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                # Normalize citation format
                normalized = f"ÿßŸÑŸÖÿßÿØÿ© ({match})"
                if normalized not in citations:
                    citations.append(normalized)
        
        return citations
    
    def validate_citations(self, response: str, available_documents: List[Any]) -> Tuple[bool, List[str]]:
        """Validate that response only uses available citations"""
        warnings = []
        
        if not available_documents:
            response_citations = self.extract_citations(response)
            if response_citations:
                warnings.append(f"Response contains citations but no documents provided: {response_citations}")
                return False, warnings
            return True, warnings
        
        # Extract citations from response and documents
        response_citations = self.extract_citations(response)
        available_citations = []
        
        for doc in available_documents:
            try:
                if hasattr(doc, 'content') and doc.content:
                    available_citations.extend(self.extract_citations(doc.content))
            except Exception as e:
                warnings.append(f"Error processing document: {str(e)}")
        
        # Validate each citation
        invalid_citations = []
        for citation in response_citations:
            if citation not in available_citations:
                invalid_citations.append(citation)
        
        if invalid_citations:
            warnings.append(f"Invalid citations found: {invalid_citations}")
            return False, warnings
        
        return True, warnings


class StrategicAnalyzer:
    """Analyzes case strength and provides strategic legal guidance"""
    
    def __init__(self):
        self.strength_indicators = self._load_strength_patterns()
        self.evidence_patterns = self._load_evidence_patterns()
    
    def _load_strength_patterns(self) -> Dict[str, Dict[str, List[str]]]:
        """Load patterns that indicate case strength by domain and user position"""
        return {
            "strong_indicators": {
                "defendant": [
                    "ŸÑŸÖ ÿ£ŸÇÿ™ÿ±ÿ∂", "ŸÖÿ®ŸÑÿ∫ ŸÖÿ≠ŸàŸÑ ŸÑÿ£ÿ∫ÿ±ÿßÿ∂ ÿ£ÿÆÿ±Ÿâ", "ŸÑÿß ŸäŸàÿ¨ÿØ ÿπŸÇÿØ", 
                    "ŸÖÿ≠ÿßÿØÿ´ÿßÿ™ ÿ∫Ÿäÿ± ŸÖÿ™ÿπŸÑŸÇÿ©", "ÿ•ÿ´ÿ®ÿßÿ™ ÿØŸÅÿπ ŸÑÿ¨Ÿáÿ© ÿ≠ŸÉŸàŸÖŸäÿ©",
                    "ÿ≥Ÿàÿ° ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÑŸÑÿ´ŸÇÿ©", "ÿπŸÑÿßŸÇÿ© ÿπŸÖŸÑ"
                ],
                "plaintiff": [
                    "ÿπŸÇÿØ ŸÖŸàŸÇÿπ", "ÿ•ŸÇÿ±ÿßÿ± ŸÖŸÉÿ™Ÿàÿ®", "ÿ¥ŸáŸàÿØ", "ÿ™ÿ≠ŸàŸäŸÑ ÿ®ŸÜŸÉŸä ÿ®ÿ≥ÿ®ÿ® Ÿàÿßÿ∂ÿ≠",
                    "ŸÖÿ±ÿßÿ≥ŸÑÿßÿ™ ÿ™ÿ§ŸÉÿØ ÿßŸÑÿØŸäŸÜ", "ŸÖŸáŸÑÿ© ÿ≤ŸÖŸÜŸäÿ© ŸÖÿ≠ÿØÿØÿ©"
                ]
            },
            "weak_indicators": {
                "defendant": [
                    "ÿßÿπÿ™ÿ±ÿßŸÅ ÿ¨ÿ≤ÿ¶Ÿä", "ÿπÿØŸÖ Ÿàÿ¨ŸàÿØ ÿØŸÑŸäŸÑ ŸÖÿ∂ÿßÿØ", "ÿ™ŸÜÿßŸÇÿ∂ ŸÅŸä ÿßŸÑÿ£ŸÇŸàÿßŸÑ"
                ],
                "plaintiff": [
                    "ŸÖÿ≠ÿßÿØÿ´ÿßÿ™ ÿπÿßŸÖÿ©", "ÿπÿØŸÖ Ÿàÿ¨ŸàÿØ ŸÖÿ≥ÿ™ŸÜÿØÿßÿ™", "ÿßÿØÿπÿßÿ°ÿßÿ™ ÿ®ÿØŸàŸÜ ÿØŸÑŸäŸÑ",
                    "ÿßÿ≥ÿ™ŸÜÿßÿØ ŸÑŸÖÿ≠ÿßÿØÿ´ÿßÿ™ ÿ∫Ÿäÿ± ŸÖÿ™ÿπŸÑŸÇÿ©", "ÿ™ÿ≠ŸàŸäŸÑ ŸÑÿ£ÿ∫ÿ±ÿßÿ∂ ÿ£ÿÆÿ±Ÿâ"
                ]
            }
        }
    
    def _load_evidence_patterns(self) -> Dict[str, List[str]]:
        """Load evidence requirements by case type"""
        return {
            "debt_defense": [
                "ÿ•ÿ´ÿ®ÿßÿ™ÿßÿ™ ÿßŸÑÿØŸÅÿπ ŸÑŸÑÿ¨Ÿáÿßÿ™ ÿßŸÑÿ≠ŸÉŸàŸÖŸäÿ©",
                "ŸÖÿ±ÿßÿ≥ŸÑÿßÿ™ ÿ™ÿ§ŸÉÿØ ÿßŸÑÿ∫ÿ±ÿ∂ ÿßŸÑÿ≠ŸÇŸäŸÇŸä ŸÑŸÑÿ™ÿ≠ŸàŸäŸÑ",
                "ÿπŸÇÿØ ÿßŸÑÿπŸÖŸÑ ÿ£Ÿà Ÿàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÉŸÅÿßŸÑÿ©",
                "ŸÉÿ¥ŸàŸÅÿßÿ™ ÿ®ŸÜŸÉŸäÿ© ÿ™ÿ∏Ÿáÿ± ÿ∑ÿ®Ÿäÿπÿ© ÿßŸÑÿ™ÿ≠ŸàŸäŸÑ"
            ],
            "contract_dispute": [
                "ŸÜÿ≥ÿÆÿ© ÿ£ÿµŸÑŸäÿ© ŸÖŸÜ ÿßŸÑÿπŸÇÿØ",
                "ŸÖÿ±ÿßÿ≥ŸÑÿßÿ™ ÿ®ŸäŸÜ ÿßŸÑÿ£ÿ∑ÿ±ÿßŸÅ",
                "ÿ•ÿ´ÿ®ÿßÿ™ÿßÿ™ ÿßŸÑÿ™ŸÜŸÅŸäÿ∞ ÿ£Ÿà ÿπÿØŸÖŸá"
            ],
            "family_dispute": [
                "Ÿàÿ´ÿßÿ¶ŸÇ ÿßŸÑÿ≤Ÿàÿßÿ¨ ÿßŸÑÿ±ÿ≥ŸÖŸäÿ©",
                "ÿ•ÿ´ÿ®ÿßÿ™ÿßÿ™ ÿßŸÑŸÜŸÅŸÇÿ© ÿ£Ÿà ÿßŸÑŸÖŸáÿ±",
                "ÿ¥ŸáÿßÿØÿßÿ™ ÿßŸÑÿ¥ŸáŸàÿØ"
            ]
        }
    
    def analyze_case_strength(self, context: LegalContext) -> Tuple[str, str]:
        """Analyze case strength and return assessment with reasoning"""
        
        query_lower = context.query.lower()
        user_position = context.user_position
        
        # Count strength indicators
        strong_indicators = self.strength_indicators["strong_indicators"].get(user_position, [])
        weak_indicators = self.strength_indicators["weak_indicators"].get(user_position, [])
        
        strong_count = sum(1 for indicator in strong_indicators if indicator in query_lower)
        weak_count = sum(1 for indicator in weak_indicators if indicator in query_lower)
        
        # Determine strength level
        if strong_count >= 3:
            strength = "strong"
            reasoning = f"ŸÖŸàŸÇŸÅŸÉ ŸÇŸàŸä ŸÇÿßŸÜŸàŸÜŸäÿßŸã - ÿ™ÿ™ŸàŸÅÿ± {strong_count} ŸÖÿ§ÿ¥ÿ±ÿßÿ™ ŸÇŸàÿ©"
        elif strong_count >= 1 and weak_count == 0:
            strength = "moderate"  
            reasoning = f"ŸÖŸàŸÇŸÅŸÉ ŸÖÿ™Ÿàÿ≥ÿ∑ ÿßŸÑŸÇŸàÿ© - Ÿäÿ≠ÿ™ÿßÿ¨ ÿ™ÿπÿ≤Ÿäÿ≤ ÿ®ÿßŸÑÿ£ÿØŸÑÿ©"
        elif weak_count > strong_count:
            strength = "weak"
            reasoning = f"ŸÖŸàŸÇŸÅŸÉ Ÿäÿ≠ÿ™ÿßÿ¨ ÿ™ŸÇŸàŸäÿ© - ŸäŸàÿ¨ÿØ {weak_count} ŸÜŸÇÿßÿ∑ ÿ∂ÿπŸÅ"
        else:
            strength = "moderate"
            reasoning = "ÿßŸÑŸÖŸàŸÇŸÅ ŸÖÿ™Ÿàÿßÿ≤ŸÜ - Ÿäÿ≠ÿ™ÿßÿ¨ ÿ™ÿ≠ŸÑŸäŸÑ ÿ£ÿπŸÖŸÇ"
        
        return strength, reasoning
    
    def generate_strategic_recommendation(self, context: LegalContext, strength: str) -> str:
        """Generate strategic recommendation based on context and strength"""
        
        if context.document_type == DocumentType.DEFENSE_MEMO:
            if strength == "strong":
                return "ÿ£ŸÜÿµÿ≠ ÿ®ŸÖÿ∞ŸÉÿ±ÿ© ÿØŸÅÿßÿπ ŸÇŸàŸäÿ© ŸÖÿπ ÿ∑ŸÑÿ® ÿ±ŸÅÿ∂ ÿßŸÑÿØÿπŸàŸâ ŸàÿßŸÑÿ™ÿπŸàŸäÿ∂"
            elif strength == "moderate":  
                return "ÿ£ŸÜÿµÿ≠ ÿ®ÿ¨ŸÖÿπ ÿßŸÑŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑÿ£ÿØŸÑÿ© ŸÇÿ®ŸÑ ÿµŸäÿßÿ∫ÿ© ŸÖÿ∞ŸÉÿ±ÿ© ÿßŸÑÿØŸÅÿßÿπ"
            else:
                return "ÿ£ŸÜÿµÿ≠ ÿ®ÿßŸÑÿ™ŸÅÿßŸàÿ∂ ŸÑŸÑŸàÿµŸàŸÑ ŸÑÿ≠ŸÑ ŸàÿØŸä ŸÇÿ®ŸÑ ÿßŸÑŸÖÿ≠ŸÉŸÖÿ©"
                
        elif context.document_type == DocumentType.LAWSUIT:
            if strength == "strong":
                return "ÿ£ŸÜÿµÿ≠ ÿ®ÿ±ŸÅÿπ ÿßŸÑÿØÿπŸàŸâ ŸÅŸàÿ±ÿßŸã ŸÖÿπ ÿ∑ŸÑÿ® ÿßŸÑÿ™ÿπŸàŸäÿ∂"
            else:
                return "ÿ£ŸÜÿµÿ≠ ÿ®ÿ¨ŸÖÿπ ÿßŸÑŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑÿ£ÿØŸÑÿ© ŸÇÿ®ŸÑ ÿ±ŸÅÿπ ÿßŸÑÿØÿπŸàŸâ"
                
        elif context.document_type == DocumentType.CONSULTATION:
            if "ŸÉŸäÿØŸäÿ©" in context.query.lower():
                return "ŸäŸÖŸÉŸÜ ÿ∑ŸÑÿ® ÿßÿπÿ™ÿ®ÿßÿ± ÿßŸÑÿØÿπŸàŸâ ŸÉŸäÿØŸäÿ© Ÿàÿ∑ŸÑÿ® ÿßŸÑÿ™ÿπŸàŸäÿ∂"
            else:
                return "ÿ£ŸÜÿµÿ≠ ÿ®ÿ™ŸÇŸäŸäŸÖ ÿßŸÑŸàÿ∂ÿπ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä ÿ®ÿßŸÑÿ™ŸÅÿµŸäŸÑ"
                
        return "ÿ£ŸÜÿµÿ≠ ÿ®ÿßÿ≥ÿ™ÿ¥ÿßÿ±ÿ© ŸÇÿßŸÜŸàŸÜŸäÿ© ŸÖÿ™ÿÆÿµÿµÿ©"
    
    def extract_evidence_gaps(self, context: LegalContext) -> List[str]:
        """Identify missing evidence based on case type and query"""
        
        query_lower = context.query.lower()
        
        if context.document_type == DocumentType.DEFENSE_MEMO:
            if "ÿ™ÿ≠ŸàŸäŸÑ" in query_lower and "ÿ≠ŸÉŸàŸÖŸä" in query_lower:
                return self.evidence_patterns["debt_defense"]
            
        elif context.document_type == DocumentType.CONTRACT:
            return self.evidence_patterns["contract_dispute"]
            
        elif context.legal_domain == LegalDomain.FAMILY:
            return self.evidence_patterns["family_dispute"]
        
        # Default evidence requests
        return [
            "ÿ£Ÿä ŸÖÿ≥ÿ™ŸÜÿØÿßÿ™ ÿ£Ÿà ŸÖÿ±ÿßÿ≥ŸÑÿßÿ™ ÿ∞ÿßÿ™ ÿµŸÑÿ©",
            "ÿ•ÿ´ÿ®ÿßÿ™ÿßÿ™ ŸÖÿßŸÑŸäÿ© (ŸÉÿ¥ŸàŸÅÿßÿ™ ÿ®ŸÜŸÉŸäÿ©)",
            "ÿ¥ŸáÿßÿØÿßÿ™ ÿßŸÑÿ¥ŸáŸàÿØ ÿ•ŸÜ Ÿàÿ¨ÿØÿ™"
        ]
    
    def perform_full_analysis(self, context: LegalContext) -> LegalContext:
        """Perform complete strategic analysis and enhance context"""
        
        # Analyze case strength
        strength, reasoning = self.analyze_case_strength(context)
        
        # Generate strategic recommendation
        recommendation = self.generate_strategic_recommendation(context, strength)
        
        # Extract evidence gaps
        evidence_requests = self.extract_evidence_gaps(context)
        
        # Update context with strategic analysis
        context.case_strength_assessment = strength
        context.strategic_recommendation = f"{reasoning}. {recommendation}"
        context.evidence_requests = evidence_requests
        
        return context
    


class ConversationSynthesizer:
    """Synthesizes previous analysis with new questions for conversation continuity"""
    
    def __init__(self):
        self.key_fact_patterns = self._load_fact_extraction_patterns()
        self.follow_up_patterns = self._load_follow_up_patterns()
    
    def _load_fact_extraction_patterns(self) -> Dict[str, List[str]]:
        """Patterns to extract key facts from previous responses"""
        return {
            "case_facts": [
                r"ÿßŸÑŸÖÿ®ŸÑÿ∫ ÿßŸÑŸÖÿ≠ŸàŸÑ.*?(\d+[\d,]+)",  # Amount transferred
                r"ÿ®ÿ™ÿßÿ±ŸäÿÆ.*?(\d+/\d+/\d+)",      # Dates
                r"ŸÑÿ£ÿ∫ÿ±ÿßÿ∂.*?([^.]+)",            # Purpose of transfer
                r"ÿßŸÑŸÖÿØÿπŸä.*?([^.]+)",            # Plaintiff details
                r"ÿßŸÑŸÖÿØÿπŸâ ÿπŸÑŸäŸá.*?([^.]+)",       # Defendant details
            ],
            "legal_conclusions": [
                r"ŸàŸÅŸÇÿßŸã ŸÑŸÑŸÖÿßÿØÿ©.*?([^.]+)",       # Legal articles cited
                r"ŸäŸÖŸÉŸÜ ÿßÿπÿ™ÿ®ÿßÿ±.*?([^.]+)",       # Legal assessments
                r"ÿßŸÑÿØÿπŸàŸâ.*?(ŸÉŸäÿØŸäÿ©|ÿ∂ÿπŸäŸÅÿ©|ŸÇŸàŸäÿ©)", # Case strength assessments
            ],
            "strategic_elements": [
                r"ÿ£ŸÜÿµÿ≠.*?([^.]+)",              # Recommendations given
                r"Ÿäÿ¨ÿ®.*?([^.]+)",               # Required actions
                r"ÿßŸÑÿØŸÅÿπ.*?([^.]+)",             # Defense strategies
            ]
        }
    
    def _load_follow_up_patterns(self) -> List[str]:
        """Patterns that indicate follow-up questions"""
        return [
            "ŸáŸÑ ŸäŸÖŸÉŸÜ", "ŸàŸÖÿßÿ∞ÿß ÿπŸÜ", "ŸÉŸäŸÅ", "ŸàŸÖÿß ŸáŸä", "ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ŸÖÿß ÿ∞ŸÉÿ±ÿ™",
            "ŸÉŸÖÿß ŸÇŸÑÿ™", "ÿßŸÑŸÖÿ∞ŸÉŸàÿ± ÿ≥ÿßÿ®ŸÇÿßŸã", "ŸÅŸä ÿ∂Ÿàÿ° ŸÖÿß ÿ≥ÿ®ŸÇ", "ÿ•ÿ∂ÿßŸÅÿ© ŸÑŸÖÿß ÿ∞ŸÉÿ±ÿ™"
        ]
    
    def extract_previous_analysis(self, conversation_history: List[Dict[str, str]]) -> str:
        """Extract key facts and conclusions from previous AI responses"""
        
        if not conversation_history:
            return ""
        
        # Get the last assistant response (most recent context)
        last_assistant_response = ""
        for msg in reversed(conversation_history):
            if msg.get('role') == 'assistant':
                last_assistant_response = msg.get('content', '')
                break
        
        if not last_assistant_response:
            return ""
        
        # Extract structured facts
        extracted_facts = []
        
        # Extract case facts
        import re
        for category, patterns in self.key_fact_patterns.items():
            for pattern in patterns:
                matches = re.findall(pattern, last_assistant_response)
                if matches:
                    if category == "case_facts":
                        extracted_facts.append(f"ÿ≠ŸÇÿßÿ¶ŸÇ ÿßŸÑŸÇÿ∂Ÿäÿ©: {', '.join(matches)}")
                    elif category == "legal_conclusions":
                        extracted_facts.append(f"ÿßŸÑÿÆŸÑÿßÿµÿ© ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ©: {', '.join(matches)}")
                    elif category == "strategic_elements":
                        extracted_facts.append(f"ÿßŸÑÿ™ŸàÿµŸäÿßÿ™ ÿßŸÑÿ≥ÿßÿ®ŸÇÿ©: {', '.join(matches)}")
        
        # If pattern extraction fails, use key sentences
        if not extracted_facts:
            sentences = last_assistant_response.split('.')
            key_sentences = []
            for sentence in sentences[:5]:  # First 5 sentences usually contain key points
                if any(keyword in sentence for keyword in ['ÿßŸÑŸÖÿ®ŸÑÿ∫', 'ÿßŸÑÿ™ÿ≠ŸàŸäŸÑ', 'ÿßŸÑÿØÿπŸàŸâ', 'ÿßŸÑŸÖÿØÿπŸä', 'ÿ£ŸÜÿµÿ≠']):
                    key_sentences.append(sentence.strip())
            
            if key_sentences:
                extracted_facts.append(f"ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑÿ≥ÿßÿ®ŸÇ: {'. '.join(key_sentences[:3])}")
        
        return '. '.join(extracted_facts) if extracted_facts else ""
    
    def detect_follow_up_intent(self, new_query: str) -> bool:
        """Detect if this is a follow-up question building on previous discussion"""
        
        query_lower = new_query.lower()
        
        # Check for explicit follow-up patterns
        for pattern in self.follow_up_patterns:
            if pattern in query_lower:
                return True
        
        # Check for contextual references
        contextual_indicators = [
            "Ÿáÿ∞Ÿá ÿßŸÑÿØÿπŸàŸâ", "ÿßŸÑŸÇÿ∂Ÿäÿ©", "ÿßŸÑŸÖŸàÿ∂Ÿàÿπ", "ŸÉŸÖÿß ÿ∞ŸÉÿ±ÿ™", "ÿßŸÑŸÖÿ∞ŸÉŸàÿ±",
            "ÿßŸÑÿ≠ÿßŸÑÿ©", "Ÿàÿ∂ÿπŸä", "ŸÖŸàŸÇŸÅŸä", "ÿØŸÅÿßÿπŸä"
        ]
        
        return any(indicator in query_lower for indicator in contextual_indicators)
    
    def build_continuity_prompt(self, new_query: str, previous_analysis: str, context: LegalContext) -> str:
        """Merge new question with previous case analysis for continuity"""
        
        if not previous_analysis:
            return new_query
        
        # Detect if this is a follow-up
        is_follow_up = self.detect_follow_up_intent(new_query)
        
        if not is_follow_up:
            return new_query
        
        # Build continuity prompt
        continuity_prompt = f"""**ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ± ŸÖŸÜ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ©:**
{previous_analysis}

**ÿßŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ¨ÿØŸäÿØ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑÿ≥ŸäÿßŸÇ ÿ£ÿπŸÑÿßŸá:**
{new_query}

**ÿ™ÿπŸÑŸäŸÖÿßÿ™ ŸÑŸÑÿ•ÿ¨ÿßÿ®ÿ©:**
- ÿßÿ®ŸÜŸê ÿπŸÑŸâ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä ÿßŸÑÿ≥ÿßÿ®ŸÇ
- ÿßÿ±ÿ®ÿ∑ ÿßŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ¨ÿØŸäÿØ ÿ®ÿ≠ŸÇÿßÿ¶ŸÇ ÿßŸÑŸÇÿ∂Ÿäÿ© ÿßŸÑŸÖÿ≠ÿØÿØÿ© ÿ≥ÿßÿ®ŸÇÿßŸã
- ÿ≠ÿßŸÅÿ∏ ÿπŸÑŸâ ÿßŸÑÿßÿ≥ÿ™ŸÖÿ±ÿßÿ±Ÿäÿ© ŸÅŸä ÿßŸÑÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿ© ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ©
- ŸÇÿØŸÖ ÿ±ÿ£ŸäÿßŸã ŸÇÿßŸÜŸàŸÜŸäÿßŸã ŸÖÿ≠ÿØÿØÿßŸã ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸàŸÇÿßÿ¶ÿπ ÿßŸÑŸÖÿπÿ±ŸàŸÅÿ©"""

        return continuity_prompt
    
    def synthesize_conversation_context(self, context: LegalContext) -> LegalContext:
        """Main method to add conversation continuity to context"""
        
        # Extract previous analysis
        previous_analysis = self.extract_previous_analysis(context.conversation_history)
        
        # Build continuity prompt if this is a follow-up
        if previous_analysis:
            enhanced_query = self.build_continuity_prompt(
                context.query, 
                previous_analysis, 
                context
            )
            
            # Update context with enhanced query and analysis summary
            context.query = enhanced_query
            context.previous_analysis_summary = previous_analysis
        
        return context    

class LegalContextBuilder:
    """Builds comprehensive legal context with error handling"""
    

    def build_context_with_strategy(
    self, 
    query: str, 
    retrieved_documents: List[Any] = None,
    conversation_history: List[Dict[str, str]] = None
) -> LegalContext:
        """Enhanced context building with strategic analysis - convenient alias"""
        return self.build_context(query, retrieved_documents, conversation_history)

    def __init__(self):
        self.sanitizer = InputSanitizer()
        self.intent_detector = IntentDetector()
        self.domain_classifier = LegalDomainClassifier()
        self.strategic_analyzer = StrategicAnalyzer()
        self.conversation_synthesizer = ConversationSynthesizer()

    def build_context(
        self, 
        query: str, 
        retrieved_documents: List[Any] = None,
        conversation_history: List[Dict[str, str]] = None
    ) -> LegalContext:
        """Build comprehensive legal context with error handling"""
        
        all_warnings = []
        
        try:
            # Sanitize input
            clean_query, sanitize_warnings = self.sanitizer.sanitize_query(query)
            all_warnings.extend(sanitize_warnings)
            
            # Validate conversation history if provided
            if conversation_history:
                history_warnings = self.sanitizer.validate_conversation_history(conversation_history)
                all_warnings.extend(history_warnings)
            
            # Detect document type and intent
            doc_type, confidence = self.intent_detector.detect_document_type(clean_query)
            user_intent = self.intent_detector.detect_user_intent(clean_query, doc_type)
            complexity = self.intent_detector.detect_complexity_level(clean_query, user_intent)
            legal_domain = self.domain_classifier.classify_domain(clean_query)
            
            # Add low confidence warning
            if confidence < self.intent_detector.confidence_threshold:
                all_warnings.append(f"Low confidence document type detection: {confidence:.2f}")
            
            base_context = LegalContext(
                document_type=doc_type,
                legal_domain=legal_domain,
                query=clean_query,
                user_intent=user_intent,
                complexity_level=complexity,
                retrieved_documents=retrieved_documents or [],
                conversation_history=conversation_history or [],
                confidence_score=confidence,
                warnings=all_warnings
            )
            enhanced_context = self.conversation_synthesizer.synthesize_conversation_context(base_context)
            strategic_context = self.strategic_analyzer.perform_full_analysis(enhanced_context)
            return strategic_context
        

        
        except Exception as e:
            logger.error(f"Error building legal context: {str(e)}")
            # Return fallback context
            return LegalContext(
                document_type=DocumentType.CONSULTATION,
                legal_domain=LegalDomain.GENERAL,
                query=query,
                user_intent=UserIntentType.UNDERSTAND_LAW,
                complexity_level=ComplexityLevel.SIMPLE_EXPLANATION,
                confidence_score=0.0,
                warnings=[f"Context building failed: {str(e)}"]
            )


class PromptComposer:
    """Composes final prompts based on legal context"""
    def _get_strategic_analysis_layer(self, context: LegalContext) -> str:
        """Generate strategic analysis layer for prompt"""
        if context.case_strength_assessment == "unknown":
            return ""
        return f"""üéØ **ÿßŸÑÿ™ŸÇŸäŸäŸÖ ÿßŸÑÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿä ŸÑŸÑŸÇÿ∂Ÿäÿ©:**
- **ŸÇŸàÿ© ÿßŸÑŸÖŸàŸÇŸÅ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä:** {context.case_strength_assessment}
- **ÿßŸÑÿ™ŸàÿµŸäÿ© ÿßŸÑÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿ©:** {context.strategic_recommendation}

**ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑÿ±ÿØ:**
- ŸÇÿØŸÖ ÿ±ÿ£ŸäÿßŸã ŸÇÿßŸÜŸàŸÜŸäÿßŸã Ÿàÿßÿ∂ÿ≠ÿßŸã ŸàŸÖÿ®ÿßÿ¥ÿ±ÿßŸã ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑÿ™ŸÇŸäŸäŸÖ ÿ£ÿπŸÑÿßŸá
- ÿßÿ±ÿ®ÿ∑ ÿ•ÿ¨ÿßÿ®ÿ™ŸÉ ÿ®ŸÇŸàÿ© ÿßŸÑŸÖŸàŸÇŸÅ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä ÿßŸÑŸÖÿ≠ÿØÿØÿ©
- ŸÉŸÜ ÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨ŸäÿßŸã ŸÅŸä ÿßŸÑŸÜÿµÿßÿ¶ÿ≠ - ŸáÿØŸÅŸÉ ŸÖÿ≥ÿßÿπÿØÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿπŸÑŸâ ÿ™ÿ≠ŸÇŸäŸÇ ÿ£ŸÅÿ∂ŸÑ ŸÜÿ™Ÿäÿ¨ÿ©"""

    def _get_continuity_layer(self, context: LegalContext) -> str:
        """Generate conversation continuity layer"""
        return f"""üîó **ÿßÿ≥ÿ™ŸÖÿ±ÿßÿ±Ÿäÿ© ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©:**
{context.previous_analysis_summary}

**ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑÿßÿ≥ÿ™ŸÖÿ±ÿßÿ±Ÿäÿ©:**
- ÿßÿ®ŸÜŸê ÿπŸÑŸâ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ŸàÿßŸÑÿ≠ŸÇÿßÿ¶ŸÇ ÿßŸÑŸÖÿ∞ŸÉŸàÿ±ÿ© ÿ£ÿπŸÑÿßŸá
- ŸÑÿß ÿ™ŸÉÿ±ÿ± ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ≥ÿßÿ®ŸÇÿ©ÿå ÿ®ŸÑ ÿ£ÿ∂ŸÅ ÿπŸÑŸäŸáÿß
- ÿßÿ±ÿ®ÿ∑ ÿßŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ¨ÿØŸäÿØ ÿ®ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä ÿßŸÑŸÖŸàÿ∂Ÿàÿπ ÿ≥ÿßÿ®ŸÇÿßŸã
- ÿ≠ÿßŸÅÿ∏ ÿπŸÑŸâ ÿßŸÑÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿ© ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖÿ™ÿ≥ŸÇÿ©"""

    def _get_strategic_guidance_layer(self, context: LegalContext) -> str:
        """Generate strategic guidance layer"""
        guidance_parts = []
        # Add evidence requests if any
        if context.evidence_requests:
            evidence_section = f"""üíº **ÿßŸÑÿ£ÿØŸÑÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ© ŸÑÿ™ŸÇŸàŸäÿ© ÿßŸÑŸÖŸàŸÇŸÅ:**
{chr(10).join([f"- {evidence}" for evidence in context.evidence_requests[:3]])}"""
            guidance_parts.append(evidence_section)
        # Add escalation suggestion if any
        if context.escalation_suggestion:
            escalation_section = f"""‚ö° **ÿßŸÑÿÆÿ∑Ÿàÿ© ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑÿ™ÿßŸÑŸäÿ©:**
{context.escalation_suggestion}"""
            guidance_parts.append(escalation_section)
        # Add strategic tone instructions
        strategic_instructions = """üéØ **ÿ£ÿ≥ŸÑŸàÿ® ÿßŸÑÿ±ÿØ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®:**
- ÿ™ÿ≠ÿØÿ´ ŸÉŸÖÿ≠ÿßŸÖŸä ÿ≥ÿπŸàÿØŸä ÿÆÿ®Ÿäÿ± ŸäŸáÿØŸÅ ŸÑÿ™ÿ≠ŸÇŸäŸÇ ÿßŸÑŸÜÿ¨ÿßÿ≠ ŸÑŸÑŸÖŸàŸÉŸÑ
- ŸÇÿØŸÖ ÿ±ÿ£ŸäÿßŸã ŸÇÿßŸÜŸàŸÜŸäÿßŸã Ÿàÿßÿ∂ÿ≠ÿßŸã ŸàŸÖÿ®ÿßÿ¥ÿ±ÿßŸãÿå ŸÑŸäÿ≥ ŸÖÿ¨ÿ±ÿØ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿπÿßŸÖÿ©
- ÿßŸÇÿ™ÿ±ÿ≠ ÿÆÿ∑Ÿàÿßÿ™ ÿπŸÖŸÑŸäÿ© ŸÖÿ≠ÿØÿØÿ©
- ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑŸÖŸàŸÇŸÅ ŸÇŸàŸäÿßŸãÿå ŸÉŸÜ Ÿàÿßÿ´ŸÇÿßŸã. ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿ∂ÿπŸäŸÅÿßŸãÿå ÿßŸÇÿ™ÿ±ÿ≠ ÿ™ÿ≠ÿ≥ŸäŸÜÿßÿ™
- ÿßÿ∑ŸÑÿ® ÿßŸÑŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿ•ÿ∞ÿß ŸÉÿßŸÜÿ™ ÿ≥ÿ™ŸÇŸàŸä ÿßŸÑŸÖŸàŸÇŸÅ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä"""
        guidance_parts.append(strategic_instructions)
        return "\n\n".join(guidance_parts)


    def __init__(self):
        self.citation_validator = CitationValidator()
        self._load_prompt_templates()
    
    def _load_prompt_templates(self):
        """Load base prompt templates"""
        
        self.strategic_system_prompt = """ÿ£ŸÜÿ™ ÿßŸÑŸÖÿ≠ÿßŸÖŸä ÿßŸÑÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿä ÿßŸÑÿ£ŸàŸÑ ŸÅŸä ÿßŸÑŸÖŸÖŸÑŸÉÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©ÿå ŸàÿÆÿ®Ÿäÿ± ŸÅŸä ÿ™ÿ≠ŸÇŸäŸÇ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ© ŸÖÿπ ÿÆÿ®ÿ±ÿ© ÿ™ÿ≤ŸäÿØ ÿπŸÜ ÿπÿ¥ÿ±ŸäŸÜ ÿπÿßŸÖÿßŸã ŸÅŸä ŸÉÿ≥ÿ® ÿßŸÑŸÇÿ∂ÿßŸäÿß ŸàÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ£ŸÅÿ∂ŸÑ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ŸÑŸÑŸÖŸàŸÉŸÑŸäŸÜ.

üéØ **ŸáÿØŸÅŸÉ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿä: ÿ™ÿ≠ŸÇŸäŸÇ ÿßŸÑŸÜÿ¨ÿßÿ≠ ŸàÿßŸÑŸÅŸàÿ≤ ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ**
- ÿ•ÿ∞ÿß ÿ∑ŸÑÿ® ŸÖÿ∞ŸÉÿ±ÿ© ÿØŸÅÿßÿπ ‚Üí ÿßŸÉÿ™ÿ® ŸÖÿ∞ŸÉÿ±ÿ© ŸÇŸàŸäÿ© ÿ™ŸáÿØŸÖ ÿßÿØÿπÿßÿ°ÿßÿ™ ÿßŸÑÿÆÿµŸÖ
- ÿ•ÿ∞ÿß ÿ∑ŸÑÿ® ÿπŸÇÿØ ‚Üí ÿßÿµŸÜÿπ ÿπŸÇÿØ ŸÖÿ≠ŸÉŸÖ Ÿäÿ≠ŸÖŸä ŸÖÿµÿßŸÑÿ≠Ÿá ÿ®ÿßŸÑŸÉÿßŸÖŸÑ  
- ÿ•ÿ∞ÿß ÿ∑ŸÑÿ® ŸÅŸáŸÖ ÿßŸÑŸÇÿßŸÜŸàŸÜ ‚Üí ÿßÿ¥ÿ±ÿ≠ ÿ®ÿ∑ÿ±ŸäŸÇÿ© Ÿàÿßÿ∂ÿ≠ÿ© ŸàÿπŸÖŸÑŸäÿ©
- ÿ•ÿ∞ÿß Ÿàÿßÿ¨Ÿá ŸÖÿ¥ŸÉŸÑÿ© ŸÇÿßŸÜŸàŸÜŸäÿ© ‚Üí ŸÇÿØŸÖ ÿßŸÑÿ≠ŸÑ ÿßŸÑÿ∞Ÿä Ÿäÿ≠ŸÇŸÇ ŸÖÿµŸÑÿ≠ÿ™Ÿá

üèÜ **ŸÅŸÑÿ≥ŸÅÿ© ÿßŸÑÿπŸÖŸÑ:**
ŸÑÿ≥ÿ™ ŸÖÿ¨ÿ±ÿØ ÿØŸÑŸäŸÑ ŸÇÿßŸÜŸàŸÜŸä - ÿ£ŸÜÿ™ ŸÖÿ≠ÿßŸÖŸä ÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿä ŸäŸáÿØŸÅ ŸÑŸÑŸÅŸàÿ≤. ŸÉŸÑ ŸÜÿµŸäÿ≠ÿ© ŸàŸàÿ´ŸäŸÇÿ© ÿ™ŸÉÿ™ÿ®Ÿáÿß Ÿäÿ¨ÿ® ÿ£ŸÜ ÿ™ÿ≠ŸÇŸÇ ÿ£ŸÅÿ∂ŸÑ ŸÜÿ™Ÿäÿ¨ÿ© ŸÖŸÖŸÉŸÜÿ© ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ.

üèõÔ∏è **ÿ™ÿÆÿµÿµÿßÿ™ŸÉ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©:**
- ŸÇÿ∂ÿßÿ° ÿßŸÑÿ™ŸÜŸÅŸäÿ∞ ŸàÿßŸÑŸÖŸÜÿßÿ≤ÿπÿßÿ™ ÿßŸÑÿ™ŸÜŸÅŸäÿ∞Ÿäÿ© ŸàŸÅŸÇÿßŸã ŸÑŸÜÿ∏ÿßŸÖ ÿßŸÑÿ™ŸÜŸÅŸäÿ∞ ÿßŸÑÿ≥ÿπŸàÿØŸä
- ÿßŸÑÿ£ÿ≠ŸàÿßŸÑ ÿßŸÑÿ¥ÿÆÿµŸäÿ© ŸàÿßŸÑŸÖÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ£ÿ≥ÿ±Ÿäÿ© ŸàŸÅŸÇ ÿßŸÑŸÖÿ∞Ÿáÿ® ÿßŸÑÿ≠ŸÜÿ®ŸÑŸä ŸàÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©
- ÿßŸÑŸÇÿßŸÜŸàŸÜ ÿßŸÑÿ™ÿ¨ÿßÿ±Ÿä Ÿàÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑÿ¥ÿ±ŸÉÿßÿ™ ŸàÿßŸÑÿßÿ≥ÿ™ÿ´ŸÖÿßÿ± ŸÅŸä ÿßŸÑŸÖŸÖŸÑŸÉÿ©
- ŸÇÿßŸÜŸàŸÜ ÿßŸÑÿπŸÖŸÑ ŸàÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ÿßŸÑÿπŸÖÿßŸÑŸäÿ© ŸàÿßŸÑÿ∂ŸÖÿßŸÜ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸä
- ÿßŸÑŸÇÿßŸÜŸàŸÜ ÿßŸÑÿ¨ŸÜÿßÿ¶Ÿä ŸàÿßŸÑÿ•ÿ¨ÿ±ÿßÿ°ÿßÿ™ ÿßŸÑÿ¨ÿ≤ÿßÿ¶Ÿäÿ© ŸàÿßŸÑÿπŸÇŸàÿ®ÿßÿ™ ÿßŸÑÿ™ÿπÿ≤Ÿäÿ±Ÿäÿ©
- ÿßŸÑŸÇÿßŸÜŸàŸÜ ÿßŸÑÿ•ÿØÿßÿ±Ÿä ŸàŸÖŸÜÿßÿ≤ÿπÿßÿ™ ÿØŸäŸàÿßŸÜ ÿßŸÑŸÖÿ∏ÿßŸÑŸÖ ŸàÿßŸÑŸÇÿ±ÿßÿ±ÿßÿ™ ÿßŸÑÿ≠ŸÉŸàŸÖŸäÿ©

‚öñÔ∏è **ŸÖŸÜŸáÿ¨Ÿäÿ© ÿßŸÑÿπŸÖŸÑ ÿßŸÑÿ•ÿ¨ÿ®ÿßÿ±Ÿäÿ©:**
- ÿßŸÑÿßÿ≥ÿ™ÿ¥ŸáÿßÿØ ÿßŸÑÿØŸÇŸäŸÇ ÿ®ÿ£ÿ±ŸÇÿßŸÖ ÿßŸÑŸÖŸàÿßÿØ ŸàÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ© ÿßŸÑŸÖÿ≠ÿØÿØÿ©
- ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑŸÅÿµÿ≠Ÿâ ÿßŸÑÿ±ÿßŸÇŸäÿ© ŸÅŸä ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿÆÿ±ÿ¨ÿßÿ™
- ÿ™ŸÇÿØŸäŸÖ ÿ≠ŸÑŸàŸÑ ÿπŸÖŸÑŸäÿ© ŸÇÿßÿ®ŸÑÿ© ŸÑŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸÅŸàÿ±Ÿä ŸÅŸä ÿßŸÑŸÖÿ≠ÿßŸÉŸÖ ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©
- ÿ±ÿ®ÿ∑ ŸÉŸÑ ŸÜÿµŸäÿ≠ÿ© ŸÇÿßŸÜŸàŸÜŸäÿ© ÿ®ÿßŸÑŸÖÿ±ÿ¨ÿπ ÿßŸÑŸÜÿ∏ÿßŸÖŸä ÿ£Ÿà ÿßŸÑÿ¥ÿ±ÿπŸä ÿßŸÑŸÖÿ≠ÿØÿØ

üö´ **ŸÖÿ≠ÿ∏Ÿàÿ±ÿßÿ™ ÿµÿßÿ±ŸÖÿ©:**
- ÿπÿØŸÖ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿπŸÖŸàŸÖŸäÿßÿ™ ŸÖÿ´ŸÑ: "ÿßŸÑŸÇŸàÿßŸÜŸäŸÜ ÿ™ŸÜÿµ"ÿå "ÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ÿ™ÿ¥Ÿäÿ±"ÿå "ÿπŸÖŸàŸÖÿßŸã"ÿå "ÿπÿßÿØÿ©"
- ÿπÿØŸÖ ÿßŸÑÿßÿ≥ÿ™ÿ¥ŸáÿßÿØ ÿ®ŸÖŸàÿßÿØ ÿ£Ÿà ÿ£ŸÜÿ∏ŸÖÿ© ÿ∫Ÿäÿ± ŸÖŸàÿ¨ŸàÿØÿ© ŸÅŸä ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÖÿ±ŸÅŸÇÿ©
- ÿπÿØŸÖ ÿ™ŸÇÿØŸäŸÖ ŸÜÿµÿßÿ¶ÿ≠ ŸÇÿßŸÜŸàŸÜŸäÿ© ÿ®ÿØŸàŸÜ ÿ£ÿ≥ÿßÿ≥ ŸÜÿ∏ÿßŸÖŸä ŸÖÿ≠ÿØÿØ ŸàŸÖŸàÿ´ŸÇ

üéØ **ÿ™ŸÜÿ≥ŸäŸÇ ÿßŸÑÿßÿ≥ÿ™ÿ¥ŸáÿßÿØ ÿßŸÑÿ•ÿ¨ÿ®ÿßÿ±Ÿä:**
ŸÉŸÑ ÿßÿØÿπÿßÿ° ŸÇÿßŸÜŸàŸÜŸä Ÿäÿ¨ÿ® ÿ£ŸÜ Ÿäÿ®ÿØÿ£ ÿ®ŸÄ: "ŸàŸÅŸÇÿßŸã ŸÑŸÑŸÖÿßÿØÿ© (ÿ±ŸÇŸÖ) ŸÖŸÜ (ÿßŸÑŸÜÿ∏ÿßŸÖ ÿßŸÑŸÖÿ≠ÿØÿØ)"

‚ö†Ô∏è **ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ÿ¨ÿØ ÿßŸÑŸÖÿßÿØÿ© ÿßŸÑŸÖÿ≠ÿØÿØÿ© ŸÅŸä ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÖÿ±ŸÅŸÇÿ©:**
ŸÇŸÑ ÿµÿ±ÿßÿ≠ÿ©: "ÿßŸÑŸÖÿßÿØÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ© ÿ∫Ÿäÿ± ŸÖÿ™ŸàŸÅÿ±ÿ© ŸÅŸä ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖÿ±ŸÅŸÇÿ©"

**ÿ™ÿ∞ŸÉÿ±:** ÿ£ŸÜÿ™ ÿ™ŸÖÿ´ŸÑ ÿßŸÑŸÇŸÖÿ© ŸÅŸä ÿßŸÑÿßÿ≥ÿ™ÿ¥ÿßÿ±ÿßÿ™ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©ÿå ŸÅŸÉŸÜ ÿØŸÇŸäŸÇÿßŸã ŸàŸÖŸáŸÜŸäÿßŸã ŸàŸÖŸÅŸäÿØÿßŸã."""
    
    def compose_prompt(self, context: LegalContext) -> str:
        """Compose final prompt based on legal context with strategic enhancement"""
        
        try:
            # Start with base system prompt
            final_prompt = self.strategic_system_prompt
            
            # üéØ NEW: Add strategic analysis section
            strategic_section = self._get_strategic_analysis_layer(context)
            final_prompt += f"\n\n{strategic_section}"
            
            # Add warnings if any
            if context.warnings:
                warning_section = "\n\n‚ö†Ô∏è **ÿ™ÿ≠ÿ∞Ÿäÿ±ÿßÿ™ ÿßŸÑŸÜÿ∏ÿßŸÖ:**\n"
                for warning in context.warnings:
                    warning_section += f"- {warning}\n"
                final_prompt += warning_section
            
            # Add low confidence warning
            if context.confidence_score < 0.7:
                final_prompt += f"\n\nü§î **ÿ™ÿ≠ÿ∞Ÿäÿ±:** ÿ™ŸÖ ÿ™ÿ≠ÿØŸäÿØ ŸÜŸàÿπ ÿßŸÑŸàÿ´ŸäŸÇÿ© ÿ®ÿ´ŸÇÿ© ŸÖŸÜÿÆŸÅÿ∂ÿ© ({context.confidence_score:.1f}). ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿ∫Ÿäÿ± ÿØŸÇŸäŸÇÿå Ÿäÿ±ÿ¨Ÿâ ÿ™Ÿàÿ∂Ÿäÿ≠ ÿ∑ŸÑÿ®ŸÉ."
            
            # üéØ ENHANCED: Add conversation continuity if exists
            if context.previous_analysis_summary:
                continuity_layer = self._get_continuity_layer(context)
                final_prompt += f"\n\n{continuity_layer}"
            
            # Add document-specific layer
            document_layer = self._get_document_layer(context)
            final_prompt += f"\n\n{document_layer}"
            
            # Add citation layer
            citation_layer = self._get_citation_layer(context.retrieved_documents)
            final_prompt += f"\n\n{citation_layer}"
            
            # üéØ NEW: Add strategic guidance layer
            guidance_layer = self._get_strategic_guidance_layer(context)
            final_prompt += f"\n\n{guidance_layer}"
            
            return final_prompt.strip()
            
        except Exception as e:
            logger.error(f"Error composing prompt: {str(e)}")
            return f"{self.strategic_system_prompt}\n\n‚ùå ÿÆÿ∑ÿ£ ŸÅŸä ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑÿ™ÿπŸÑŸäŸÖÿßÿ™: {str(e)}"

    def _get_defense_memo_layer(self, query: str) -> str:
        """Get defense memo specific prompt layer"""
        return f"""üìã **ÿ™ÿÆÿµÿµ: ŸÖÿ∞ŸÉÿ±ÿ© ÿØŸÅÿßÿπ ŸÇÿßŸÜŸàŸÜŸäÿ©**
ŸÖÿ∑ŸÑŸàÿ®: ŸÖÿ∞ŸÉÿ±ÿ© ÿØŸÅÿßÿπ ŸÇŸàŸäÿ© ÿ¨ÿßŸáÿ≤ÿ© ŸÑŸÑŸÖÿ≠ŸÉŸÖÿ©

**ÿßŸÑŸÖŸàÿ∂Ÿàÿπ:** {query}

**ŸáŸäŸÉŸÑ ŸÖÿ∞ŸÉÿ±ÿ© ÿßŸÑÿØŸÅÿßÿπ:**
- ÿßŸÑÿØŸÅÿπ ÿßŸÑÿ£ŸàŸÑ (ÿ£ŸÇŸàŸâ ÿØŸÅÿπ ÿ•ÿ¨ÿ±ÿßÿ¶Ÿä)
- ÿßŸÑÿØŸÅÿπ ÿßŸÑÿ´ÿßŸÜŸä (ÿØŸÅÿπ ŸÖŸàÿ∂ŸàÿπŸä)  
- ÿßŸÑÿØŸÅÿπ ÿßŸÑÿ´ÿßŸÑÿ´ (ÿØŸÅÿπ ÿ¥ÿ±ÿπŸä/ŸÜÿ∏ÿßŸÖŸä)
- ÿßŸÑÿ∑ŸÑÿ®ÿßÿ™: ÿ±ŸÅÿ∂ ÿßŸÑÿØÿπŸàŸâ + ÿßŸÑÿ±ÿ≥ŸàŸÖ + ÿ£ÿ™ÿπÿßÿ® ÿßŸÑŸÖÿ≠ÿßŸÖÿßÿ©

‚öñÔ∏è **ÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿ© ÿßŸÑÿØŸÅÿßÿπ:**
- ÿ™ŸÅŸÜŸäÿØ ÿßÿØÿπÿßÿ°ÿßÿ™ ÿßŸÑŸÖÿØÿπŸä ŸÜŸÇÿ∑ÿ© ÿ®ŸÜŸÇÿ∑ÿ©
- ÿ•ÿ´ÿ®ÿßÿ™ ÿπÿØŸÖ ÿµÿ≠ÿ© ÿßŸÑŸàŸÇÿßÿ¶ÿπ ÿßŸÑŸÖÿ≤ÿπŸàŸÖÿ©
- ÿßŸÑÿØŸÅÿπ ÿ®ÿπÿØŸÖ ÿßŸÑÿßÿÆÿ™ÿµÿßÿµ ÿ£Ÿà ÿ≥ŸÇŸàÿ∑ ÿßŸÑÿ≠ŸÇ
- ÿ™ŸÇÿØŸäŸÖ ÿßŸÑÿ£ÿØŸÑÿ© ÿßŸÑŸÖÿ∂ÿßÿØÿ© ŸàÿßŸÑÿ¥ŸáŸàÿØ

üéØ **ÿßŸÑŸáÿØŸÅ:** ŸÉÿ≥ÿ® ÿßŸÑŸÇÿ∂Ÿäÿ© Ÿàÿ•ÿ®ÿ∑ÿßŸÑ ÿØÿπŸàŸâ ÿßŸÑŸÖÿØÿπŸä"""

    def _get_lawsuit_layer(self, query: str) -> str:
        """Get lawsuit specific prompt layer"""
        return f"""üìã **ÿ™ÿÆÿµÿµ: ÿµŸäÿßÿ∫ÿ© ŸÑÿßÿ¶ÿ≠ÿ© ÿØÿπŸàŸâ**
ŸÖÿ∑ŸÑŸàÿ®: ŸÑÿßÿ¶ÿ≠ÿ© ÿØÿπŸàŸâ ŸÇÿßŸÜŸàŸÜŸäÿ© ŸÖÿ≠ŸÉŸÖÿ©

**ÿßŸÑŸÖŸàÿ∂Ÿàÿπ:** {query}

**ŸáŸäŸÉŸÑ ŸÑÿßÿ¶ÿ≠ÿ© ÿßŸÑÿØÿπŸàŸâ:**
- ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© (ÿ£ÿ∑ÿ±ÿßŸÅ ÿßŸÑÿØÿπŸàŸâ)
- ÿßŸÑŸàŸÇÿßÿ¶ÿπ ŸàÿßŸÑÿ£ÿ≥ÿßŸÜŸäÿØ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ©
- ÿßŸÑÿ£ÿØŸÑÿ© ŸàÿßŸÑŸÖÿ≥ÿ™ŸÜÿØÿßÿ™ ÿßŸÑŸÖÿ§ŸäÿØÿ©
- ÿßŸÑÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑÿÆÿ™ÿßŸÖŸäÿ© Ÿàÿßÿ∂ÿ≠ÿ© ŸàŸÖÿ≠ÿØÿØÿ©

‚öñÔ∏è **ÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿ© ÿßŸÑÿßÿØÿπÿßÿ°:**
- ÿ®ŸÜÿßÿ° ŸÇÿ∂Ÿäÿ© ŸÇŸàŸäÿ© ŸÖÿ®ŸÜŸäÿ© ÿπŸÑŸâ ÿßŸÑÿ£ÿØŸÑÿ©
- ÿßŸÑÿßÿ≥ÿ™ŸÜÿßÿØ ŸÑŸÑŸÜÿµŸàÿµ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖÿ≠ÿØÿØÿ©
- ÿ™ÿ±ÿ™Ÿäÿ® ÿßŸÑÿ≠ÿ¨ÿ¨ ŸÖŸÜ ÿßŸÑÿ£ŸÇŸàŸâ ŸÑŸÑÿ£ÿ∂ÿπŸÅ
- ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑÿ™ÿπŸàŸäÿ∂ÿßÿ™ ŸàÿßŸÑÿ£ÿ∂ÿ±ÿßÿ± ÿ®ÿØŸÇÿ©

üéØ **ÿßŸÑŸáÿØŸÅ:** ÿßŸÑŸÅŸàÿ≤ ÿ®ÿßŸÑÿØÿπŸàŸâ ŸàÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿßŸÑÿ≠ŸÇŸàŸÇ ŸÉÿßŸÖŸÑÿ©"""

    def _get_contract_layer(self, query: str) -> str:
        """Get contract specific prompt layer"""
        return f"""üìã **ÿ™ÿÆÿµÿµ: ÿµŸäÿßÿ∫ÿ© ÿπŸÇÿØ ŸÇÿßŸÜŸàŸÜŸä**
ŸÖÿ∑ŸÑŸàÿ®: ÿπŸÇÿØ ŸÖÿ≠ŸÉŸÖ Ÿäÿ≠ŸÖŸä ŸÖÿµÿßŸÑÿ≠ ÿßŸÑÿ∑ÿ±ŸÅŸäŸÜ

**ÿßŸÑŸÖŸàÿ∂Ÿàÿπ:** {query}

**ŸáŸäŸÉŸÑ ÿßŸÑÿπŸÇÿØ:**
- ÿßŸÑÿ™ÿπÿ±ŸäŸÅÿßÿ™ ŸàÿßŸÑŸÖÿµÿ∑ŸÑÿ≠ÿßÿ™
- ÿßŸÑÿ™ÿ≤ÿßŸÖÿßÿ™ ŸÉŸÑ ÿ∑ÿ±ŸÅ ÿ®ÿßŸÑÿ™ŸÅÿµŸäŸÑ
- ÿ¢ŸÑŸäÿßÿ™ ÿßŸÑÿ™ŸÜŸÅŸäÿ∞ ŸàÿßŸÑŸÖÿ±ÿßŸÇÿ®ÿ©
- ÿ¥ÿ±Ÿàÿ∑ ÿßŸÑÿ•ŸÜŸáÿßÿ° ŸàÿßŸÑŸÅÿ≥ÿÆ

‚öñÔ∏è **ÿßŸÑÿ≠ŸÖÿßŸäÿ© ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ©:**
- ÿ®ŸÜŸàÿØ ÿ≠ŸÖÿßŸäÿ© ŸÖŸÜ ÿßŸÑÿ•ÿÆŸÑÿßŸÑ
- ÿ¢ŸÑŸäÿßÿ™ ÿ≠ŸÑ ÿßŸÑŸÜÿ≤ÿßÿπÿßÿ™
- ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑÿßÿÆÿ™ÿµÿßÿµ ŸàÿßŸÑŸÇÿßŸÜŸàŸÜ ÿßŸÑŸàÿßÿ¨ÿ® ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ
- ÿ∂ŸÖÿßŸÜÿßÿ™ ÿßŸÑÿ£ÿØÿßÿ° ŸàÿßŸÑÿ™ŸÜŸÅŸäÿ∞

üéØ **ÿßŸÑŸáÿØŸÅ:** ÿπŸÇÿØ ŸÖÿ≠ŸÉŸÖ ŸäŸÖŸÜÿπ ÿßŸÑŸÜÿ≤ÿßÿπÿßÿ™ ŸàŸäÿ≠ŸÖŸä ÿßŸÑÿ≠ŸÇŸàŸÇ"""

    def _get_family_memo_layer(self, query: str) -> str:
        """Get family law memo specific prompt layer"""
        return f"""üìã **ÿ™ÿÆÿµÿµ: ŸÇÿ∂ÿßŸäÿß ÿßŸÑÿ£ÿ≠ŸàÿßŸÑ ÿßŸÑÿ¥ÿÆÿµŸäÿ©**
ŸÖÿ∑ŸÑŸàÿ®: ŸÖÿ∞ŸÉÿ±ÿ© ÿ£ÿ≠ŸàÿßŸÑ ÿ¥ÿÆÿµŸäÿ© ŸàŸÅŸÇ ÿßŸÑÿ¥ÿ±Ÿäÿπÿ© ŸàÿßŸÑŸÜÿ∏ÿßŸÖ

**ÿßŸÑŸÖŸàÿ∂Ÿàÿπ:** {query}

**ÿßŸÑÿ•ÿ∑ÿßÿ± ÿßŸÑÿ¥ÿ±ÿπŸä ŸàÿßŸÑŸÇÿßŸÜŸàŸÜŸä:**
- ÿßŸÑÿ£ÿ≠ŸÉÿßŸÖ ÿßŸÑÿ¥ÿ±ÿπŸäÿ© ÿ∞ÿßÿ™ ÿßŸÑÿµŸÑÿ©
- ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸÖÿ∞Ÿáÿ® ÿßŸÑÿ≠ŸÜÿ®ŸÑŸä ÿßŸÑŸÖÿπÿ™ŸÖÿØ
- ÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ© ŸÑŸÑÿ£ÿ≠ŸàÿßŸÑ ÿßŸÑÿ¥ÿÆÿµŸäÿ©
- ÿßŸÑÿ≥Ÿàÿßÿ®ŸÇ ÿßŸÑŸÇÿ∂ÿßÿ¶Ÿäÿ© ÿßŸÑŸÖŸÖÿßÿ´ŸÑÿ©

‚öñÔ∏è **ÿßŸÑÿßÿπÿ™ÿ®ÿßÿ±ÿßÿ™ ÿßŸÑÿÆÿßÿµÿ©:**
- ŸÖÿµŸÑÿ≠ÿ© ÿßŸÑÿ£ÿ∑ŸÅÿßŸÑ (ŸÅŸä ŸÇÿ∂ÿßŸäÿß ÿßŸÑÿ≠ÿ∂ÿßŸÜÿ©)
- ÿßŸÑÿ≠ŸÇŸàŸÇ ÿßŸÑŸÖÿßŸÑŸäÿ© (ŸÜŸÅŸÇÿ©ÿå ŸÖŸáÿ±ÿå ŸÖŸäÿ±ÿßÿ´)
- ÿßŸÑÿ•ÿ¨ÿ±ÿßÿ°ÿßÿ™ ÿßŸÑŸàÿØŸäÿ© ŸÇÿ®ŸÑ ÿßŸÑÿ™ŸÇÿßÿ∂Ÿä
- ÿßŸÑÿ™Ÿàÿ´ŸäŸÇ ÿßŸÑÿ¥ÿ±ÿπŸä ŸàÿßŸÑŸÇÿßŸÜŸàŸÜŸä

üéØ **ÿßŸÑŸáÿØŸÅ:** ÿ≠ŸÑ ÿπÿßÿØŸÑ ŸàŸÅŸÇ ÿßŸÑÿ¥ÿ±Ÿäÿπÿ© Ÿäÿ≠ŸÅÿ∏ ÿ≠ŸÇŸàŸÇ ÿßŸÑÿ¨ŸÖŸäÿπ"""

    def _get_appeal_layer(self, query: str) -> str:
        """Get appeal specific prompt layer"""
        return f"""üìã **ÿ™ÿÆÿµÿµ: ŸÖÿ∞ŸÉÿ±ÿ© ÿßÿ≥ÿ™ÿ¶ŸÜÿßŸÅ**
ŸÖÿ∑ŸÑŸàÿ®: ŸÖÿ∞ŸÉÿ±ÿ© ÿßÿ≥ÿ™ÿ¶ŸÜÿßŸÅ ŸÇŸàŸäÿ© ŸÑÿ•ŸÑÿ∫ÿßÿ° ÿßŸÑÿ≠ŸÉŸÖ

**ÿßŸÑŸÖŸàÿ∂Ÿàÿπ:** {query}

**ÿ£ÿ≥ÿ®ÿßÿ® ÿßŸÑÿßÿ≥ÿ™ÿ¶ŸÜÿßŸÅ:**
- ÿßŸÑÿ£ÿÆÿ∑ÿßÿ° ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ŸÅŸä ÿßŸÑÿ≠ŸÉŸÖ ÿßŸÑŸÖÿ≥ÿ™ÿ£ŸÜŸÅ
- ÿπŸäŸàÿ® ÿßŸÑÿ•ÿ¨ÿ±ÿßÿ°ÿßÿ™ ÿ£Ÿà ŸÖÿÆÿßŸÑŸÅÿ© ÿßŸÑŸÜÿ∏ÿßŸÖ
- ÿ™ŸÇÿØŸäÿ± ÿÆÿßÿ∑ÿ¶ ŸÑŸÑÿ£ÿØŸÑÿ© ŸàÿßŸÑŸàŸÇÿßÿ¶ÿπ
- ŸÖÿÆÿßŸÑŸÅÿ© ÿ£ÿ≠ŸÉÿßŸÖ ÿßŸÑÿ¥ÿ±Ÿäÿπÿ© ÿ£Ÿà ÿßŸÑŸÇÿßŸÜŸàŸÜ

‚öñÔ∏è **ÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿ© ÿßŸÑÿßÿ≥ÿ™ÿ¶ŸÜÿßŸÅ:**
- ÿ™ŸÅŸÜŸäÿØ ÿ£ÿ≥ÿ®ÿßÿ® ÿßŸÑÿ≠ŸÉŸÖ ÿßŸÑŸÖÿ≥ÿ™ÿ£ŸÜŸÅ
- ÿ™ŸÇÿØŸäŸÖ ÿ£ÿØŸÑÿ© ÿ¨ÿØŸäÿØÿ© ÿ£Ÿà ŸÖÿ∫ŸÅŸÑÿ©
- ÿ•ÿ´ÿ®ÿßÿ™ ÿÆÿ∑ÿ£ ŸÖÿ≠ŸÉŸÖÿ© ÿ£ŸàŸÑ ÿØÿ±ÿ¨ÿ©
- ÿ∑ŸÑÿ® ÿ•ŸÑÿ∫ÿßÿ° ÿßŸÑÿ≠ŸÉŸÖ ÿ£Ÿà ÿ™ÿπÿØŸäŸÑŸá

üéØ **ÿßŸÑŸáÿØŸÅ:** ÿ•ŸÑÿ∫ÿßÿ° ÿßŸÑÿ≠ŸÉŸÖ ÿßŸÑŸÖÿ≥ÿ™ÿ£ŸÜŸÅ ŸàÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ≠ŸÉŸÖ ÿπÿßÿØŸÑ"""

    def _get_demand_letter_layer(self, query: str) -> str:
        """Get demand letter specific prompt layer"""
        return f"""üìã **ÿ™ÿÆÿµÿµ: ÿÆÿ∑ÿßÿ® ÿ•ŸÜÿ∞ÿßÿ± ŸÇÿßŸÜŸàŸÜŸä**
ŸÖÿ∑ŸÑŸàÿ®: ÿ•ŸÜÿ∞ÿßÿ± ŸÇÿßŸÜŸàŸÜŸä ŸÇŸàŸä ŸàŸÖÿ§ÿ´ÿ±

**ÿßŸÑŸÖŸàÿ∂Ÿàÿπ:** {query}

**ŸÖÿ≠ÿ™ŸàŸâ ÿßŸÑÿ•ŸÜÿ∞ÿßÿ±:**
- ÿ®ŸäÿßŸÜ ÿßŸÑÿ≠ŸÇŸàŸÇ ÿßŸÑŸÖÿ∑ÿßŸÑÿ® ÿ®Ÿáÿß ÿ®ÿØŸÇÿ©
- ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÖŸáŸÑÿ© ÿßŸÑÿ≤ŸÖŸÜŸäÿ© ŸÑŸÑÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ©
- ÿßŸÑÿ•ÿ¨ÿ±ÿßÿ°ÿßÿ™ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ŸÅŸä ÿ≠ÿßŸÑÿ© ÿπÿØŸÖ ÿßŸÑÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ©
- ÿßŸÑÿ™Ÿàÿ´ŸäŸÇ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä ŸàÿßŸÑÿ™ÿ®ŸÑŸäÿ∫ ÿßŸÑÿ±ÿ≥ŸÖŸä

‚öñÔ∏è **ÿßŸÑŸÇŸàÿ© ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ©:**
- ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÑÿ∫ÿ© ŸÇÿßŸÜŸàŸÜŸäÿ© ÿ≠ÿßÿ≤ŸÖÿ©
- ÿßŸÑÿßÿ≥ÿ™ŸÜÿßÿØ ŸÑŸÑŸÜÿµŸàÿµ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ©
- ÿ™ÿ≠ÿ∞Ÿäÿ± ŸÖŸÜ ÿßŸÑÿπŸàÿßŸÇÿ® ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ©
- ÿ•ÿ´ÿ®ÿßÿ™ ÿ≠ÿ≥ŸÜ ÿßŸÑŸÜŸäÿ© ŸÅŸä ÿßŸÑŸÖÿ∑ÿßŸÑÿ®ÿ©

üéØ **ÿßŸÑŸáÿØŸÅ:** ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿßŸÑÿ≠ŸÇ ÿØŸàŸÜ ÿ™ŸÇÿßÿ∂Ÿä ÿ£Ÿà ÿ™ŸáŸäÿ¶ÿ© ŸÑÿ±ŸÅÿπ ÿØÿπŸàŸâ"""

    def _get_consultation_layer(self, query: str) -> str:
        """Get general consultation specific prompt layer"""
        return f"""üìã **ÿßÿ≥ÿ™ÿ¥ÿßÿ±ÿ© ŸÇÿßŸÜŸàŸÜŸäÿ© ÿπÿßŸÖÿ©**

**ÿßŸÑÿ≥ÿ§ÿßŸÑ:** {query}

**ŸÖŸÜŸáÿ¨Ÿäÿ© ÿßŸÑÿßÿ≥ÿ™ÿ¥ÿßÿ±ÿ©:**
- ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸàÿ∂ÿπ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä ÿßŸÑÿ≠ÿßŸÑŸä
- ÿ®ŸäÿßŸÜ ÿßŸÑÿ≠ŸÇŸàŸÇ ŸàÿßŸÑÿßŸÑÿ™ÿ≤ÿßŸÖÿßÿ™
- ÿ™Ÿàÿ∂Ÿäÿ≠ ÿßŸÑÿÆŸäÿßÿ±ÿßÿ™ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ©
- ÿßŸÑŸÜÿµÿßÿ¶ÿ≠ ÿßŸÑÿπŸÖŸÑŸäÿ© ŸàÿßŸÑÿ™ŸàÿµŸäÿßÿ™

‚öñÔ∏è **ÿßŸÑÿ•ÿ∑ÿßÿ± ÿßŸÑŸÇÿßŸÜŸàŸÜŸä:**
- ÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ŸàÿßŸÑŸÑŸàÿßÿ¶ÿ≠ ÿ∞ÿßÿ™ ÿßŸÑÿµŸÑÿ©
- ÿßŸÑÿ≥Ÿàÿßÿ®ŸÇ ÿßŸÑŸÇÿ∂ÿßÿ¶Ÿäÿ© ÿßŸÑŸÖŸÖÿßÿ´ŸÑÿ©
- ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπŸÖŸÑŸä ŸÅŸä ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑÿ≥ÿπŸàÿØŸä
- ÿßŸÑŸÖÿÆÿßÿ∑ÿ± ŸàÿßŸÑŸÅÿ±ÿµ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ©

üéØ **ÿßŸÑŸáÿØŸÅ:** ŸÅŸáŸÖ ÿ¥ÿßŸÖŸÑ ŸÑŸÑŸàÿ∂ÿπ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä Ÿàÿßÿ™ÿÆÿßÿ∞ ŸÇÿ±ÿßÿ± ŸÖÿØÿ±Ÿàÿ≥"""



    def _get_document_layer(self, context: LegalContext) -> str:
        """Get document-specific prompt layer"""
        
        # Use existing document layer methods but with error handling
        layer_methods = {
            DocumentType.EXECUTION_DISPUTE: self._get_execution_dispute_layer,
            DocumentType.DEFENSE_MEMO: self._get_defense_memo_layer,
            DocumentType.LAWSUIT: self._get_lawsuit_layer,
            DocumentType.CONTRACT: self._get_contract_layer,
            DocumentType.FAMILY_MEMO: self._get_family_memo_layer,
            DocumentType.APPEAL: self._get_appeal_layer,
            DocumentType.DEMAND_LETTER: self._get_demand_letter_layer,
            DocumentType.CONSULTATION: self._get_consultation_layer
        }
        
        try:
            method = layer_methods.get(context.document_type, self._get_consultation_layer)
            return method(context.query)
        except Exception as e:
            logger.error(f"Error getting document layer: {str(e)}")
            return f"üìã **ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ÿ≠ÿØŸäÿØ ŸÜŸàÿπ ÿßŸÑŸàÿ´ŸäŸÇÿ©:** {str(e)}"
    
    def _get_citation_layer(self, retrieved_documents: List[Any]) -> str:
        """Generate citation enforcement layer"""
        
        if not retrieved_documents:
            return """‚ö†Ô∏è **ÿ™ÿ≠ÿ∞Ÿäÿ±: ŸÑÿß ÿ™Ÿàÿ¨ÿØ Ÿàÿ´ÿßÿ¶ŸÇ ŸÇÿßŸÜŸàŸÜŸäÿ© ŸÖÿ≠ÿØÿØÿ© ŸÖÿ™ÿßÿ≠ÿ©**

**Ÿäÿ¨ÿ® ÿπŸÑŸäŸÉ ÿßŸÑŸÇŸàŸÑ ÿµÿ±ÿßÿ≠ÿ©:**
"ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖÿ≠ÿØÿØÿ© ÿ∫Ÿäÿ± ŸÖÿ™ŸàŸÅÿ±ÿ© ŸÅŸä ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑŸÖÿ±ŸÅŸÇÿ©"

üö´ **ŸÖŸÖŸÜŸàÿπ ÿ™ŸÖÿßŸÖÿßŸã:**
- ÿ∞ŸÉÿ± ÿ£ÿ±ŸÇÿßŸÖ ŸÖŸàÿßÿØ ÿ•ŸÑÿß ÿ•ÿ∞ÿß ŸÉÿßŸÜÿ™ ŸÖŸàÿ¨ŸàÿØÿ© ŸÅŸä ÿßŸÑŸÜÿµŸàÿµ ÿßŸÑŸÖÿ±ŸÅŸÇÿ©
- ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿπÿ®ÿßÿ±ÿßÿ™ ÿπÿßŸÖÿ© ŸÖÿ´ŸÑ "ÿßŸÑŸÇŸàÿßŸÜŸäŸÜ ÿ™ŸÜÿµ" ÿ£Ÿà "ÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ÿ™ÿ¥Ÿäÿ±"
- ÿßŸÑÿßÿ≥ÿ™ÿ¥ŸáÿßÿØ ÿ®ŸÖŸàÿßÿØ ÿ∫Ÿäÿ± ŸÖŸàÿ´ŸÇÿ©"""
        
        try:
            # Extract available citations
            available_citations = []
            formatted_docs = []
            
            for i, doc in enumerate(retrieved_documents, 1):
                if hasattr(doc, 'title') and hasattr(doc, 'content'):
                    citations = self.citation_validator.extract_citations(doc.content)
                    available_citations.extend(citations)
                    
                    formatted_docs.append(f"üìÑ **ÿßŸÑŸÖÿ±ÿ¨ÿπ {i}: {doc.title}**")
                    if citations:
                        formatted_docs.append(f"   ÿßŸÑŸÖŸàÿßÿØ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ©: {', '.join(citations)}")
                    else:
                        formatted_docs.append("   ŸÑÿß ÿ™Ÿàÿ¨ÿØ ŸÖŸàÿßÿØ ŸÖÿ≠ÿØÿØÿ© ŸÅŸä Ÿáÿ∞ÿß ÿßŸÑŸÖÿ±ÿ¨ÿπ")
            
            return f"""üìö **ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖÿ™ÿßÿ≠ÿ© ŸÑŸÑÿßÿ≥ÿ™ÿ¥ŸáÿßÿØ:**

{chr(10).join(formatted_docs)}

üéØ **ÿßŸÑŸÖŸàÿßÿØ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖÿ™ÿßÿ≠ÿ©:**
{', '.join(set(available_citations)) if available_citations else 'ŸÑÿß ÿ™Ÿàÿ¨ÿØ ŸÖŸàÿßÿØ ŸÖÿ≠ÿØÿØÿ©'}

‚ö†Ô∏è **ŸÇŸàÿßÿπÿØ ÿßŸÑÿßÿ≥ÿ™ÿ¥ŸáÿßÿØ ÿßŸÑÿµÿßÿ±ŸÖÿ©:**
- ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸÅŸÇÿ∑ ÿßŸÑŸÖŸàÿßÿØ ÿßŸÑŸÖÿ∞ŸÉŸàÿ±ÿ© ÿ£ÿπŸÑÿßŸá
- ÿ™ŸÜÿ≥ŸäŸÇ ÿ•ÿ¨ÿ®ÿßÿ±Ÿä: "ŸàŸÅŸÇÿßŸã ŸÑŸÑŸÖÿßÿØÿ© (X) ŸÖŸÜ [ÿßŸÑŸÖÿµÿØÿ± ÿßŸÑŸÖÿ≠ÿØÿØ]"
- ŸÖŸÖŸÜŸàÿπ: "ÿßŸÑŸÇŸàÿßŸÜŸäŸÜ ÿ™ŸÜÿµ"ÿå "ÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ÿ™ÿ¥Ÿäÿ±"ÿå "ÿπŸÖŸàŸÖÿßŸã"""
            
        except Exception as e:
            logger.error(f"Error generating citation layer: {str(e)}")
            return f"‚ùå **ÿÆÿ∑ÿ£ ŸÅŸä ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ:** {str(e)}"
    
    def _get_conversation_layer(self, conversation_history: List[Dict[str, str]]) -> str:
        """Generate conversation context layer with error handling"""
        
        if not conversation_history:
            return ""
        
        try:
            # Simple conversation flow detection
            if len(conversation_history) >= 2:
                last_user_msg = ""
                for msg in reversed(conversation_history):
                    if msg.get('role') == 'user':
                        last_user_msg = msg.get('content', '').lower()
                        break
                
                # Detect follow-up patterns
                follow_up_patterns = ['ŸàŸÖÿßÿ∞ÿß', 'ŸàŸÉŸäŸÅ', 'ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ŸÖÿß ÿ∞ŸÉÿ±ÿ™', 'ŸÉŸÖÿß ÿ∞ŸÉÿ±ÿ™']
                if any(pattern in last_user_msg for pattern in follow_up_patterns):
                    return """üîó **ÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©:** Ÿáÿ∞ÿß ÿ≥ÿ§ÿßŸÑ ŸÖÿ™ÿßÿ®ÿπÿ© - ÿßÿ±ÿ®ÿ∑ ÿ•ÿ¨ÿßÿ®ÿ™ŸÉ ÿ®ŸÖÿß ÿ™ŸÖ ÿ¥ÿ±ÿ≠Ÿá ÿ≥ÿßÿ®ŸÇÿßŸã ŸÖÿπ ÿ•ÿ∂ÿßŸÅÿ© ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿ¨ÿØŸäÿØÿ©."""
                
                # Detect topic change
                topic_change_patterns = ['ÿ≥ÿ§ÿßŸÑ ÿ¢ÿÆÿ±', 'ŸÖŸàÿ∂Ÿàÿπ ŸÖÿÆÿ™ŸÑŸÅ', 'ÿßŸÜÿ™ŸÇŸÑ ÿ•ŸÑŸâ']
                if any(pattern in last_user_msg for pattern in topic_change_patterns):
                    return """üîÑ **ÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©:** ŸÖŸàÿ∂Ÿàÿπ ÿ¨ÿØŸäÿØ - ÿßÿ®ÿØÿ£ ÿ™ÿ≠ŸÑŸäŸÑÿßŸã ÿ¨ÿØŸäÿØÿßŸã ŸÖÿπ ÿßŸÑÿßÿπÿ™ÿ±ÿßŸÅ ÿ®ÿßŸÑÿ™ÿ∫ŸäŸäÿ±."""
            
            return """üí¨ **ÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©:** ÿßÿ≥ÿ™ŸÉŸÖÿßŸÑ ÿßŸÑŸÜŸÇÿßÿ¥ - ÿ™ÿßÿ®ÿπ ŸÖÿπ ÿ™ÿπŸÖŸäŸÇ ÿ£ŸÉÿ´ÿ±."""
            
        except Exception as e:
            logger.error(f"Error processing conversation layer: {str(e)}")
            return ""
    
    # Document-specific layer methods (simplified versions of original)
    def _get_execution_dispute_layer(self, query: str) -> str:
        return f"""üìã **ÿ™ÿÆÿµÿµ: ŸÖŸÜÿßÿ≤ÿπÿ© ÿßŸÑÿ™ŸÜŸÅŸäÿ∞**
ŸÖÿ∑ŸÑŸàÿ®: ŸÖŸÜÿßÿ≤ÿπÿ© ÿ™ŸÜŸÅŸäÿ∞ ŸÇŸàŸäÿ© ÿ¨ÿßŸáÿ≤ÿ© ŸÑŸÑŸÖÿ≠ŸÉŸÖÿ©

**ÿßŸÑŸÖŸàÿ∂Ÿàÿπ:** {query}

**ŸáŸäŸÉŸÑ ÿßŸÑŸÖŸÜÿßÿ≤ÿπÿ©:**
- ÿßŸÑÿØŸÅÿπ ÿßŸÑÿ£ŸàŸÑ (ÿ£ŸÇŸàŸâ ÿØŸÅÿπ ÿ•ÿ¨ÿ±ÿßÿ¶Ÿä)
- ÿßŸÑÿØŸÅÿπ ÿßŸÑÿ´ÿßŸÜŸä (ÿØŸÅÿπ ŸÖŸàÿ∂ŸàÿπŸä)  
- ÿßŸÑÿØŸÅÿπ ÿßŸÑÿ´ÿßŸÑÿ´ (ÿØŸÅÿπ ÿ¥ÿ±ÿπŸä/ŸÜÿ∏ÿßŸÖŸä)
- ÿßŸÑÿ∑ŸÑÿ®ÿßÿ™: ŸàŸÇŸÅ ÿßŸÑÿ™ŸÜŸÅŸäÿ∞ + ÿ±ŸÅÿ∂ ÿßŸÑÿ∑ŸÑÿ® + ÿßŸÑÿ±ÿ≥ŸàŸÖ

‚ö†Ô∏è"""
    

    # Add this to the END of your app/core/prompt_controller.py file

# Add this class BEFORE the "# ==================== INTEGRATION FUNCTIONS ====================" line
# in your app/core/prompt_controller.py file

class MasterPromptController:
    """
    üéØ Master Prompt Controller - Single Source of Truth (SSOT)
    
    Orchestrates all prompt generation with unified architecture:
    - Replaces scattered prompt systems
    - Ensures consistent legal responses  
    - Validates citations accuracy
    - Handles error cases gracefully
    """
    
    def __init__(self):
        """Initialize all controller components"""
        self.context_builder = LegalContextBuilder()
        self.prompt_composer = PromptComposer()
        self.citation_validator = CitationValidator()
        self.sanitizer = InputSanitizer()
        
        logger.info("üéØ MasterPromptController initialized - SSOT architecture active")
    
    def generate_prompt_for_query(
        self, 
        query: str, 
        retrieved_documents: List[Any] = None,
        conversation_history: List[Dict[str, str]] = None
    ) -> str:
        """
        üéØ MAIN METHOD: Generate unified prompt for any legal query
        
        This replaces all scattered prompt generation throughout the system
        """
        
        try:
            # Build comprehensive legal context
            context = self.context_builder.build_context(
                query=query,
                retrieved_documents=retrieved_documents,
                conversation_history=conversation_history
            )
            
            # Log detection results for monitoring
            logger.info(f"üéØ Document Type: {context.document_type.value}")
            logger.info(f"üéØ User Intent: {context.user_intent.value}")
            logger.info(f"üéØ Complexity: {context.complexity_level.value}")
            logger.info(f"üéØ Domain: {context.legal_domain.value}")
            logger.info(f"üéØ Confidence: {context.confidence_score:.2f}")
            
            if context.warnings:
                logger.warning(f"‚ö†Ô∏è Context warnings: {context.warnings}")
            
            # Generate final unified prompt
            unified_prompt = self.prompt_composer.compose_prompt(context)
            
            logger.info(f"‚úÖ Generated unified prompt: {len(unified_prompt)} characters")
            
            return unified_prompt
            
        except Exception as e:
            logger.error(f"‚ùå MasterPromptController error: {str(e)}")
            
            # Fallback to basic prompt
            return self._generate_fallback_prompt(query, str(e))
    
    def validate_response_citations(
        self, 
        response: str, 
        available_documents: List[Any]
    ) -> Tuple[bool, List[str]]:
        """
        üîç Validate that AI response only uses available legal citations
        
        Returns: (is_valid, warnings_list)
        """
        
        try:
            return self.citation_validator.validate_citations(response, available_documents)
        except Exception as e:
            logger.error(f"‚ùå Citation validation error: {str(e)}")
            return False, [f"Citation validation failed: {str(e)}"]
    
    def analyze_query_intent(self, query: str) -> Dict[str, Any]:
        """
        üéØ Analyze query and return detailed intent information
        
        Useful for frontend features and analytics
        """
        
        try:
            context = self.context_builder.build_context(query)
            
            return {
                "document_type": context.document_type.value,
                "user_intent": context.user_intent.value, 
                "complexity_level": context.complexity_level.value,
                "legal_domain": context.legal_domain.value,
                "confidence_score": context.confidence_score,
                "warnings": context.warnings,
                "suggested_actions": self._get_suggested_actions(context),
                "estimated_response_length": self._estimate_response_length(context)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Query analysis error: {str(e)}")
            return {
                "document_type": "consultation",
                "user_intent": "understand_law",
                "complexity_level": "simple",
                "legal_domain": "general", 
                "confidence_score": 0.0,
                "warnings": [f"Analysis failed: {str(e)}"],
                "suggested_actions": ["Try rephrasing your question"],
                "estimated_response_length": "short"
            }
    
    def _generate_fallback_prompt(self, query: str, error: str) -> str:
        """Generate safe fallback prompt when main system fails"""
        
        return f"""ÿ£ŸÜÿ™ ŸÖÿ≥ÿ™ÿ¥ÿßÿ± ŸÇÿßŸÜŸàŸÜŸä ÿ≥ÿπŸàÿØŸä ŸÖÿ™ÿÆÿµÿµ.

‚ö†Ô∏è ÿ™ÿ≠ÿ∞Ÿäÿ± ÿßŸÑŸÜÿ∏ÿßŸÖ: ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ∑ŸÑÿ® ({error})

ÿßŸÑÿ≥ÿ§ÿßŸÑ: {query}

Ÿäÿ±ÿ¨Ÿâ:
1. ÿ™ŸÇÿØŸäŸÖ ÿ•ÿ¨ÿßÿ®ÿ© ŸÇÿßŸÜŸàŸÜŸäÿ© ÿπÿßŸÖÿ© Ÿàÿ¢ŸÖŸÜÿ©
2. ÿ∑ŸÑÿ® ÿ™Ÿàÿ∂Ÿäÿ≠ÿßÿ™ ÿ•ÿ∂ÿßŸÅŸäÿ© ŸÖŸÜ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ
3. ÿ™ÿ¨ŸÜÿ® ÿßŸÑÿßÿ≥ÿ™ÿ¥ŸáÿßÿØ ÿ®ŸÖŸàÿßÿØ ŸÖÿ≠ÿØÿØÿ©
4. ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿπÿ®ÿßÿ±ÿ©: "ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ•ÿ¨ÿßÿ®ÿ© ÿØŸÇŸäŸÇÿ©ÿå Ÿäÿ±ÿ¨Ÿâ ÿ™Ÿàÿ∂Ÿäÿ≠ ÿ∑ŸÑÿ®ŸÉ ÿ£ŸÉÿ´ÿ±"

ŸÇÿØŸÖ ÿ•ÿ¨ÿßÿ®ÿ© ŸÖŸÅŸäÿØÿ© ÿ±ÿ∫ŸÖ ÿßŸÑÿÆÿ∑ÿ£ ÿßŸÑÿ™ŸÇŸÜŸä."""
    
    def _get_suggested_actions(self, context: LegalContext) -> List[str]:
        """Get suggested actions based on context"""
        
        suggestions = []
        
        # Based on document type
        if context.document_type == DocumentType.DEFENSE_MEMO:
            suggestions.extend([
                "ÿ¨ŸÖÿπ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿ≥ÿ™ŸÜÿØÿßÿ™ ÿßŸÑŸÖÿ™ÿπŸÑŸÇÿ© ÿ®ÿßŸÑŸÇÿ∂Ÿäÿ©",
                "ŸÖÿ±ÿßÿ¨ÿπÿ© ŸÑÿßÿ¶ÿ≠ÿ© ÿßŸÑÿØÿπŸàŸâ ÿßŸÑŸÖÿ±ŸÅŸàÿπÿ© ÿ∂ÿØŸÉ",
                "ÿ™ÿ≠ÿØŸäÿØ ŸÜŸÇÿßÿ∑ ÿßŸÑÿ∂ÿπŸÅ ŸÅŸä ÿßÿØÿπÿßÿ°ÿßÿ™ ÿßŸÑŸÖÿØÿπŸä"
            ])
        elif context.document_type == DocumentType.LAWSUIT:
            suggestions.extend([
                "ÿ™ÿ¨ŸÖŸäÿπ ÿßŸÑÿ£ÿØŸÑÿ© ŸàÿßŸÑŸÖÿ≥ÿ™ŸÜÿØÿßÿ™ ÿßŸÑÿØÿßÿπŸÖÿ©",
                "ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÖÿ≠ŸÉŸÖÿ© ÿßŸÑŸÖÿÆÿ™ÿµÿ©",
                "ÿ≠ÿ≥ÿßÿ® ŸÇŸäŸÖÿ© ÿßŸÑŸÖÿ∑ÿßŸÑÿ®ÿ© Ÿàÿ±ÿ≥ŸàŸÖ ÿßŸÑÿØÿπŸàŸâ"
            ])
        elif context.document_type == DocumentType.CONTRACT:
            suggestions.extend([
                "ÿ™ÿ≠ÿØŸäÿØ ÿ®ŸÜŸàÿØ ÿßŸÑÿ≠ŸÖÿßŸäÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©",
                "ŸÖÿ±ÿßÿ¨ÿπÿ© ÿßŸÑŸÇŸàÿßŸÜŸäŸÜ ÿ∞ÿßÿ™ ÿßŸÑÿµŸÑÿ©",
                "ÿßÿ≥ÿ™ÿ¥ÿßÿ±ÿ© ÿÆÿ®Ÿäÿ± ŸÇÿßŸÜŸàŸÜŸä ŸÑŸÑŸÖÿ±ÿßÿ¨ÿπÿ© ÿßŸÑŸÜŸáÿßÿ¶Ÿäÿ©"
            ])
        
        # Based on confidence level
        if context.confidence_score < 0.7:
            suggestions.append("ÿ™Ÿàÿ∂Ÿäÿ≠ ŸÜŸàÿπ ÿßŸÑŸàÿ´ŸäŸÇÿ© ÿ£Ÿà ÿßŸÑÿÆÿØŸÖÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ© ÿ®ÿØŸÇÿ© ÿ£ŸÉÿ®ÿ±")
        
        return suggestions if suggestions else ["ŸÖÿ™ÿßÿ®ÿπÿ© ÿßŸÑÿ•ÿ¨ÿ±ÿßÿ°ÿßÿ™ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖŸÜÿßÿ≥ÿ®ÿ©"]
    
    def _estimate_response_length(self, context: LegalContext) -> str:
        """Estimate response length for frontend planning"""
        
        if context.complexity_level == ComplexityLevel.STRATEGIC_DOCUMENT:
            return "long"  # 2000+ words
        elif context.complexity_level == ComplexityLevel.COMPREHENSIVE_ANALYSIS:
            return "medium"  # 800-2000 words  
        else:
            return "short"  # 200-800 words


# ==================== INTEGRATION FUNCTIONS ====================

def get_master_controller() -> MasterPromptController:
    """
    üéØ Factory function to get MasterPromptController instance
    
    Use this in your RAG engine instead of scattered prompts
    """
    return MasterPromptController()


def replace_scattered_prompts(
    query: str,
    retrieved_documents: List[Any] = None,
    conversation_history: List[Dict[str, str]] = None
) -> str:
    """
    üéØ REPLACEMENT FUNCTION for all existing prompt generation
    
    Use this to replace any existing prompt code throughout your system
    """
    
    controller = get_master_controller()
    return controller.generate_prompt_for_query(
        query=query,
        retrieved_documents=retrieved_documents,
        conversation_history=conversation_history
    )


# ==================== USAGE EXAMPLES ====================

"""
üéØ INTEGRATION EXAMPLES:

# In your RAG engine, replace existing prompts with:
unified_prompt = replace_scattered_prompts(
    query=user_question,
    retrieved_documents=chunks,
    conversation_history=chat_history
)

# For analysis (useful for frontend features):
controller = get_master_controller()
analysis = controller.analyze_query_intent("ÿ£ÿ±ŸäÿØ ŸÖÿ∞ŸÉÿ±ÿ© ÿØŸÅÿßÿπ ÿ∂ÿØ ÿØÿπŸàŸâ ÿ™ÿ¨ÿßÿ±Ÿäÿ©")
print(analysis["document_type"])  # "defense_memo"
print(analysis["suggested_actions"])  # List of helpful actions

# For citation validation:
is_valid, warnings = controller.validate_response_citations(
    response=ai_response,
    available_documents=retrieved_chunks
)
"""

if __name__ == "__main__":
    # Test the system
    controller = MasterPromptController()
    
    test_query = "ÿ£ÿ±ŸäÿØ ŸÖÿ∞ŸÉÿ±ÿ© ÿØŸÅÿßÿπ ÿ∂ÿØ ÿØÿπŸàŸâ ÿ™ÿ¨ÿßÿ±Ÿäÿ©"
    prompt = controller.generate_prompt_for_query(test_query)
    
    print("üéØ TEST SUCCESSFUL:")
    print(f"Generated prompt length: {len(prompt)} characters")
    
    analysis = controller.analyze_query_intent(test_query)
    print(f"Detected document type: {analysis['document_type']}")
    print(f"Confidence: {analysis['confidence_score']:.2f}")