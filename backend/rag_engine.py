"""
Legal Reasoning RAG Engine - Production Ready
Zero tech debt, clean architecture, smart legal reasoning
Built for Saudi legal AI with proper issue analysis and contextual prompting
"""
from app.legal_reasoning.document_type_analyzer import LegalDocumentTypeAnalyzer, DocumentType
from app.legal_reasoning.document_generator import LegalDocumentGenerator
import os
from datetime import datetime
from dotenv import load_dotenv
from openai import AsyncOpenAI
import markdown
from typing import List, Dict, Optional, Any, AsyncIterator
import re
import logging
from app.legal_reasoning.memo_processor import LegalMemoProcessor
# Import legal reasoning components
from app.legal_reasoning.issue_analyzer import EnhancedLegalIssueAnalyzer, LegalIssue
from app.core.prompt_controller import MasterPromptController, get_master_controller
# Import clean architecture components
from app.storage.vector_store import VectorStore, Chunk
from app.storage.sqlite_store import SqliteVectorStore

# Load environment variables
try:
    load_dotenv(".env")
except:
    pass

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# API key configuration
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Initialize AI clients - prioritize OpenAI, fallback to DeepSeek
if OPENAI_API_KEY:
    ai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
    ai_model = "gpt-4o"
    print("âœ… Using OpenAI for async AI and embeddings")
elif DEEPSEEK_API_KEY:
    ai_client = AsyncOpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com/v1")
    ai_model = "deepseek-chat"
    print("âœ… Using DeepSeek for async AI and embeddings")
else:
    raise ValueError("âŒ Either OPENAI_API_KEY or DEEPSEEK_API_KEY must be provided in environment")


class StorageFactory:
    """Factory for creating storage backends based on configuration"""
    
    @staticmethod
    def create_storage() -> VectorStore:
        """Create storage backend based on environment configuration"""
        storage_type = os.getenv("VECTOR_STORAGE_TYPE", "sqlite").lower()
        
        if storage_type == "sqlite":
            db_path = os.getenv("SQLITE_DB_PATH", "data/vectors.db")
            return SqliteVectorStore(db_path)
        elif storage_type == "qdrant":
            # Future: QdrantVectorStore implementation
            raise NotImplementedError("Qdrant storage not yet implemented")
        else:
            raise ValueError(f"Unknown storage type: {storage_type}")


class DocumentRetriever:
    """
    Pure database-driven document retriever
    No hardcoded documents - everything comes from storage
    """
    
    def __init__(self, storage: VectorStore, ai_client: AsyncOpenAI):
        """
        Initialize retriever with storage backend
        
        Args:
            storage: Vector storage implementation
            ai_client: AI client for query embeddings
        """
        self.storage = storage
        self.ai_client = ai_client
        self.initialized = False
        
        logger.info(f"DocumentRetriever initialized with {type(storage).__name__}")
    
    async def initialize(self) -> None:
        """Initialize storage backend (no document loading)"""
        if self.initialized:
            return
        
        try:
            # Initialize storage backend
            await self.storage.initialize()
            
            # Check current document count
            stats = await self.storage.get_stats()
            logger.info(f"Storage initialized with {stats.total_chunks} existing documents")
            
            self.initialized = True
            
        except Exception as e:
            logger.error(f"Failed to initialize retriever: {e}")
            raise
    
    async def retrieve_relevant_chunks(self, query: str, legal_issue: LegalIssue, top_k: int = 2) -> List[Chunk]:
        """
        Retrieve relevant chunks from database with legal context
        
        Args:
            query: Search query
            legal_issue: Analyzed legal issue for contextual retrieval
            top_k: Number of results to return
            
        Returns:
            List of relevant Chunk objects from database
        """
        # Ensure initialization
        if not self.initialized:
            await self.initialize()
        
        try:
            # Check if we have any documents in storage
            stats = await self.storage.get_stats()
            if stats.total_chunks == 0:
                logger.warning("No documents found in storage")
                return []
            
            logger.info(f"Searching {stats.total_chunks} documents for: '{query[:50]}...'")
            logger.info(f"Legal context: {legal_issue.legal_domain} | {legal_issue.issue_type}")
            
            # Use hybrid search for better legal document retrieval
            if hasattr(self.storage, 'search_hybrid'):
                search_results = await self.storage.search_hybrid(query, top_k=top_k)
            else:
                # Fallback to basic similarity search
                response = await self.ai_client.embeddings.create(
                    model="text-embedding-ada-002",
                    input=query
                )
                query_embedding = response.data[0].embedding
                search_results = await self.storage.search_similar(query_embedding, top_k=top_k)
            
            # Extract chunks from search results
            relevant_chunks = [result.chunk for result in search_results]
            
            if relevant_chunks:
                logger.info(f"Found {len(relevant_chunks)} relevant documents:")
                for i, chunk in enumerate(relevant_chunks):
                    similarity = search_results[i].similarity_score
                    logger.info(f"  {i+1}. {chunk.title[:50]}... (similarity: {similarity:.3f})")
            else:
                logger.info("No relevant documents found")
            
            return relevant_chunks
            
        except Exception as e:
            logger.error(f"Failed to retrieve relevant chunks: {e}")
            return []
    
    async def get_document_count(self) -> int:
        """Get total number of documents in storage"""
        try:
            stats = await self.storage.get_stats()
            return stats.total_chunks
        except Exception as e:
            logger.error(f"Error getting document count: {e}")
            return 0


class LegalPromptBuilder:
    """Advanced legal prompt builder with issue-aware contextualization"""
    
    LEGAL_SYSTEM_PROMPT = """Ø£Ù†Øª Ù…Ø­Ø§Ù…ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ Ø®Ø¨ÙŠØ± ÙˆÙ…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªÙ…Ø±Ø³ Ù…Ø¹ 20 Ø¹Ø§Ù…Ø§Ù‹ Ù…Ù† Ø§Ù„Ø®Ø¨Ø±Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ.

ØªØ®ØµØµØ§ØªÙƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:
- Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠ ÙˆØ§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¬Ø²Ø§Ø¦ÙŠØ©
- Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ù…Ø¯Ù†ÙŠ ÙˆØ§Ù„Ù…Ø±Ø§ÙØ¹Ø§Øª Ø§Ù„Ø´Ø±Ø¹ÙŠØ©
- Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¹Ù…Ù„ ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø¹Ù…Ø§Ù„ÙŠØ©
- Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„ØªØ¬Ø§Ø±ÙŠ ÙˆØ§Ù„Ø´Ø±ÙƒØ§Øª
- Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ…ÙŠ
- Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø£Ø­ÙˆØ§Ù„ Ø§Ù„Ø´Ø®ØµÙŠØ©

ðŸŽ¯ **Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ©:**
- ÙŠØ¬Ø¨ Ø°ÙƒØ± Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø© ÙˆØ§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù„ÙƒÙ„ Ù†Ù‚Ø·Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
- ÙƒÙ„ Ø§Ø¯Ø¹Ø§Ø¡ Ù‚Ø§Ù†ÙˆÙ†ÙŠ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¨Ø¯Ø£ Ø¨Ù€: "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X) Ù…Ù† [Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø¯Ø¯]"
- Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©: "Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† ØªÙ†Øµ", "Ø§Ù„Ø£Ù†Ø¸Ù…Ø© ØªØ´ÙŠØ±", "Ø¹Ù…ÙˆÙ…Ø§Ù‹", "Ø¹Ø§Ø¯Ø©"
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙŠ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø±ÙÙ‚Ø©ØŒ Ù‚Ù„: "Ø§Ù„Ù…Ø§Ø¯Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø±ÙÙ‚Ø©"

ðŸš« **Ø¹Ø¨Ø§Ø±Ø§Øª Ù…Ø­Ø¸ÙˆØ±Ø© ØªÙ…Ø§Ù…Ø§Ù‹:**
- "ØªØ­Ø¯Ø¯Ù‡Ø§ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø¹Ù…ÙˆÙ…Ø§Ù‹"
- "ØªÙ†Øµ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø¹Ø§Ø¯Ø©"
- "Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© ØªØ´ÙŠØ±"
- "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¹Ø§Ù…Ø©"
- "Ø­Ø³Ø¨ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…Ø¹Ù…ÙˆÙ„ Ø¨Ù‡Ø§"

âœ… **Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ©:**
- ØªÙ‚Ø¯ÙŠÙ… Ù…Ø´ÙˆØ±Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¹Ù…Ù„ÙŠØ© Ù…Ø¹ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¯Ù‚ÙŠÙ‚
- Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù„ÙˆÙ„ Ù…Ø¹ Ø°ÙƒØ± Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„ØºØ© ÙˆØ§Ø¶Ø­Ø© Ù…Ø¹ Ø§Ù„Ø§Ø³ØªÙ†Ø§Ø¯ Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØµØ±ÙŠØ­Ø©
- ØªÙ‚Ø¯ÙŠÙ… Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ø­Ø¯Ø¯Ø© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ù†ØµÙˆØµ ÙˆØ§Ø¶Ø­Ø©
- Ø±Ø¨Ø· ÙƒÙ„ Ù†ØµÙŠØ­Ø© Ø¨Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ø¨Ø§Ù„Ø±Ù‚Ù… ÙˆØ§Ù„Ù…ØµØ¯Ø±

ðŸŽ¯ **ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:**
- "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (12) Ù…Ù† Ø§Ù„Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠØ© Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±Ø§ÙØ¹Ø§Øª Ø§Ù„Ø´Ø±Ø¹ÙŠØ©"
- "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø§Ø¯Ø© (8) Ù…Ù† Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ø«Ø¨Ø§Øª"
- "Ø§Ø³ØªÙ†Ø§Ø¯Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (94) Ù…Ù† Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¬Ø²Ø§Ø¦ÙŠØ©"

âš ï¸ **ØªØ­Ø°ÙŠØ± Ù†Ù‡Ø§Ø¦ÙŠ:**
Ø£ÙŠ Ø¥Ø¬Ø§Ø¨Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆÙ…ÙŠØ§Øª Ø£Ùˆ Ø¹Ø¯Ù… Ø°ÙƒØ± Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ØªØ¹ØªØ¨Ø± ØºÙŠØ± Ù…Ù‚Ø¨ÙˆÙ„Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹."""
    
    @classmethod
    def get_system_prompt(cls) -> str:
        """Get legal system prompt"""
        return cls.LEGAL_SYSTEM_PROMPT
    
    @classmethod
    def add_anti_generalization_enforcement(cls, base_prompt: str) -> str:
        """Add final layer of anti-generalization enforcement to any prompt"""
        
        enforcement_layer = """

ðŸš¨ **ØªØ­Ø°ÙŠØ± Ù†Ù‡Ø§Ø¦ÙŠ - Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø© Ù„Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯:**

âœ… **ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ:**
- Ø°ÙƒØ± Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø© ÙˆØ§Ù„Ù…ØµØ¯Ø± Ù„ÙƒÙ„ Ø§Ø¯Ø¹Ø§Ø¡ Ù‚Ø§Ù†ÙˆÙ†ÙŠ
- Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ†Ø³ÙŠÙ‚: "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X) Ù…Ù† [Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø¯Ø¯]"
- Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±ÙÙ‚Ø© Ø£Ø¹Ù„Ø§Ù‡

ðŸš« **Ù…Ù…Ù†ÙˆØ¹ ØªÙ…Ø§Ù…Ø§Ù‹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª:**
- "ØªØ­Ø¯Ø¯Ù‡Ø§ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø¹Ù…ÙˆÙ…Ø§Ù‹"
- "ØªÙ†Øµ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø¹Ø§Ø¯Ø©"
- "Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© ØªØ´ÙŠØ±"
- "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¹Ø§Ù…Ø©"
- "Ø­Ø³Ø¨ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…Ø¹Ù…ÙˆÙ„ Ø¨Ù‡Ø§"
- "Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† ÙŠÙ†Øµ"
- "Ø§Ù„Ø£Ù†Ø¸Ù…Ø© ØªÙˆØ¶Ø­"
- "ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø¹Ù…ÙˆÙ…Ø§Ù‹"

âš ï¸ **Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©:**
Ù‚Ù„ Ø¨ÙˆØ¶ÙˆØ­: "Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø±ÙÙ‚Ø©"

ðŸŽ¯ **ØªØ°ÙƒØ±:** ÙƒÙ„ ÙƒÙ„Ù…Ø© ÙÙŠ Ø¥Ø¬Ø§Ø¨ØªÙƒ ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨Ù…Ø§Ø¯Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ø­Ø¯Ø¯Ø© Ø£Ùˆ ØªØµØ±ÙŠØ­ ÙˆØ§Ø¶Ø­ Ø¨Ø¹Ø¯Ù… ØªÙˆÙØ± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©.

**Ø£ÙŠ Ù…Ø®Ø§Ù„ÙØ© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ØªØ¹ØªØ¨Ø± Ø®Ø·Ø£Ù‹ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹ Ø¬Ø³ÙŠÙ…Ø§Ù‹.**"""

        return base_prompt + enforcement_layer


    @classmethod
    def build_legal_prompt(cls, query: str, retrieved_chunks: List[Chunk], legal_issue: LegalIssue) -> str:
        """Build contextual legal prompt based on issue analysis"""
        
        # Determine prompt strategy based on legal issue
        if legal_issue.user_position == 'defendant' and legal_issue.advice_type == 'defense_strategy':
            return cls._build_defense_strategy_prompt(query, retrieved_chunks, legal_issue)
        
        elif legal_issue.advice_type == 'procedural_guide':
            return cls._build_procedural_guide_prompt(query, retrieved_chunks, legal_issue)
        
        elif legal_issue.advice_type == 'rights_explanation':
            return cls._build_rights_explanation_prompt(query, retrieved_chunks, legal_issue)
        
        elif legal_issue.user_position == 'plaintiff':
            return cls._build_action_strategy_prompt(query, retrieved_chunks, legal_issue)
        
        else:
            return cls._build_general_advice_prompt(query, retrieved_chunks, legal_issue)
    
    @classmethod
    def _build_defense_strategy_prompt(cls, query: str, retrieved_chunks: List[Chunk], legal_issue: LegalIssue) -> str:
        """Build defense strategy prompt for defendants"""
        
        legal_context = cls._format_legal_context(retrieved_chunks)
        
        return f"""Ø£Ù†Øª Ù…Ø­Ø§Ù…ÙŠ Ø¯ÙØ§Ø¹ Ø³Ø¹ÙˆØ¯ÙŠ Ø®Ø¨ÙŠØ±. Ù…ÙˆÙƒÙ„Ùƒ ÙŠÙˆØ§Ø¬Ù‡ Ù‚Ø¶ÙŠØ© ÙÙŠ Ù…Ø¬Ø§Ù„ {legal_issue.legal_domain} ÙˆÙŠØ­ØªØ§Ø¬ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¯ÙØ§Ø¹ Ù‚ÙˆÙŠØ© ÙˆØ¹Ù…Ù„ÙŠØ©.

ðŸ“š **Ø§Ù„Ø£Ù†Ø¸Ù…Ø© ÙˆØ§Ù„Ù„ÙˆØ§Ø¦Ø­ Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©:**
{legal_context}

âš–ï¸ **Ù…ÙˆÙ‚Ù Ø§Ù„Ø¯ÙØ§Ø¹:**
{query}

**Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ ÙƒÙ…Ø­Ø§Ù…ÙŠ Ø¯ÙØ§Ø¹ Ù…ØªÙ…Ø±Ø³:**

ðŸŽ¯ **Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¯ÙØ§Ø¹ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:**
- Ø­Ø¯Ø¯ Ø£Ù‚ÙˆÙ‰ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯ÙØ§Ø¹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…Ø±ÙÙ‚Ø©
- Ø§Ù‚ØªØ±Ø­ Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ø¯ÙØ§Ø¹ÙŠØ© Ø§Ù„Ø£ÙƒØ«Ø± ÙØ¹Ø§Ù„ÙŠØ© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø¶ÙŠØ©
- Ø±ØªØ¨ Ø§Ù„Ø¯ÙÙˆØ¹ Ø­Ø³Ø¨ Ù‚ÙˆØ© Ø§Ù„ØªØ£Ø«ÙŠØ± ÙˆØ§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©

ðŸ›¡ï¸ **Ø§Ù„Ø¯ÙÙˆØ¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©:**
- Ø§Ø°ÙƒØ± Ø§Ù„Ø¯ÙÙˆØ¹ Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø© ØªÙØµÙŠÙ„ÙŠØ§Ù‹
- Ø±Ø¨Ø· ÙƒÙ„ Ø¯ÙØ¹ Ø¨Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
- Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ØªØ·Ø¨ÙŠÙ‚ ÙƒÙ„ Ø¯ÙØ¹ Ø¹Ù…Ù„ÙŠØ§Ù‹

ðŸ“‹ **Ø®Ø·Ø© Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ÙÙˆØ±ÙŠØ©:**
- Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ø¨ Ø§ØªØ®Ø§Ø°Ù‡Ø§ ÙÙˆØ±Ø§Ù‹ (Ø®Ù„Ø§Ù„ 24-48 Ø³Ø§Ø¹Ø©)
- Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙˆØ§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¬Ù…Ø¹Ù‡Ø§ Ø¨Ø§Ù„ØªÙØµÙŠÙ„
- Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙˆØ§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©

ðŸ’¡ **Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©:**
- Ù†ØµØ§Ø¦Ø­ ØªÙƒØªÙŠÙƒÙŠØ© Ù„ØªÙ‚ÙˆÙŠØ© Ø§Ù„Ù…ÙˆÙ‚Ù Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ
- Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
- Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„Ø¯ÙØ¹ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ

ØªØ­Ø¯Ø« ÙƒÙ…Ø­Ø§Ù…ÙŠ Ø¯ÙØ§Ø¹ Ù…Ø­ØªØ±Ù ÙŠØ¹Ø·ÙŠ Ù†ØµØ§Ø¦Ø­ Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ ÙÙˆØ±Ø§Ù‹."""

    @classmethod
    def _build_procedural_guide_prompt(cls, query: str, retrieved_chunks: List[Chunk], legal_issue: LegalIssue) -> str:
        """Build procedural guide prompt"""
        
        legal_context = cls._format_legal_context(retrieved_chunks)
        
        return f"""Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¥Ø¬Ø±Ø§Ø¦ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ {legal_issue.legal_domain}. 

ðŸ“š **Ø§Ù„Ø£Ù†Ø¸Ù…Ø© ÙˆØ§Ù„Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¦ÙŠØ©:**
{legal_context}

â“ **Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¦ÙŠ:**
{query}

**Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ ÙƒØ®Ø¨ÙŠØ± Ø¥Ø¬Ø±Ø§Ø¦ÙŠ:**

ðŸ“‹ **Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¦ÙŠ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ:**
- Ø§Ø´Ø±Ø­ ÙƒÙ„ Ø®Ø·ÙˆØ© Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ù„ØªÙØµÙŠÙ„ ÙˆØ§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„ØµØ­ÙŠØ­
- Ø­Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯ ÙˆØ§Ù„Ù…Ù‡Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨Ø¯Ù‚Ø©
- Ø§Ø°ÙƒØ± Ø§Ù„Ø±Ø³ÙˆÙ… ÙˆØ§Ù„ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¥Ù† ÙˆØ¬Ø¯Øª
- ÙˆØ¶Ø­ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¨Ø¯ÙŠÙ„Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø·ÙˆØ§Ø±Ø¦

ðŸ“„ **Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©:**
- Ø­Ø¯Ø¯ ÙƒÙ„ Ù…Ø³ØªÙ†Ø¯ Ù…Ø·Ù„ÙˆØ¨ Ø¨Ø¯Ù‚Ø© Ù…Ø¹ Ø§Ù„ÙˆØµÙ
- Ø§Ø´Ø±Ø­ ÙƒÙŠÙÙŠØ© Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙƒÙ„ Ù…Ø³ØªÙ†Ø¯
- Ø§Ø°ÙƒØ± Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª ÙˆØ§Ù„Ø´Ø±ÙˆØ· Ù„ÙƒÙ„ Ù…Ø³ØªÙ†Ø¯
- Ø­Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© ÙˆØ§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ©

âš ï¸ **Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¦ÙŠØ© Ø§Ù„Ø­Ø±Ø¬Ø©:**
- Ø§Ù†Ø¨Ù‡ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¦ÙŠØ© Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªØ¤Ø¯ÙŠ Ù„Ø±ÙØ¶ Ø§Ù„Ø·Ù„Ø¨
- Ø§Ø°ÙƒØ± Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙˆÙƒÙŠÙÙŠØ© ØªØ¬Ù†Ø¨Ù‡Ø§
- Ø­Ø¯Ø¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…

ðŸ• **Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ ÙˆØ§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯:**
- Ø¶Ø¹ Ø¬Ø¯ÙˆÙ„Ø§Ù‹ Ø²Ù…Ù†ÙŠØ§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹ Ù„ÙƒÙ„ Ø¥Ø¬Ø±Ø§Ø¡
- Ø­Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø­Ø±Ø¬Ø© Ø§Ù„ØªÙŠ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ£Ø¬ÙŠÙ„Ù‡Ø§
- Ø§Ù‚ØªØ±Ø­ Ù‡Ø§Ù…Ø´ Ø£Ù…Ø§Ù† Ø²Ù…Ù†ÙŠ Ù„ÙƒÙ„ Ø®Ø·ÙˆØ©

Ù‚Ø¯Ù… Ø¯Ù„ÙŠÙ„Ø§Ù‹ Ø¹Ù…Ù„ÙŠØ§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙŠÙ…ÙƒÙ† Ø§ØªØ¨Ø§Ø¹Ù‡ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© Ø¨Ø¯ÙˆÙ† Ø£Ø®Ø·Ø§Ø¡."""

    @classmethod
    def _build_rights_explanation_prompt(cls, query: str, retrieved_chunks: List[Chunk], legal_issue: LegalIssue) -> str:
        """Build rights explanation prompt"""
        
        legal_context = cls._format_legal_context(retrieved_chunks)
        
        return f"""Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø´Ø±Ø­ Ø§Ù„Ø­Ù‚ÙˆÙ‚ ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª ÙÙŠ {legal_issue.legal_domain}.

ðŸ“š **Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©:**
{legal_context}

â“ **Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù† Ø§Ù„Ø­Ù‚ÙˆÙ‚:**
{query}

**Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ ÙƒØ®Ø¨ÙŠØ± Ø­Ù‚ÙˆÙ‚ÙŠ:**

âš–ï¸ **Ø§Ù„Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:**
- Ø§Ø´Ø±Ø­ ÙƒÙ„ Ø­Ù‚ Ø¨ÙˆØ¶ÙˆØ­ Ù…Ø¹ Ø§Ù„Ø§Ø³ØªÙ†Ø§Ø¯ Ù„Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
- Ø­Ø¯Ø¯ Ù†Ø·Ø§Ù‚ ÙƒÙ„ Ø­Ù‚ ÙˆØ­Ø¯ÙˆØ¯Ù‡ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
- ÙˆØ¶Ø­ ÙƒÙŠÙÙŠØ© Ù…Ù…Ø§Ø±Ø³Ø© ÙƒÙ„ Ø­Ù‚ Ø¹Ù…Ù„ÙŠØ§Ù‹
- Ø§Ø°ÙƒØ± Ø§Ù„Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø·Ù„Ù‚Ø© ÙˆØ§Ù„Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø´Ø±ÙˆØ·Ø©

ðŸ“œ **Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©:**
- Ø­Ø¯Ø¯ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªÙ‚Ø§Ø¨Ù„ ÙƒÙ„ Ø­Ù‚
- Ø§Ø´Ø±Ø­ Ø¹ÙˆØ§Ù‚Ø¨ Ø¹Ø¯Ù… Ø§Ù„ÙˆÙØ§Ø¡ Ø¨Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª
- ÙˆØ¶Ø­ Ø§Ù„ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ø­Ù‚ÙˆÙ‚ ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª

ðŸ›¡ï¸ **Ø¢Ù„ÙŠØ§Øª Ø§Ù„Ø­Ù…Ø§ÙŠØ© ÙˆØ§Ù„Ø¥Ù†ÙØ§Ø°:**
- ÙƒÙŠÙÙŠØ© Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ø¨Ø§Ù„Ø­Ù‚ÙˆÙ‚ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹
- Ø§Ù„Ø¬Ù‡Ø§Øª Ø§Ù„Ù…Ø®ØªØµØ© Ø¨Ø­Ù…Ø§ÙŠØ© ÙƒÙ„ Ø­Ù‚
- Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù†ØªÙ‡Ø§Ùƒ Ø§Ù„Ø­Ù‚ÙˆÙ‚
- Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ø¨Ø¯ÙŠÙ„Ø© Ù„Ø­Ù„ Ø§Ù„Ù†Ø²Ø§Ø¹Ø§Øª

ðŸ’¡ **Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:**
- ÙƒÙŠÙÙŠØ© ØªÙˆØ«ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙˆÙ‚ ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§
- Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ù…Ù† Ø§Ù„ØªÙ†Ø§Ø²Ù„ ØºÙŠØ± Ø§Ù„Ù…Ù‚ØµÙˆØ¯ Ø¹Ù† Ø§Ù„Ø­Ù‚ÙˆÙ‚
- Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù‚ÙˆÙ‚ ÙƒØ§Ù…Ù„Ø©

Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø© Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© Ù…Ù† Ø§Ù„ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ."""

    @classmethod
    def _build_action_strategy_prompt(cls, query: str, retrieved_chunks: List[Chunk], legal_issue: LegalIssue) -> str:
        """Build action strategy prompt for plaintiffs"""
        
        legal_context = cls._format_legal_context(retrieved_chunks)
        
        return f"""Ø£Ù†Øª Ù…Ø­Ø§Ù…ÙŠ ÙˆÙ…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„ØªÙ‚Ø§Ø¶ÙŠ ÙˆØ§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª ÙÙŠ {legal_issue.legal_domain}.

ðŸ“š **Ø§Ù„Ø£Ø³Ø§Ø³ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ:**
{legal_context}

âš–ï¸ **Ù…ÙˆÙ‚Ù Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø©:**
{query}

**Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ ÙƒÙ…Ø­Ø§Ù…ÙŠ ØªÙ‚Ø§Ø¶ÙŠ Ù…ØªÙ…Ø±Ø³:**

ðŸŽ¯ **Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø©:**
- Ø­Ø¯Ø¯ Ø£Ù‚ÙˆÙ‰ Ø§Ù„Ø£Ø³Ø³ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù„Ù„Ù…Ø·Ø§Ù„Ø¨Ø©
- Ø§Ù‚ØªØ±Ø­ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø£ÙƒØ«Ø± ÙØ¹Ø§Ù„ÙŠØ© Ù„ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
- Ø±ØªØ¨ Ø§Ù„Ø­Ø¬Ø¬ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø­Ø³Ø¨ Ù‚ÙˆØ© Ø§Ù„ØªØ£Ø«ÙŠØ±

ðŸ“‹ **Ø®Ø·Ø© Ø§Ù„ØªÙ‚Ø§Ø¶ÙŠ:**
- Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ø±ÙØ¹ Ø§Ù„Ø¯Ø¹ÙˆÙ‰ Ø£Ùˆ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø©
- Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙˆØ§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„ÙˆØ§Ø¬Ø¨ Ø¬Ù…Ø¹Ù‡Ø§
- Ø£ÙØ¶Ù„ ØªÙˆÙ‚ÙŠØª Ù„Ø§ØªØ®Ø§Ø° Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©

ðŸ’ª **ØªÙ‚ÙˆÙŠØ© Ø§Ù„Ù…ÙˆÙ‚Ù Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ:**
- ÙƒÙŠÙÙŠØ© ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø£Ø¯Ù„Ø© ÙˆØ§Ù„Ø­Ø¬Ø¬
- Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ø¨ Ø§ØªØ®Ø§Ø°Ù‡Ø§ Ù„Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø­Ù‚ÙˆÙ‚
- Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªÙØ§ÙˆØ¶ Ù‚Ø¨Ù„ Ø§Ù„ØªÙ‚Ø§Ø¶ÙŠ

âš ï¸ **ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±:**
- Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„Ù†Ø¬Ø§Ø­ ÙˆØ¹ÙˆØ§Ù…Ù„ Ø§Ù„ØªØ£Ø«ÙŠØ±
- Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© ÙˆØ§Ù„Ø¹Ø§Ø¦Ø¯ Ø§Ù„Ù…Ø­ØªÙ…Ù„
- Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… Ù†Ø¬Ø§Ø­ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

Ù‚Ø¯Ù… Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø´Ø§Ù…Ù„Ø© ÙˆØ¹Ù…Ù„ÙŠØ© Ù„ØªØ­Ù‚ÙŠÙ‚ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬."""

    @classmethod
    def _build_general_advice_prompt(cls, query: str, retrieved_chunks: List[Chunk], legal_issue: LegalIssue) -> str:
        """Build general legal advice prompt"""
        
        legal_context = cls._format_legal_context(retrieved_chunks)
        
        if not legal_context:
            return f"""Ù‚Ø¯Ù… Ø§Ø³ØªØ´Ø§Ø±Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ:

{query}

**Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø©:**
- Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆÙˆØ§Ø¶Ø­Ø© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©
- ØªÙˆØ¶ÙŠØ­ Ø¹Ù…Ù„ÙŠ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ
- Ù†ØµØ§Ø¦Ø­ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ø­Ø¯Ø¯Ø© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚
- ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¥Ù† Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±"""
        
        return f"""Ù‚Ø¯Ù… Ø§Ø³ØªØ´Ø§Ø±Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ© Ù…ØªØ®ØµØµØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©:

ðŸ“š **Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø±Ø³Ù…ÙŠØ©:**
{legal_context}

â“ **Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ:**
{query}

**Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ ÙƒÙ…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ:**

ðŸ” **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ:**
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…Ø±ÙÙ‚Ø©
- ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
- ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø­Ù‚ÙˆÙ‚ ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª

ðŸ’¡ **Ø§Ù„Ø¥Ø±Ø´Ø§Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠ:**
- Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ÙˆØ§Ø¬Ø¨ Ø§ØªØ®Ø§Ø°Ù‡Ø§
- Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
- Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ÙˆØ§Ù„Ø§Ø­ØªÙŠØ§Ø·Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©

ðŸ“‹ **Ø§Ù„ØªÙˆØµÙŠØ§Øª:**
- Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©
- Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ ÙÙŠ Ø­Ø§Ù„Ø© ÙˆØ¬ÙˆØ¯ Ø¹Ù‚Ø¨Ø§Øª
- Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ ÙˆØ§Ù„Ø¬Ù‡Ø§Øª Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„ÙŠÙ‡Ø§

Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ù…Ù‡Ù†ÙŠØ© ÙˆØ§Ø¶Ø­Ø© Ù…Ø¹ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©."""

    @classmethod
    def _format_legal_context(cls, retrieved_chunks: List[Chunk]) -> str:
        """Format retrieved legal documents with article extraction and citation guidance"""
        if not retrieved_chunks:
            return """âš ï¸ **ØªØ­Ø°ÙŠØ±:** Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ«Ø§Ø¦Ù‚ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ø­Ø¯Ø¯Ø© Ù…ØªØ§Ø­Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
            
**ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ:**
- Ø£Ù† ØªÙ‚ÙˆÙ„ ØµØ±Ø§Ø­Ø©: "Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
- ØªØ¬Ù†Ø¨ ØªÙ…Ø§Ù…Ø§Ù‹ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© Ø£Ùˆ ØºÙŠØ± Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
- Ù„Ø§ ØªØ°ÙƒØ± Ø£Ø±Ù‚Ø§Ù… Ù…ÙˆØ§Ø¯ Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±ÙÙ‚Ø©"""
        
        formatted_context = []
        article_numbers_found = []
        
        for i, chunk in enumerate(retrieved_chunks, 1):
            # Extract article numbers from chunk content
            articles = cls._extract_article_numbers(chunk.content)
            if articles:
                article_numbers_found.extend(articles)
            
            # Format chunk with article highlighting
            formatted_chunk = f"""ðŸ“„ **Ø§Ù„Ù…Ø±Ø¬Ø¹ {i}: {chunk.title}**

ðŸ“‹ **Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø±Ø¬Ø¹:**
{cls._highlight_articles(chunk.content)}

ðŸ’¡ **Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯:**
- Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© Ø£Ø¹Ù„Ø§Ù‡ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ø±Ø¬Ø¹
- Ø§Ø°ÙƒØ± Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø© + Ù…ØµØ¯Ø±Ù‡Ø§ ({chunk.title})
- Ù„Ø§ ØªØ³ØªÙ†ØªØ¬ Ù…ÙˆØ§Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†Øµ"""
            
            formatted_context.append(formatted_chunk)
        
        # Add citation summary
        if article_numbers_found:
            summary = f"""
ðŸŽ¯ **Ù…Ù„Ø®Øµ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯:**
{', '.join(set(article_numbers_found))}

âš ï¸ **ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
- Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© Ø£Ø¹Ù„Ø§Ù‡
- ÙƒÙ„ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªØ¨Ø¹ ØªÙ†Ø³ÙŠÙ‚: "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X) Ù…Ù† [Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯]"
- Ù…Ù…Ù†ÙˆØ¹ Ø°ÙƒØ± Ø£ÙŠ Ù…ÙˆØ§Ø¯ Ø£Ø®Ø±Ù‰ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±ÙÙ‚Ø©
- Ø¥Ø°Ø§ Ø³Ø£Ù„Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù† Ù…Ø§Ø¯Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ù‚Ù„: "Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø§Ø¯Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø±ÙÙ‚Ø©"
"""
            formatted_context.insert(0, summary)
        
        return "\n\n".join(formatted_context)

    @classmethod
    def _extract_article_numbers(cls, text: str) -> List[str]:
        """Extract article numbers from legal text"""
        import re
        
        # Patterns for Arabic article numbers
        patterns = [
            r'Ø§Ù„Ù…Ø§Ø¯Ø©\s*\((\d+)\)',           # Ø§Ù„Ù…Ø§Ø¯Ø© (12)
            r'Ø§Ù„Ù…Ø§Ø¯Ø©\s*(\d+)',              # Ø§Ù„Ù…Ø§Ø¯Ø© 12
            r'Ù…Ø§Ø¯Ø©\s*\((\d+)\)',            # Ù…Ø§Ø¯Ø© (12)
            r'Ù…Ø§Ø¯Ø©\s*(\d+)',               # Ù…Ø§Ø¯Ø© 12
            r'Ø§Ù„ÙÙ‚Ø±Ø©\s*\((\d+)\)',          # Ø§Ù„ÙÙ‚Ø±Ø© (3)
            r'Ø§Ù„ÙÙ‚Ø±Ø©\s*(\d+)',             # Ø§Ù„ÙÙ‚Ø±Ø© 3
            r'Ø§Ù„Ø¨Ù†Ø¯\s*\((\d+)\)',           # Ø§Ù„Ø¨Ù†Ø¯ (5)
            r'Ø§Ù„Ø¨Ù†Ø¯\s*(\d+)',              # Ø§Ù„Ø¨Ù†Ø¯ 5
        ]
        
        article_numbers = []
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                article_numbers.append(f"Ø§Ù„Ù…Ø§Ø¯Ø© ({match})")
        
        return list(set(article_numbers))  # Remove duplicates

    @classmethod  
    def _highlight_articles(cls, text: str) -> str:
        """Highlight article numbers in legal text for easy identification"""
        import re
        
        # Highlight article patterns
        patterns = [
            (r'(Ø§Ù„Ù…Ø§Ø¯Ø©\s*\(\d+\))', r'ðŸŽ¯ **\1**'),
            (r'(Ø§Ù„Ù…Ø§Ø¯Ø©\s*\d+)', r'ðŸŽ¯ **\1**'),
            (r'(Ù…Ø§Ø¯Ø©\s*\(\d+\))', r'ðŸŽ¯ **\1**'),
            (r'(Ù…Ø§Ø¯Ø©\s*\d+)', r'ðŸŽ¯ **\1**'),
        ]
        
        highlighted_text = text
        for pattern, replacement in patterns:
            highlighted_text = re.sub(pattern, replacement, highlighted_text)
        
        return highlighted_text


    @classmethod
    def build_conversation_aware_prompt(
        cls, 
        query: str, 
        retrieved_chunks: List[Chunk], 
        legal_issue: LegalIssue
    ) -> str:
        """Lean conversation-aware prompt with citation enforcement"""
        
        legal_context = cls._format_legal_context(retrieved_chunks)
        
        # Determine conversation prefix
        conversation_prefix = ""
        if hasattr(legal_issue, 'conversation_context'):
            context = legal_issue.conversation_context
            if context.conversation_flow == 'first_message':
                conversation_prefix = "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø¬Ø¯ÙŠØ¯Ø© - Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„:"
            elif context.is_follow_up:
                conversation_prefix = "Ù…ØªØ§Ø¨Ø¹Ø© - Ø§Ø¨Ø¯Ø£ Ø¨Ù€ 'ÙƒÙ…Ø§ Ø°ÙƒØ±Øª Ø³Ø§Ø¨Ù‚Ø§Ù‹':"
            elif context.is_repetition:
                conversation_prefix = "ØªÙˆØ¶ÙŠØ­ - Ø§Ø´Ø±Ø­ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø¨Ø³Ø·:"
            elif context.conversation_flow == 'continuation':
                conversation_prefix = "Ø§Ø³ØªÙƒÙ…Ø§Ù„ - Ø£Ø¶Ù Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©:"
            elif context.conversation_flow == 'topic_change':
                conversation_prefix = "Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÙŠØ¯ - Ø§Ø¨Ø¯Ø£ Ø¨Ù€ 'Ø§Ù†ØªÙ‚Ø§Ù„Ø§Ù‹ Ø¥Ù„Ù‰':"
        
        return f"""{conversation_prefix}

ðŸ“š {legal_context}

â“ {query}

ðŸŽ¯ **Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ©:** ÙƒÙ„ Ù†Ù‚Ø·Ø© ØªØ¨Ø¯Ø£ Ø¨Ù€ "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X) Ù…Ù† [Ø§Ù„Ù…ØµØ¯Ø±]"
ðŸš« **Ù…Ù…Ù†ÙˆØ¹:** Ø¹Ù…ÙˆÙ…ÙŠØ§ØªØŒ "Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† ØªÙ†Øµ"ØŒ Ø§Ø³ØªØ´Ù‡Ø§Ø¯Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©

Ù‚Ø¯Ù… Ø§Ø³ØªØ´Ø§Ø±Ø© Ø¹Ù…Ù„ÙŠØ© Ù…Ø¹ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¯Ù‚ÙŠÙ‚."""
            

    @classmethod
    def _build_comprehensive_first_prompt(cls, query: str, retrieved_chunks: List[Chunk], legal_issue: LegalIssue) -> str:
        """Build comprehensive first response prompt with citation enforcement"""
        legal_context = cls._format_legal_context(retrieved_chunks)

        # 'legal_issue' is required by signature for consistency, even if not used directly.
        return f"""Ù‡Ø°Ø§ Ø£ÙˆÙ„ Ø³Ø¤Ø§Ù„ ÙÙŠ Ø§Ø³ØªØ´Ø§Ø±Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©. Ù‚Ø¯Ù… Ø§Ø³ØªØ´Ø§Ø±Ø© Ø´Ø§Ù…Ù„Ø© Ù…Ø¹ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¯Ù‚ÙŠÙ‚.

ðŸ“š **Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©:**
{legal_context}

â“ **Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ:**
{query}

ðŸŽ¯ **Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ©:**
- ÙƒÙ„ Ù†Ù‚Ø·Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙŠØ¬Ø¨ Ø£Ù† ØªØ¨Ø¯Ø£ Ø¨Ù€: "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X) Ù…Ù† [Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯]"
- Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù…: "Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† ØªÙ†Øµ", "Ø§Ù„Ø£Ù†Ø¸Ù…Ø© ØªØ´ÙŠØ±", "Ø¹Ù…ÙˆÙ…Ø§Ù‹", "Ø¹Ø§Ø¯Ø©"
- Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø£Ø¹Ù„Ø§Ù‡
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ù…Ø§Ø¯Ø© Ù…Ø­Ø¯Ø¯Ø©ØŒ Ù‚Ù„: "Ø§Ù„Ù…Ø§Ø¯Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø±ÙÙ‚Ø©"

**Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ ÙƒÙ…Ø­Ø§Ù…ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ Ø®Ø¨ÙŠØ±:**

âš–ï¸ **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ:**
- Ø§Ø¨Ø¯Ø£ ÙƒÙ„ Ù†Ù‚Ø·Ø© Ø¨Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯: "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X) Ù…Ù† [Ø§Ù„Ù…ØµØ¯Ø±]"
- Ø§Ø±Ø¨Ø· ÙƒÙ„ Ø­Ù‚ Ø£Ùˆ Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
- Ø§Ø´Ø±Ø­ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù…Ø¹ Ø°ÙƒØ± Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ

ðŸ’¡ **Ø§Ù„Ø¥Ø±Ø´Ø§Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù…Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±:**
- "Ø¨Ù…ÙˆØ¬Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø© (X): Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù‡ÙŠ..."
- "Ø§Ø³ØªÙ†Ø§Ø¯Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Y): Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù‡ÙŠ..."
- "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Z): Ø§Ù„Ù…Ù‡Ù„Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù‡ÙŠ..."

ðŸŽ¯ **Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ù…Ø¹ Ø§Ù„Ø£Ø³Ø§Ø³ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ:**
- "Ø§Ù„Ù…Ø§Ø¯Ø© (X) ØªØªÙŠØ­ Ù„Ùƒ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©..."
- "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø§Ø¯Ø© (Y): Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ù‡ÙŠ..."
- "Ø§Ù„Ù…Ø§Ø¯Ø© (Z) ØªÙˆØ¶Ø­ Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø§Ù„Ù…ØªØ§Ø­Ø©..."

âš ï¸ **ØªØ­Ø°ÙŠØ±Ø§Øª Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ø­Ø¯Ø¯Ø©:**
- "Ø§Ù„Ù…Ø§Ø¯Ø© (X) ØªØ­Ø°Ø± Ù…Ù†..."
- "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Y): ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨..."
- "Ø§Ù„Ù…Ø§Ø¯Ø© (Z) ØªÙ†Øµ Ø¹Ù„Ù‰ Ø¹Ù‚ÙˆØ¨Ø©..."

ðŸš« **Ù…Ù…Ù†ÙˆØ¹ ØªÙ…Ø§Ù…Ø§Ù‹:**
- Ø£ÙŠ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ø§Ù…Ø© Ø¨Ø¯ÙˆÙ† Ø±Ù‚Ù… Ù…Ø§Ø¯Ø© Ù…Ø­Ø¯Ø¯
- Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¨Ù…ÙˆØ§Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ø±ÙÙ‚Ø©
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø¨Ø§Ø±Ø§Øª: "Ø­Ø³Ø¨ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†", "Ø§Ù„Ø£Ù†Ø¸Ù…Ø© ØªÙ†Øµ", "Ø¹Ù…ÙˆÙ…Ø§Ù‹"

Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø£Ø¹Ù„Ø§Ù‡ Ù…Ø¹ Ø°ÙƒØ± Ø£Ø±Ù‚Ø§Ù…Ù‡Ø§ ÙˆÙ…ØµØ§Ø¯Ø±Ù‡Ø§ Ø¨Ø¯Ù‚Ø©."""


    @classmethod
    def _build_clarification_prompt(cls, query: str, retrieved_chunks: List[Chunk]) -> str:
        """Build clarification-focused prompt with citation enforcement"""

        legal_context = cls._format_legal_context(retrieved_chunks)

        return f"""Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ·Ù„Ø¨ ØªÙˆØ¶ÙŠØ­Ø§Ù‹ Ø¥Ø¶Ø§ÙÙŠØ§Ù‹. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØ¶ÙŠØ­ Ù…Ø¹ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¯Ù‚ÙŠÙ‚.

ðŸ“š **Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©:**
{legal_context}

â“ **Ø·Ù„Ø¨ Ø§Ù„ØªÙˆØ¶ÙŠØ­:**
{query}

ðŸŽ¯ **Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ©:**
- ÙƒÙ„ ØªÙˆØ¶ÙŠØ­ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¨Ø¯Ø£ Ø¨Ù€: "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X) Ù…Ù† [Ø§Ù„Ù…ØµØ¯Ø±]"
- Ù„Ø§ ØªÙˆØ¶ÙŠØ­Ø§Øª Ø¹Ø§Ù…Ø© - ÙÙ‚Ø· Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ù…Ø§Ø¯Ø© Ù…Ø­Ø¯Ø¯Ø©ØŒ Ù‚Ù„: "Ø§Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØºÙŠØ± Ù…ØªÙˆÙØ± ÙÙŠ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø±ÙÙ‚Ø©"

**Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ:**

ðŸ” **Ø§Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ù…Ø±ÙƒØ² Ù…Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±:**
- "Ø§Ù„Ù…Ø§Ø¯Ø© (X) ØªÙˆØ¶Ø­ Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù‚Ø·Ø© ÙƒØ§Ù„ØªØ§Ù„ÙŠ..."
- "Ø¨Ù…ÙˆØ¬Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø© (Y): Ø§Ù„ØªÙØ³ÙŠØ± Ø§Ù„ØµØ­ÙŠØ­ Ù‡Ùˆ..."
- "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Z): Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…Ø­Ø¯Ø¯ ÙŠØ´Ù…Ù„..."

ðŸ’­ **Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØµÙŠØ§ØºØ© Ø¨Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯:**
- "Ù„ØªØ¨Ø³ÙŠØ· Ø§Ù„Ù…Ø§Ø¯Ø© (X): Ø§Ù„Ù…Ù‚ØµÙˆØ¯ Ù‡Ùˆ..."
- "Ø§Ù„Ù…Ø§Ø¯Ø© (Y) ØªØ¹Ù†ÙŠ Ø¹Ù…Ù„ÙŠØ§Ù‹..."
- "Ù„Ù„ØªÙˆØ¶ÙŠØ­ØŒ Ø§Ù„Ù…Ø§Ø¯Ø© (Z) ØªÙ†Øµ Ø¹Ù„Ù‰..."

âœ… **Ø®Ø·ÙˆØ§Øª ÙˆØ§Ø¶Ø­Ø© Ù…Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±:**
- "Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X): ..."
- "Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¨Ù…ÙˆØ¬Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø© (Y): ..."
- "Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø«Ø§Ù„Ø«Ø© Ø§Ø³ØªÙ†Ø§Ø¯Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Z): ..."

ðŸš« **Ù…Ù…Ù†ÙˆØ¹ ØªÙ…Ø§Ù…Ø§Ù‹:**
- Ø£ÙŠ ØªÙˆØ¶ÙŠØ­ Ø¨Ø¯ÙˆÙ† Ø±Ù‚Ù… Ù…Ø§Ø¯Ø© Ù…Ø­Ø¯Ø¯
- Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø©
- Ø§Ù„ØªØ´Ø¨ÙŠÙ‡Ø§Øª Ø¨Ø¯ÙˆÙ† Ø£Ø³Ø§Ø³ Ù‚Ø§Ù†ÙˆÙ†ÙŠ

Ù‚Ø¯Ù… ØªÙˆØ¶ÙŠØ­Ø§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹ Ù…Ø¨Ù†ÙŠØ§Ù‹ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹."""

@classmethod
def _build_follow_up_prompt(cls, query: str, retrieved_chunks: List[Chunk], legal_issue: LegalIssue) -> str:
    """Build follow-up prompt with citation enforcement and reference to previous discussion"""
    
    legal_context = cls._format_legal_context(retrieved_chunks)
    
    return f"""Ù‡Ø°Ø§ Ø³Ø¤Ø§Ù„ Ù…ØªØ§Ø¨Ø¹Ø© ÙŠØ¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚Ø§Ø´ Ø§Ù„Ø³Ø§Ø¨Ù‚. Ø§Ø±Ø¨Ø· Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø¨Ù…Ø§ ØªÙ… Ø´Ø±Ø­Ù‡ Ù…Ø¹ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¯Ù‚ÙŠÙ‚.

ðŸ“š **Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©:**
{legal_context}

â“ **Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©:**
{query}

ðŸŽ¯ **Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ©:**
- ÙƒÙ„ Ù†Ù‚Ø·Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙŠØ¬Ø¨ Ø£Ù† ØªØ¨Ø¯Ø£ Ø¨Ù€: "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X) Ù…Ù† [Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯]"
- Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø£Ø¹Ù„Ø§Ù‡
- Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© Ø£Ùˆ ØºÙŠØ± Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©

**Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ:**

ðŸ”— **Ø§Ù„Ø±Ø¨Ø· Ø¨Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù…Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±:**
- "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø§ Ù†Ø§Ù‚Ø´Ù†Ø§Ù‡ Ø³Ø§Ø¨Ù‚Ø§Ù‹ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø§Ø¯Ø© (X)..."
- "ÙƒÙ…Ø§ Ø°ÙƒØ±Øª ÙÙŠ Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Y)..."
- "Ù„Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ù…Ø§ ØªÙ… Ø´Ø±Ø­Ù‡ Ø¹Ù† Ø§Ù„Ù…Ø§Ø¯Ø© (Z)..."

âž• **Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯:**
- "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X) Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©: Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù‡ÙŠ..."
- "Ø§Ù„Ù…Ø§Ø¯Ø© (Y) ØªÙˆØ¶Ø­ Ø¬Ø§Ù†Ø¨Ø§Ù‹ Ù„Ù… Ù†ØªØ·Ø±Ù‚ Ø¥Ù„ÙŠÙ‡ Ø³Ø§Ø¨Ù‚Ø§Ù‹..."
- "Ø¨Ù…ÙˆØ¬Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø© (Z): Ø§Ù„ØªÙØµÙŠÙ„ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ ÙŠØ´Ù…Ù„..."

ðŸŽ¯ **Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù…Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±:**
- "Ø§Ù„Ù…Ø§Ø¯Ø© (X) ØªØ·Ø¨Ù‚ Ù…Ø¹ Ù…Ø§ Ø³Ø¨Ù‚ Ø¨Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©..."
- "Ø§Ø³ØªÙ†Ø§Ø¯Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Y): Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‡ÙŠ..."
- "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Z): Ø§Ù„ØªÙƒØ§Ù…Ù„ ÙŠØªÙ… Ø¹Ø¨Ø±..."

âš ï¸ **ØªØ¬Ù†Ø¨ ØªÙ…Ø§Ù…Ø§Ù‹:**
- ØªÙƒØ±Ø§Ø± Ù†ÙØ³ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
- Ø°ÙƒØ± Ù…ÙˆØ§Ø¯ Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„ÙŠÙ‡Ø§ ÙƒØ¥Ø¶Ø§ÙØ©
- Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© Ø¨Ø¯ÙˆÙ† Ù…ØµØ§Ø¯Ø± Ù…Ø­Ø¯Ø¯Ø©

Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØªØ³Ù„Ø³Ù„ Ù…Ù†Ø·Ù‚ÙŠ Ù…Ø¹ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¯Ù‚ÙŠÙ‚ Ù…Ù† Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…ØªØ§Ø­Ø©."""

@classmethod
def _build_continuation_prompt(cls, query: str, retrieved_chunks: List[Chunk], legal_issue: LegalIssue) -> str:
    """Build continuation prompt with citation enforcement"""
    
    legal_context = cls._format_legal_context(retrieved_chunks)
    
    return f"""Ù‡Ø°Ø§ Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ù„Ù†ÙØ³ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ. ØªØ§Ø¨Ø¹ Ø§Ù„Ù†Ù‚Ø§Ø´ Ù…Ø¹ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¯Ù‚ÙŠÙ‚.

ðŸ“š **Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©:**
{legal_context}

â“ **Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹:**
{query}

ðŸŽ¯ **Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ©:**
- ÙƒÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¬Ø¯ÙŠØ¯Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªØ¨Ø¯Ø£ Ø¨Ù€: "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X) Ù…Ù† [Ø§Ù„Ù…ØµØ¯Ø±]"
- Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø£Ø¹Ù„Ø§Ù‡
- Ù„Ø§ ØªÙƒØ±Ø± Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¥Ù„Ø§ Ù„Ù„Ø¶Ø±ÙˆØ±Ø©

**Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ:**

ðŸ“ˆ **Ø§Ù„Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ù…Ø¹ Ù…ØµØ§Ø¯Ø± Ø¬Ø¯ÙŠØ¯Ø©:**
- "Ù„Ù„ØªØ¹Ù…Ù‚ Ø£ÙƒØ«Ø±ØŒ Ø§Ù„Ù…Ø§Ø¯Ø© (X) ØªÙ†Øµ Ø¹Ù„Ù‰..."
- "Ù…Ù† Ø¬Ø§Ù†Ø¨ Ø¢Ø®Ø±ØŒ Ø§Ù„Ù…Ø§Ø¯Ø© (Y) ØªÙˆØ¶Ø­..."
- "Ù„Ù„Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ù‰ Ù…Ø§ Ø³Ø¨Ù‚ØŒ Ø§Ù„Ù…Ø§Ø¯Ø© (Z) ØªØ´ÙŠØ± Ø¥Ù„Ù‰..."

ðŸ” **Ø§Ù„ØªØ¹Ù…Ù‚ ÙÙŠ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯:**
- "Ø§Ù„Ù…Ø§Ø¯Ø© (X) ØªØ­Ø¯Ø¯ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø§Ù„ØªØ§Ù„ÙŠØ©..."
- "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Y): Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª ØªØ´Ù…Ù„..."
- "Ø§Ù„Ù…Ø§Ø¯Ø© (Z) ØªÙˆØ¶Ø­ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©..."

ðŸ’¼ **Ø§Ù„Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù…Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±:**
- "Ø§Ù„Ù…Ø§Ø¯Ø© (X) ØªØ·Ø¨Ù‚ Ø¹Ù…Ù„ÙŠØ§Ù‹ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø§Øª..."
- "Ø¨Ù…ÙˆØ¬Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø© (Y): Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ØªØªØ·Ù„Ø¨..."
- "Ø§Ø³ØªÙ†Ø§Ø¯Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Z): Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ØªØ´Ù…Ù„..."

ðŸš« **Ù…Ù…Ù†ÙˆØ¹:**
- Ø¥Ø¹Ø§Ø¯Ø© Ø´Ø±Ø­ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙŠ ØªÙ… ØªÙ†Ø§ÙˆÙ„Ù‡Ø§ Ù…Ø³Ø¨Ù‚Ø§Ù‹
- Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¨Ù…ÙˆØ§Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹
- Ø§Ù„Ø¹Ù…ÙˆÙ…ÙŠØ§Øª Ø¨Ø¯ÙˆÙ† Ù…ØµØ§Ø¯Ø± Ù…Ø­Ø¯Ø¯Ø©

Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¯Ù‚ÙŠÙ‚ Ù…Ù† Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…ØªØ§Ø­Ø©."""

@classmethod
def _build_topic_change_prompt(cls, query: str, retrieved_chunks: List[Chunk], legal_issue: LegalIssue) -> str:
    """Build prompt for topic change with fresh citation enforcement"""
    
    legal_context = cls._format_legal_context(retrieved_chunks)
    
    return f"""Ø§Ù†ØªÙ‚Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¬Ø¯ÙŠØ¯. Ø§Ø¨Ø¯Ø£ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø¬Ø¯ÙŠØ¯Ø§Ù‹ Ù…Ø¹ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¯Ù‚ÙŠÙ‚.

ðŸ“š **Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯:**
{legal_context}

â“ **Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯:**
{query}

ðŸŽ¯ **Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯:**
- ÙƒÙ„ Ù†Ù‚Ø·Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªØ¨Ø¯Ø£ Ø¨Ù€: "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (X) Ù…Ù† [Ø§Ù„Ù…ØµØ¯Ø±]"
- ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù‡Ø°Ø§ ÙƒØ§Ø³ØªØ´Ø§Ø±Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© ØªÙ…Ø§Ù…Ø§Ù‹
- Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ø±ÙÙ‚Ø© Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯

**Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ:**

ðŸ”„ **Ø§Ù„Ø§Ø¹ØªØ±Ø§Ù Ø¨Ø§Ù„ØªØºÙŠÙŠØ±:**
- "Ø§Ù†ØªÙ‚Ø§Ù„Ø§Ù‹ Ø¥Ù„Ù‰ Ù…ÙˆØ¶ÙˆØ¹ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¬Ø¯ÙŠØ¯..."
- "Ø¨Ø®ØµÙˆØµ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø­ÙˆÙ„..."
- "ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…Ø®ØªÙ„Ù..."

âš–ï¸ **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯:**
- "Ø§Ù„Ù…Ø§Ø¯Ø© (X) ØªØ­ÙƒÙ… Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯..."
- "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Y): Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ ÙŠØ´Ù…Ù„..."
- "Ø¨Ù…ÙˆØ¬Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø© (Z): Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© Ù‡ÙŠ..."

ðŸŽ¯ **Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±:**
- "Ø§Ù„Ù…Ø§Ø¯Ø© (X) ØªÙ†Øµ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©..."
- "Ø§Ø³ØªÙ†Ø§Ø¯Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Y): Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª ØªØ´Ù…Ù„..."
- "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø§Ø¯Ø© (Z): Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù‡ÙŠ..."

ðŸš« **Ù…Ù…Ù†ÙˆØ¹:**
- Ø§Ù„Ø±Ø¨Ø· Ø¨Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¨Ø¯ÙˆÙ† Ù…Ø¨Ø±Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ
- Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© Ø£Ùˆ Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©
- Ù†Ù‚Ù„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø£Ø®Ø±Ù‰

ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù‡Ø°Ø§ ÙƒØ§Ø³ØªØ´Ø§Ø±Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¯Ù‚ÙŠÙ‚ Ù…Ù† Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…ØªØ§Ø­Ø©."""





"""
Updated RAG Engine Integration - Minimal changes to pass AI client
Only change: Pass AI client to MasterPromptController
"""


    
class LegalReasoningRAGEngine:
    """
    Advanced Legal Reasoning RAG Engine - Enhanced with Dynamic AI Analysis
    
    Minimal changes: Now passes AI client to MasterPromptController for dynamic conversation analysis
    """
    
    def __init__(self):
        """Initialize Legal RAG engine with dynamic AI conversation analysis"""
        self.ai_client = ai_client
        self.ai_model = ai_model
        
        # Create storage backend via factory
        self.storage = StorageFactory.create_storage()
        
        # Create components
        self.retriever = DocumentRetriever(
            storage=self.storage,
            ai_client=self.ai_client
        )
        
        self.issue_analyzer = EnhancedLegalIssueAnalyzer()
        self.document_type_analyzer = LegalDocumentTypeAnalyzer()
        self.document_generator = LegalDocumentGenerator()
        
        # ðŸš€ ENHANCED: Pass AI client to MasterPromptController for dynamic analysis
        self.master_controller = get_master_controller(ai_client=self.ai_client)
        
        self.prompt_builder = LegalPromptBuilder()
        
        logger.info(f"LegalReasoningRAGEngine initialized with dynamic AI conversation analysis")

    # âœ… ADD THIS METHOD INSIDE THE CLASS - PROPERLY INDENTED
    async def _stream_legal_response(self, messages: List[Dict[str, str]]) -> AsyncIterator[str]:
        """Stream legal response from AI with rate limit handling"""
        import asyncio

        max_retries = 3
        base_delay = 2

        for attempt in range(max_retries):
            try:
                stream = await self.ai_client.chat.completions.create(
                    model=self.ai_model,
                    messages=messages,
                    temperature=0.15,  # Low temperature for consistent legal advice
                    max_tokens=6000,
                    stream=True
                )

                async for chunk in stream:
                    if chunk.choices[0].delta.content:
                        yield chunk.choices[0].delta.content

                return  # Success - exit retry loop

            except Exception as e:
                error_str = str(e).lower()
                logger.error(f"AI streaming error (attempt {attempt + 1}): {e}")

                # Check if it's a rate limiting error
                if any(indicator in error_str for indicator in ["429", "rate limit", "too many requests", "quota"]):
                    if attempt < max_retries - 1:
                        retry_delay = base_delay * (2 ** attempt)  # Exponential backoff: 2s, 4s, 8s
                        logger.warning(f"ðŸ”„ Rate limit detected. Retrying in {retry_delay} seconds... (attempt {attempt + 1}/{max_retries})")

                        # Yield a waiting message to user
                        yield f"\n\nâ³ **Ø§Ù†ØªØ¸Ø§Ø±:** ØªÙ… ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ù…Ø¤Ù‚ØªØ§Ù‹. Ø¬Ø§Ø±ÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø®Ù„Ø§Ù„ {retry_delay} Ø«Ø§Ù†ÙŠØ©...\n\n"

                        await asyncio.sleep(retry_delay)
                        continue
                    else:
                        # Final attempt failed
                        logger.error(f"âŒ Rate limit exceeded after {max_retries} attempts")
                        yield f"""

ðŸš¨ **Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ**

**Ø§Ù„Ø³Ø¨Ø¨:** ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ù…Ù† Ø§Ù„Ø·Ù„Ø¨Ø§Øª (Rate Limit)

**Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:**
1. **Ø§Ù†ØªØ¸Ø± Ø¯Ù‚ÙŠÙ‚Ø© ÙˆØ§Ø­Ø¯Ø©** Ø«Ù… Ø£Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
2. **ØªØ­Ù‚Ù‚ Ù…Ù† Ø±ØµÙŠØ¯ OpenAI** ÙÙŠ Ø­Ø³Ø§Ø¨Ùƒ
3. **ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ** Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø± Ø§Ù„Ø®Ø·Ø£

**Ø±Ù…Ø² Ø§Ù„Ø®Ø·Ø£:** HTTP 429 - Too Many Requests"""
                        return

                # Different error type (not rate limiting)
                elif any(indicator in error_str for indicator in ["authentication", "api key", "unauthorized"]):
                    logger.error("âŒ Authentication error - API key issue")
                    yield f"""

ðŸ”‘ **Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©**

**Ø§Ù„Ø³Ø¨Ø¨:** Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ù…ÙØªØ§Ø­ API Ø£Ùˆ Ø§Ù†ØªÙ‡Ø§Ø¡ ØµÙ„Ø§Ø­ÙŠØªÙ‡

**Ø§Ù„Ø­Ù„ÙˆÙ„:**
1. ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ù…ÙØªØ§Ø­ OpenAI API
2. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø±ØµÙŠØ¯ ÙƒØ§ÙÙŠ ÙÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨
3. ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø·ÙˆØ± Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…ÙØ§ØªÙŠØ­

**Ø±Ù…Ø² Ø§Ù„Ø®Ø·Ø£:** {str(e)}"""
                    return

                else:
                    # Generic error - retry once
                    if attempt < max_retries - 1:
                        logger.warning(f"ðŸ”„ Generic error, retrying... (attempt {attempt + 1}/{max_retries})")
                        await asyncio.sleep(base_delay)
                        continue
                    else:
                        logger.error(f"âŒ Final attempt failed with generic error")
                        yield f"\n\nâŒ **Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ:** {str(e)}\n\nÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø£Ùˆ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ."
                        return
    
    async def _add_request_delay(self):
        """Add small delay between requests to prevent rate limiting"""
        import asyncio
        await asyncio.sleep(0.5)

    # ... rest of your existing methods (ask_question_streaming, ask_question_with_context_streaming, etc.)
    async def ask_question_streaming(self, query: str) -> AsyncIterator[str]:
        """
        Stream legal consultation with dynamic AI conversation analysis
        
        NO CHANGES to this method - it automatically uses the enhanced system!
        """
        try:
            logger.info(f"Processing legal question: {query[:50]}...")
            
            # Stage 1: Analyze legal issue
            legal_issue = await self.issue_analyzer.analyze_issue_with_context(query, [])
            logger.info(f"Legal analysis: {legal_issue.issue_type} | {legal_issue.legal_domain} | {legal_issue.user_position}")
            
            # Stage 2: Retrieve relevant legal documents
            document_type = self.document_type_analyzer.analyze_document_type(query)
            logger.info(f"Contextual document type: {document_type.specific_type} | Category: {document_type.document_category}")
            relevant_chunks = await self.retriever.retrieve_relevant_chunks(
                query=query, 
                legal_issue=legal_issue,
                top_k=2
            )
            
            # ðŸŽ¯ Stage 3: Use Enhanced Master Controller with dynamic AI analysis
            legal_prompt = self.master_controller.generate_prompt_for_query(
                query=query,
                retrieved_documents=relevant_chunks,
                conversation_history=[]
            )
            logger.info("âœ… Using enhanced Master Controller with dynamic AI conversation analysis")
            
            if relevant_chunks:
                logger.info(f"Using legal reasoning with {len(relevant_chunks)} relevant documents")
            else:
                logger.info("Using general legal knowledge (no specific documents found)")
            await self._add_request_delay()
            
            # Stage 4: Generate legal advice with enhanced system
            messages = [
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ Ù…ØªØ®ØµØµ."},
                {"role": "user", "content": legal_prompt}
            ]
            
            # Stream legal advice
            yield "âš–ï¸ **Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©**\n\n"
            
            async for chunk in await self._stream_legal_response(messages):
                yield chunk
                
        except Exception as e:
            logger.error(f"Legal reasoning error: {e}")
            yield f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©: {str(e)}"

    async def ask_question_with_context_streaming(
        self, 
        query: str, 
        conversation_history: List[Dict[str, str]]
    ) -> AsyncIterator[str]:
        """
        Stream legal consultation with dynamic conversation context analysis
        
        ðŸš€ ENHANCED: Now uses dynamic AI conversation analysis instead of hardcoded patterns!
        """
        try:
            logger.info(f"Processing contextual legal question: {query[:50]}...")
            logger.info(f"Conversation context: {len(conversation_history)} messages")
            
            # Stage 1: Analyze legal issue with conversation context
            legal_issue = await self.issue_analyzer.analyze_issue_with_context(query, conversation_history)
            logger.info(f"Legal analysis: {legal_issue.issue_type} | {legal_issue.legal_domain} | {legal_issue.user_position}")
            
            # Stage 2: Retrieve relevant legal documents
            document_type = self.document_type_analyzer.analyze_document_type(query)
            logger.info(f"Contextual document type: {document_type.specific_type} | Category: {document_type.document_category}")
            relevant_chunks = await self.retriever.retrieve_relevant_chunks(
                query=query, 
                legal_issue=legal_issue,
                top_k=2
            )
            
            # Stage 3: Build contextual messages
            messages = [
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ Ù…ØªØ®ØµØµ."}
            ]
            
            # Add conversation history (limit to last 8 messages)
            recent_history = conversation_history[-8:] if len(conversation_history) > 8 else conversation_history
            for msg in recent_history:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            # ðŸŽ¯ Stage 4: Use Enhanced Master Controller with dynamic conversation analysis
            contextual_prompt = await self.master_controller.generate_prompt_for_query(
                query=query,
                retrieved_documents=relevant_chunks,
                conversation_history=recent_history
            )
            logger.info("âœ… Using enhanced Master Controller with dynamic conversation context analysis")
            
            messages.append({    
                "role": "user",
                "content": contextual_prompt
            })

            if relevant_chunks:
                logger.info(f"Using contextual legal reasoning with {len(relevant_chunks)} documents")
            else:
                logger.info("Using contextual general legal knowledge")
            
            # Stream legal advice
            yield "âš–ï¸ **Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©**\n\n"
            
            async for chunk in self._stream_legal_response(messages):
                yield chunk
                
        except Exception as e:
            logger.error(f"Contextual legal reasoning error: {e}")
            yield f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©: {str(e)}"

    # All other methods stay exactly the same...
    async def _add_request_delay(self):
        """Add small delay between requests to prevent rate limiting - NO CHANGES"""
        import asyncio
        await asyncio.sleep(0.5)
    


# Legacy sync functions for backward compatibility
async def ask_question(query: str) -> str:
    """Legacy sync function - converts streaming to complete response"""
    chunks = []
    async for chunk in rag_engine.ask_question_streaming(query):
        chunks.append(chunk)
    return ''.join(chunks)

async def ask_question_with_context(query: str, conversation_history: List[Dict[str, str]]) -> str:
    """Legacy sync function with context - converts streaming to complete response"""
    chunks = []
    async for chunk in rag_engine.ask_question_with_context_streaming(query, conversation_history):
        chunks.append(chunk)
    return ''.join(chunks)

async def generate_conversation_title(first_message: str) -> str:
    """Legacy function for title generation"""
    return await rag_engine.generate_conversation_title(first_message)

# Add this method to your LegalReasoningRAGEngine class (around line 200)

async def process_legal_memo_file(self, file_path: str) -> Dict[str, Any]:
   """Process 25K legal memo file and add to storage"""
   
   try:
       processor = LegalMemoProcessor(self.storage)
       
       # Extract individual memos
       memos = await processor.extract_individual_memos(file_path)
       logger.info(f"Extracted {len(memos)} legal memos from file")
       
       # Process each memo
       all_chunks = []
       court_system_counts = {}
       
       for memo in memos:
           # Count by court system
           court_system_counts[memo.court_system] = court_system_counts.get(memo.court_system, 0) + 1
           
           # Chunk the memo
           chunks = processor.chunk_legal_memo(memo)
           all_chunks.extend(chunks)
           
           # Process in batches to avoid memory issues
           if len(all_chunks) >= 50:
               await self.storage.add_chunks(all_chunks)
               logger.info(f"Stored batch of {len(all_chunks)} chunks")
               all_chunks = []
       
       # Store remaining chunks
       if all_chunks:
           await self.storage.add_chunks(all_chunks)
           logger.info(f"Stored final batch of {len(all_chunks)} chunks")
       
       # Get final stats
       stats = await self.storage.get_stats()
       
       return {
           "success": True,
           "total_memos": len(memos),
           "total_chunks": stats.total_chunks,
           "court_system_breakdown": court_system_counts,
           "message": f"Successfully processed {len(memos)} legal memos into {stats.total_chunks} chunks"
       }
       
   except Exception as e:
       logger.error(f"Error processing legal memo file: {e}")
       return {
           "success": False,
           "error": str(e),
           "message": f"Failed to process legal memo file: {str(e)}"
       }

# System initialization message
print("ðŸ›ï¸ Legal Reasoning RAG Engine loaded - Production ready with zero tech debt!")
rag_engine = LegalReasoningRAGEngine()