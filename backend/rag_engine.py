"""
Optimized Multi-Domain RAG Engine - Fast & Reliable
Balanced approach: Quality responses with reasonable speed
Supports: Legal, Financial, Administrative, and Technical consultations
"""

import os
from dotenv import load_dotenv
from openai import OpenAI
import markdown
from typing import List, Dict

# Load env variables
load_dotenv(".env")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
if not DEEPSEEK_API_KEY:
    raise ValueError("โ API key missing")

# Init DeepSeek
deepseek = OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com/v1")

def ask_question(query: str) -> str:
    """
    Optimized consultation with smart category detection and balanced prompting.
    """
    print(f"๐ค ุณุคุงู ุงููุณุชุฎุฏู: {query}")

    # Detect legal litigation for strategic response
    if any(phrase in query for phrase in ["ุงูุฑุฏ ุงููุงูููู ุนูู ุฏุนูู", "ุฑุฏ ุนูู ุงูุฏุนูู"]):
        enhanced_query = f"""ูู ุจุฅุนุฏุงุฏ ุฑุฏ ูุงูููู ุดุงูู ููุชูุฏู:

{query}

ูุทููุจ: ุฑุฏ ูุงูููู ูุชูุงูู ูุชุถูู:
- ุฏููุน ููุถูุนูุฉ ูุดูููุฉ ูููุฉ
- ุงุณุชุดูุงุฏุงุช ุจุงูููุงุฏ ุงููุธุงููุฉ
- ุงุณุชุฑุงุชูุฌูุฉ ุฅุซุจุงุช ูุฃุฏูุฉ
- ุทูุจุงุช ูุถุงุฏุฉ ููุงุณุจุฉ
- ุตูุบุฉ ุฑุณููุฉ ูุงุจูุฉ ููุชูุฏูู ูููุญููุฉ"""

    # Detect financial/business questions
    elif any(word in query for word in ["ุฌุฏูู", "ูุดุฑูุน", "ุงุณุชุซูุงุฑ", "ูุงููุฉ", "ุฑุจุญ", "ุฎุณุงุฑุฉ"]):
        enhanced_query = f"""ูุฏู ุชุญูููุงู ูุงููุงู ุดุงููุงู ููุชุฎุตุตุงู:

{query}

ูุทููุจ: ุฏุฑุงุณุฉ ูุงููุฉ ูุชูุงููุฉ ุชุดูู:
- ุชุญููู ุงูุชูุงููู ูุงูุฅูุฑุงุฏุงุช
- ุฏุฑุงุณุฉ ุงูุฌุฏูู ุงูุงูุชุตุงุฏูุฉ
- ุชูููู ุงููุฎุงุทุฑ ูุงููุฑุต
- ุชูุตูุงุช ุงุณุชุฑุงุชูุฌูุฉ ุนูููุฉ
- ุฎุทุฉ ุชูููุฐูุฉ ูุงุถุญุฉ"""

    # Detect administrative questions
    elif any(word in query for word in ["ุฅุฌุฑุงุกุงุช", "ุฑุฎุตุฉ", "ุชุตุฑูุญ", "ูุฒุงุฑุฉ", "ููุงููุฉ"]):
        enhanced_query = f"""ูุฏู ุฏูููุงู ุฅุฏุงุฑูุงู ุดุงููุงู:

{query}

ูุทููุจ: ุฏููู ุฅุฏุงุฑู ูุชูุงูู ูุดูู:
- ุฎุทูุงุช ุชูููุฐูุฉ ููุตูุฉ
- ุงููุณุชูุฏุงุช ุงููุทููุจุฉ
- ุงูุฌูุงุช ุงููุฎุชุตุฉ
- ุงูุฌุฏูู ุงูุฒููู
- ูุตุงุฆุญ ุนูููุฉ ูููุฏุฉ"""

    # Detect technical questions  
    elif any(word in query for word in ["ูุธุงู", "ุชูููุฉ", "ุจุฑูุฌุฉ", "ุดุจูุฉ", "ุฃูุงู"]):
        enhanced_query = f"""ูุฏู ุงุณุชุดุงุฑุฉ ุชูููุฉ ูุชุฎุตุตุฉ:

{query}

ูุทููุจ: ุญู ุชููู ุดุงูู ูุชุถูู:
- ุชุญููู ุงููุชุทูุจุงุช ุงูุชูููุฉ
- ุงูุญููู ุงููุชุงุญุฉ ูุงูููุชุฑุญุฉ
- ุฎุทุฉ ุงูุชูููุฐ ุงูุนูููุฉ
- ุฅุฌุฑุงุกุงุช ุงูุฃูุงู ูุงูุญูุงูุฉ
- ุฃูุถู ุงูููุงุฑุณุงุช"""

    else:
        # General legal/business consultation
        enhanced_query = f"""ูุฏู ุงุณุชุดุงุฑุฉ ุดุงููุฉ ููุชุฎุตุตุฉ:

{query}

ูุทููุจ: ุงุณุชุดุงุฑุฉ ูุชูุงููุฉ ุชุดูู ุงูุชุญููู ุงููุงูููู ูุงูุนููู ูุน ุชูุตูุงุช ูุงุถุญุฉ ููุงุจูุฉ ููุชุทุจูู."""

    try:
        response = deepseek.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": enhanced_query}],
            temperature=0.3,   # Balanced for speed and quality
            max_tokens=4000,   # Optimized for speed while maintaining quality
            timeout=90         # 90 second timeout to prevent hanging
        )

        answer_raw = response.choices[0].message.content
        print("โ ุงูุฑุฏ (ูุต ุฎุงู):", answer_raw[:200] + "...")

        # Convert Markdown to HTML for the frontend
        answer_html = markdown.markdown(answer_raw)
        return answer_html

    except Exception as e:
        print(f"โ ุฎุทุฃ ูู ุงูุงุณุชุนูุงู: {e}")
        return f"<p>ุนุฐุฑุงูุ ุญุฏุซ ุฎุทุฃ ุชููู ุฃุซูุงุก ูุนุงูุฌุฉ ุงูุณุคุงู. ูุฑุฌู ุงููุญุงููุฉ ูุฑุฉ ุฃุฎุฑู.</p><p>ุชูุงุตูู ุงูุฎุทุฃ: {str(e)}</p>"


def ask_question_with_context(query: str, conversation_history: List[Dict[str, str]]) -> str:
    """
    Optimized conversational consultation with context awareness.
    """
    print("๐ง USING OPTIMIZED CONSULTANT!")
    print(f"๐ค ุณุคุงู ุงููุณุชุฎุฏู ูุน ุงูุณูุงู: {query}")
    print(f"๐ ุนุฏุฏ ุงูุฑุณุงุฆู ุงูุณุงุจูุฉ: {len(conversation_history)}")

    # Build messages with conversation history
    messages = []
    
    # Add recent conversation history (limit to last 6 messages for speed)
    recent_history = conversation_history[-6:] if len(conversation_history) > 6 else conversation_history
    for msg in recent_history:
        messages.append({
            "role": msg["role"],
            "content": msg["content"]
        })
    
    # Smart enhancement based on question type
    if any(phrase in query for phrase in ["ุงูุฑุฏ ุงููุงูููู ุนูู ุฏุนูู", "ุฑุฏ ุนูู ุงูุฏุนูู"]):
        enhanced_query = f"""ุจูุงุกู ุนูู ุงูุณูุงู ุงูุณุงุจูุ ูู ุจุฅุนุฏุงุฏ ุฑุฏ ูุงูููู ูุชูุฏู:

{query}

ูุทููุจ: ุฑุฏ ูุงูููู ุดุงูู ูุฑุงุนู ุงูููุงูุดุงุช ุงูุณุงุจูุฉ ููุชุถูู ุงุณุชุฑุงุชูุฌูุฉ ุฏูุงุนูุฉ ูุชูุงููุฉ ูุฃุฏูุฉ ูููุฉ."""

    elif any(word in query for word in ["ุฌุฏูู", "ูุดุฑูุน", "ุงุณุชุซูุงุฑ", "ูุงููุฉ"]):
        enhanced_query = f"""ุจูุงุกู ุนูู ุงูุณูุงู ุงูุณุงุจูุ ูุฏู ุชุญูููุงู ูุงููุงู ูุชูุฏูุงู:

{query}

ูุทููุจ: ุชุญููู ูุงูู ุดุงูู ูุฑุงุนู ุงูููุงูุดุงุช ุงูุณุงุจูุฉ ูุน ุชูุตูุงุช ุงุณุชุฑุงุชูุฌูุฉ ุนูููุฉ."""

    else:
        enhanced_query = f"""ุจูุงุกู ุนูู ุงูุณูุงู ุงูุณุงุจูุ ูุฏู ุงุณุชุดุงุฑุฉ ุดุงููุฉ:

{query}

ูุทููุจ: ุงุณุชุดุงุฑุฉ ูุชูุงููุฉ ุชุฑุงุนู ุงูููุงูุดุงุช ุงูุณุงุจูุฉ ูุน ุชูุตูุงุช ุนูููุฉ ูุงุถุญุฉ."""

    # Add current enhanced question
    messages.append({
        "role": "user",
        "content": enhanced_query
    })

    try:
        response = deepseek.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.3,   # Balanced for speed and quality
            max_tokens=4000,   # Optimized for speed
            timeout=90         # 90 second timeout
        )

        answer_raw = response.choices[0].message.content
        print("โ ุงูุฑุฏ ูุน ุงูุณูุงู (ูุต ุฎุงู):", answer_raw[:200] + "...")

        # Convert Markdown to HTML for the frontend
        answer_html = markdown.markdown(answer_raw)
        return answer_html

    except Exception as e:
        print(f"โ ุฎุทุฃ ูู ุงูุงุณุชุนูุงู ูุน ุงูุณูุงู: {e}")
        return f"<p>ุนุฐุฑุงูุ ุญุฏุซ ุฎุทุฃ ุชููู ุฃุซูุงุก ูุนุงูุฌุฉ ุงูุณุคุงู. ูุฑุฌู ุงููุญุงููุฉ ูุฑุฉ ุฃุฎุฑู.</p><p>ุชูุงุตูู ุงูุฎุทุฃ: {str(e)}</p>"


def generate_conversation_title(first_message: str) -> str:
    """
    Fast conversation title generation.
    """
    try:
        prompt = f"ุงูุชุฑุญ ุนููุงูุงู ูุฎุชุตุฑุงู (ุฃูู ูู 40 ุญุฑู): {first_message[:100]}"

        response = deepseek.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            max_tokens=50,    # Very small for speed
            timeout=30        # Quick timeout for titles
        )

        title = response.choices[0].message.content.strip()
        title = title.strip('"').strip("'").strip()
        
        # Remove common prefixes
        prefixes = ["ุงูุนููุงู:", "ุงูููุชุฑุญ:", "ุงูุงุณุชุดุงุฑุฉ:"]
        for prefix in prefixes:
            if title.startswith(prefix):
                title = title[len(prefix):].strip()
        
        return title if len(title) <= 40 else title[:37] + "..."
        
    except Exception as e:
        print(f"โ ุฎุทุฃ ูู ุชูููุฏ ุงูุนููุงู: {e}")
        return first_message[:37] + "..." if len(first_message) > 40 else first_message