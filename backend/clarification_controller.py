"""
Fixed Clarification Controller - Production Ready
Resolves import issues and simplifies for real-world deployment
"""

from typing import Dict, List, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
import time
import json
import hashlib
import re
from datetime import datetime

class ClarificationTrigger(Enum):
    """Types of clarification triggers"""
    LOW_CONFIDENCE = "low_confidence"
    AMBIGUOUS_INTENT = "ambiguous_intent"
    MULTI_INTERPRETATION = "multi_interpretation"
    MISSING_CONTEXT = "missing_context"
    CONFLICTING_INDICATORS = "conflicting_indicators"
    LEGAL_COMPLEXITY = "legal_complexity"

class ClarificationStatus(Enum):
    """Status of clarification attempts"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    RESOLVED = "resolved"
    FAILED = "failed"
    EXCEEDED_LIMIT = "exceeded_limit"
    FALLBACK_APPLIED = "fallback_applied"

@dataclass
class ClarificationAttempt:
    """Single clarification attempt record"""
    attempt_number: int
    trigger: ClarificationTrigger
    question_generated: str
    timestamp: float
    user_response: Optional[str] = None
    resolution_success: bool = False
    confidence_improvement: float = 0.0
    processing_time_ms: int = 0

@dataclass
class ClarificationSession:
    """Complete clarification session tracking"""
    session_id: str
    original_query: str
    initial_confidence: float
    current_confidence: float
    attempts: List[ClarificationAttempt] = field(default_factory=list)
    status: ClarificationStatus = ClarificationStatus.PENDING
    max_attempts: int = 3
    confidence_threshold: float = 0.75
    fallback_reason: Optional[str] = None
    resolution_path: List[str] = field(default_factory=list)

class AdvancedClarificationController:
    """
    ðŸŽ¯ PRODUCTION-READY CLARIFICATION LOOP CONTROL
    
    Features:
    - Intelligent clarification question generation
    - Loop prevention with adaptive limits
    - Multi-layered fallback strategies
    - Context-aware question templates
    - Session management and analytics
    """
    
    def __init__(self, openai_client):
        self.client = openai_client
        self.active_sessions: Dict[str, ClarificationSession] = {}
        self.question_templates = self._initialize_question_templates()
        self.fallback_strategies = self._initialize_fallback_strategies()
        self.confidence_analyzers = self._initialize_confidence_analyzers()
    
    async def should_trigger_clarification(
        self,
        query: str,
        validation_result: Dict,
        conversation_context: Optional[List[Dict]] = None
    ) -> Tuple[bool, Optional[ClarificationTrigger], float]:
        """
        Intelligent decision on whether clarification is needed
        
        Returns:
            (should_clarify, trigger_reason, confidence_score)
        """
        
        confidence = validation_result.get('confidence', 0.8)
        intents = validation_result.get('recommended_intents', [])
        
        # Analyze multiple factors
        triggers = []
        
        # 1. Low confidence threshold
        if confidence < 0.6:
            triggers.append((ClarificationTrigger.LOW_CONFIDENCE, 1.0 - confidence))
        
        # 2. Multiple competing intents
        if len(intents) > 2:
            triggers.append((ClarificationTrigger.MULTI_INTERPRETATION, len(intents) * 0.2))
        
        # 3. Ambiguous language patterns
        ambiguity_score = await self._analyze_ambiguity(query)
        if ambiguity_score > 0.7:
            triggers.append((ClarificationTrigger.AMBIGUOUS_INTENT, ambiguity_score))
        
        # 4. Missing critical context
        context_completeness = self._analyze_context_completeness(query, conversation_context)
        if context_completeness < 0.5:
            triggers.append((ClarificationTrigger.MISSING_CONTEXT, 1.0 - context_completeness))
        
        # 5. Conflicting indicators
        conflict_score = self._detect_conflicting_indicators(query, validation_result)
        if conflict_score > 0.6:
            triggers.append((ClarificationTrigger.CONFLICTING_INDICATORS, conflict_score))
        
        # 6. Legal complexity requiring specificity
        complexity_score = self._assess_legal_complexity(query)
        if complexity_score > 0.8 and confidence < 0.8:
            triggers.append((ClarificationTrigger.LEGAL_COMPLEXITY, complexity_score))
        
        # Select highest-priority trigger
        if triggers:
            primary_trigger, trigger_strength = max(triggers, key=lambda x: x[1])
            return True, primary_trigger, confidence
        
        return False, None, confidence
    
    async def generate_clarification_question(
        self,
        query: str,
        trigger: ClarificationTrigger,
        validation_result: Dict,
        session: ClarificationSession
    ) -> str:
        """
        Generate intelligent clarification question based on trigger type
        """
        
        # Check if we have a template-based solution first
        template_question = self._try_template_based_question(trigger, validation_result, session)
        if template_question:
            return template_question
        
        # Generate AI-powered clarification question
        ai_question = await self._generate_ai_clarification(query, trigger, validation_result, session)
        
        # Validate and refine the generated question
        refined_question = self._refine_clarification_question(ai_question, session)
        
        return refined_question
    
    def create_clarification_session(
        self,
        query: str,
        initial_confidence: float,
        max_attempts: int = 3
    ) -> ClarificationSession:
        """Create new clarification session"""
        
        session_id = self._generate_session_id(query)
        
        session = ClarificationSession(
            session_id=session_id,
            original_query=query,
            initial_confidence=initial_confidence,
            current_confidence=initial_confidence,
            max_attempts=max_attempts,
            status=ClarificationStatus.PENDING
        )
        
        self.active_sessions[session_id] = session
        return session
    
    def process_clarification_response(
        self,
        session_id: str,
        user_response: str,
        new_validation_result: Dict
    ) -> Tuple[bool, float, str]:
        """
        Process user's clarification response
        
        Returns:
            (is_resolved, new_confidence, next_action)
        """
        
        if session_id not in self.active_sessions:
            return False, 0.0, "Session not found"
        
        session = self.active_sessions[session_id]
        
        # Update current attempt
        if session.attempts:
            current_attempt = session.attempts[-1]
            current_attempt.user_response = user_response
            current_attempt.processing_time_ms = int((time.time() - current_attempt.timestamp) * 1000)
        
        # Analyze improvement
        new_confidence = new_validation_result.get('confidence', 0.0)
        confidence_improvement = new_confidence - session.current_confidence
        
        # Update session
        session.current_confidence = new_confidence
        if session.attempts:
            session.attempts[-1].confidence_improvement = confidence_improvement
            session.attempts[-1].resolution_success = new_confidence >= session.confidence_threshold
        
        # Check resolution criteria
        if new_confidence >= session.confidence_threshold:
            session.status = ClarificationStatus.RESOLVED
            session.resolution_path.append("confidence_threshold_met")
            return True, new_confidence, "resolved"
        
        # Check if we should continue or fallback
        if len(session.attempts) >= session.max_attempts:
            session.status = ClarificationStatus.EXCEEDED_LIMIT
            fallback_response = self._apply_fallback_strategy(session)
            return False, new_confidence, fallback_response
        
        # Check for improvement stagnation
        if confidence_improvement < 0.05 and len(session.attempts) >= 2:
            session.status = ClarificationStatus.FALLBACK_APPLIED
            session.fallback_reason = "improvement_stagnation"
            fallback_response = self._apply_fallback_strategy(session)
            return False, new_confidence, fallback_response
        
        # Continue clarification
        return False, new_confidence, "continue"
    
    def _try_template_based_question(
        self,
        trigger: ClarificationTrigger,
        validation_result: Dict,
        session: ClarificationSession
    ) -> Optional[str]:
        """Try to use pre-defined templates for common scenarios"""
        
        intents = validation_result.get('recommended_intents', [])
        
        # Multi-intent templates
        if trigger == ClarificationTrigger.MULTI_INTERPRETATION:
            intent_combinations = frozenset(intents)
            
            if intent_combinations in self.question_templates['multi_intent']:
                template = self.question_templates['multi_intent'][intent_combinations]
                return template.format(
                    attempt_number=len(session.attempts) + 1,
                    original_query=session.original_query
                )
        
        # Low confidence templates
        if trigger == ClarificationTrigger.LOW_CONFIDENCE:
            confidence = validation_result.get('confidence', 0.0)
            
            if confidence < 0.3:
                return self.question_templates['low_confidence']['very_low']
            elif confidence < 0.5:
                return self.question_templates['low_confidence']['moderate']
        
        # Context-specific templates
        if trigger == ClarificationTrigger.MISSING_CONTEXT:
            primary_intent = intents[0] if intents else 'general'
            
            if primary_intent in self.question_templates['missing_context']:
                return self.question_templates['missing_context'][primary_intent]
        
        return None
    
    async def _generate_ai_clarification(
        self,
        query: str,
        trigger: ClarificationTrigger,
        validation_result: Dict,
        session: ClarificationSession
    ) -> str:
        """Generate AI-powered clarification question"""
        
        clarification_prompt = f"""Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„ØºØ§Ù…Ø¶Ø©.

**Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø§Ù„Ø£ØµÙ„ÙŠ:**
{query}

**Ø³Ø¨Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ù„ØªÙˆØ¶ÙŠØ­:**
{trigger.value}

**Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:**
Ø§Ù„Ø«Ù‚Ø©: {validation_result.get('confidence', 0.8):.1%}
Ø§Ù„Ù†ÙˆØ§ÙŠØ§ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©: {', '.join(validation_result.get('recommended_intents', []))}

**Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:**
{len(session.attempts)} Ù…Ø­Ø§ÙˆÙ„Ø©

**Ù…Ù‡Ù…ØªÙƒ:**
ØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ Ø°ÙƒÙŠ ÙˆÙ‚ØµÙŠØ± ÙŠØ³Ø§Ø¹Ø¯ ÙÙŠ Ø­Ù„ Ø§Ù„ØºÙ…ÙˆØ¶.

**Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø³Ø¤Ø§Ù„:**
- ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø¨Ø§Ø´Ø± (Ø£Ù‚Ù„ Ù…Ù† 30 ÙƒÙ„Ù…Ø©)
- ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ Ù†Ù‚Ø·Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ø­Ø¯Ø¯Ø©
- ÙŠØªØ·Ù„Ø¨ Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø³ÙŠØ·Ø© (Ù†Ø¹Ù…/Ù„Ø§ Ø£Ùˆ Ø§Ø®ØªÙŠØ§Ø±)
- Ù…ØµØ§Øº Ø¨Ù„ØºØ© Ù…ÙÙ‡ÙˆÙ…Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ø§Ø¯ÙŠ

**Ø£Ù…Ø«Ù„Ø© Ø¬ÙŠØ¯Ø©:**
- "Ù‡Ù„ ØªÙ‚ØµØ¯ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª Ø£Ù… ÙƒÙŠÙÙŠØ© ØªØµØ­ÙŠØ­ Ø§Ù„ÙˆØ¶Ø¹ØŸ"
- "Ù‡Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø­Ø¯Ø«Øª Ø¨Ø§Ù„ÙØ¹Ù„ Ø£Ù… ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© ÙƒÙŠÙÙŠØ© ØªØ¬Ù†Ø¨Ù‡Ø§ØŸ"
- "Ù‡Ù„ Ø£Ù†Øª Ù…ÙˆØ¸Ù Ø£Ù… ØµØ§Ø­Ø¨ Ø¹Ù…Ù„ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©ØŸ"

Ø£Ø¬Ø¨ Ø¨Ø³Ø¤Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·:"""

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",  # Fast, cheap for clarification
                messages=[{"role": "user", "content": clarification_prompt}],
                temperature=0.3,
                max_tokens=150
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"âš ï¸ AI clarification generation failed: {e}")
            return self._get_generic_clarification_fallback(trigger)
    
    def _refine_clarification_question(self, question: str, session: ClarificationSession) -> str:
        """Refine and validate the generated clarification question"""
        
        # Remove common AI artifacts
        question = question.replace("Ø³Ø¤Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ:", "").strip()
        question = question.replace("Ø§Ù„Ø³Ø¤Ø§Ù„:", "").strip()
        
        # Ensure question mark
        if not question.endswith('ØŸ'):
            question += 'ØŸ'
        
        # Add context indicator
        attempt_number = len(session.attempts) + 1
        if attempt_number > 1:
            prefix = f"Ù„Ù„ØªÙˆØ¶ÙŠØ­ Ø£ÙƒØ«Ø± ({attempt_number}/{session.max_attempts}): "
            question = prefix + question
        
        return question
    
    def _apply_fallback_strategy(self, session: ClarificationSession) -> str:
        """Apply appropriate fallback strategy when clarification fails"""
        
        fallback_type = self._determine_fallback_type(session)
        
        if fallback_type == "best_guess_with_disclaimer":
            return self.fallback_strategies['best_guess'].format(
                confidence=int(session.current_confidence * 100),
                original_query=session.original_query
            )
        
        elif fallback_type == "multiple_scenarios":
            return self.fallback_strategies['multiple_scenarios'].format(
                original_query=session.original_query
            )
        
        elif fallback_type == "expert_referral":
            return self.fallback_strategies['expert_referral']
        
        else:
            return self.fallback_strategies['generic_fallback']
    
    def _determine_fallback_type(self, session: ClarificationSession) -> str:
        """Determine appropriate fallback strategy"""
        
        # High confidence but exceeded attempts - use best guess
        if session.current_confidence > 0.6:
            return "best_guess_with_disclaimer"
        
        # Multiple clear intents but low confidence - show scenarios
        if len(session.resolution_path) > 0 and session.current_confidence > 0.4:
            return "multiple_scenarios"
        
        # Very low confidence or legal complexity - refer to expert
        if session.current_confidence < 0.3 or ClarificationTrigger.LEGAL_COMPLEXITY in [a.trigger for a in session.attempts]:
            return "expert_referral"
        
        return "generic_fallback"
    
    def _initialize_question_templates(self) -> Dict:
        """Initialize pre-approved clarification question templates"""
        return {
            'multi_intent': {
                frozenset(['penalty_explanation', 'procedure_guide']): 
                    "Ù‡Ù„ ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª ÙÙ‚Ø·ØŒ Ø£Ù… ØªØ­ØªØ§Ø¬ Ø£ÙŠØ¶Ø§Ù‹ Ù„Ø®Ø·ÙˆØ§Øª ØªØµØ­ÙŠØ­ Ø§Ù„ÙˆØ¶Ø¹ØŸ",
                
                frozenset(['rights_inquiry', 'legal_dispute']): 
                    "Ù‡Ù„ ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ø­Ù‚ÙˆÙ‚Ùƒ Ø§Ù„Ø¹Ø§Ù…Ø©ØŒ Ø£Ù… Ù„Ø¯ÙŠÙƒ Ù†Ø²Ø§Ø¹ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…Ø­Ø¯Ø¯ ØªØ­ØªØ§Ø¬ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠÙ‡ØŸ",
                
                frozenset(['procedure_guide', 'legal_dispute']): 
                    "Ù‡Ù„ ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ù„Ù„ÙˆÙ‚Ø§ÙŠØ©ØŒ Ø£Ù… Ù„Ø¯ÙŠÙƒ Ù…Ø´ÙƒÙ„Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø­Ø§Ù„ÙŠØ© ØªØ­ØªØ§Ø¬ Ø­Ù„Ù‡Ø§ØŸ",
                
                frozenset(['penalty_explanation', 'rights_inquiry', 'procedure_guide']): 
                    "Ø³Ø¤Ø§Ù„Ùƒ ÙŠØºØ·ÙŠ Ø¹Ø¯Ø© Ø¬ÙˆØ§Ù†Ø¨. Ù…Ø§ Ø§Ù„Ø£Ù‡Ù… Ù„Ùƒ Ø§Ù„Ø¢Ù†: Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§ØªØŒ Ø£Ù… Ø­Ù‚ÙˆÙ‚ÙƒØŒ Ø£Ù… Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©ØŸ"
            },
            
            'low_confidence': {
                'very_low': "ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ø³Ø¤Ø§Ù„Ùƒ ÙŠØ­ØªØ§Ø¬ ØªÙˆØ¶ÙŠØ­ Ø£ÙƒØ«Ø±. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØªÙ‡ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø®Ø±Ù‰ØŸ",
                'moderate': "Ù„ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ØŒ Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŸ"
            },
            
            'missing_context': {
                'penalty_explanation': "Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª Ø¨Ø¯Ù‚Ø©ØŒ Ù‡Ù„ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ© Ø­Ø¯Ø«Øª Ø¨Ø§Ù„ÙØ¹Ù„ Ø£Ù… ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©ØŸ",
                'legal_dispute': "Ù„ÙÙ‡Ù… ÙˆØ¶Ø¹Ùƒ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØŒ Ù‡Ù„ Ø£Ù†Øª Ø§Ù„Ù…Ø¯Ø¹ÙŠ Ø£Ù… Ø§Ù„Ù…Ø¯Ø¹Ù‰ Ø¹Ù„ÙŠÙ‡ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù†Ø²Ø§Ø¹ØŸ",
                'rights_inquiry': "Ù„ØªÙˆØ¶ÙŠØ­ Ø­Ù‚ÙˆÙ‚ÙƒØŒ Ù‡Ù„ Ø£Ù†Øª Ù…ÙˆØ¸ÙØŒ Ø¹Ù…ÙŠÙ„ØŒ Ø£Ù… Ø·Ø±Ù Ø¢Ø®Ø± ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©ØŸ",
                'procedure_guide': "Ù„ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©ØŒ ÙÙŠ Ø£ÙŠ Ù…Ø±Ø­Ù„Ø© Ø£Ù†Øª Ø§Ù„Ø¢Ù† Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©ØŸ"
            },
            
            'conflicting_indicators': {
                'business_personal': "Ù‡Ù„ ØªØ³Ø£Ù„ Ø¹Ù† ÙˆØ¶Ø¹Ùƒ ÙƒÙØ±Ø¯ Ø£Ù… ÙƒØµØ§Ø­Ø¨ Ø¹Ù…Ù„/Ø´Ø±ÙƒØ©ØŸ",
                'past_future': "Ù‡Ù„ ØªØ³Ø£Ù„ Ø¹Ù† Ø­Ø§Ù„Ø© Ø­Ø¯Ø«Øª Ø¨Ø§Ù„ÙØ¹Ù„ Ø£Ù… ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ù…Ø§ ÙŠØ¬Ø¨ ÙØ¹Ù„Ù‡ Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹ØŸ",
                'self_other': "Ù‡Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† ÙˆØ¶Ø¹Ùƒ Ø§Ù„Ø´Ø®ØµÙŠ Ø£Ù… Ø¹Ù† Ø´Ø®Øµ Ø¢Ø®Ø±ØŸ"
            }
        }
    
    def _initialize_fallback_strategies(self) -> Dict:
        """Initialize fallback response templates"""
        return {
            'best_guess': """âš ï¸ **ØªÙ†Ø¨ÙŠÙ‡:** Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø¯Ù‚Ø© 100% Ø¨Ø¹Ø¯ Ø¹Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø§Øª ØªÙˆØ¶ÙŠØ­.

Ø³Ù†Ù‚Ø¯Ù… Ø£ÙØ¶Ù„ ØªÙ‚Ø¯ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù„Ø³Ø¤Ø§Ù„Ùƒ (Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©: {confidence}%) Ù…Ø¹ Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ø¹Ù„Ù‰ Ø¶Ø±ÙˆØ±Ø© Ù…Ø±Ø§Ø¬Ø¹Ø© Ù…Ø­Ø§Ù…Ù Ù…Ø®ØªØµ Ù„Ù„ØªØ£ÙƒØ¯.

**Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ:** {original_query}

**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ù‚Ø¯Ø±Ø©:**""",
            
            'multiple_scenarios': """ðŸ”€ **Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©:** Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ø¯ÙŠØ¯ Ù‚ØµØ¯Ùƒ Ø¨Ø¯Ù‚Ø©ØŒ Ù„Ø°Ø§ Ø³Ù†Ø¹Ø±Ø¶ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± ØªØ±Ø¬ÙŠØ­Ø§Ù‹:

**Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ø£ÙˆÙ„:** Ø¥Ø°Ø§ ÙƒÙ†Øª ØªÙ‚ØµØ¯...
**Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ø«Ø§Ù†ÙŠ:** Ø¥Ø°Ø§ ÙƒÙ†Øª ØªÙ‚ØµØ¯...
**Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ø«Ø§Ù„Ø«:** Ø¥Ø°Ø§ ÙƒÙ†Øª ØªÙ‚ØµØ¯...

ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ø£Ù‚Ø±Ø¨ Ù„Ø­Ø§Ù„ØªÙƒ Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„.""",
            
            'expert_referral': """ðŸ‘¨â€âš–ï¸ **ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ù…ØªØ®ØµØµØ©**

Ø³Ø¤Ø§Ù„Ùƒ ÙŠØªØ¶Ù…Ù† ØªØ¹Ù‚ÙŠØ¯Ø§Øª Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ØªØªØ·Ù„Ø¨ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…ØªØ®ØµØµØ§Ù‹ Ù…Ù† Ù…Ø­Ø§Ù…Ù Ù…Ø¤Ù‡Ù„.

**Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø¯Ù‚ÙŠÙ‚Ø©:**
â€¢ ðŸ“ž Ø§Ù„Ø®Ø· Ø§Ù„Ø³Ø§Ø®Ù† Ù„Ù„Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©: 19993
â€¢ ðŸ’» Ù…Ù†ØµØ© "Ø§Ø³ØªØ´Ø§Ø±Ø§Øª": consult.sa
â€¢ ðŸ›ï¸ Ù†Ù‚Ø§Ø¨Ø© Ø§Ù„Ù…Ø­Ø§Ù…ÙŠÙ† Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠÙŠÙ†: saudibar.org

**ÙŠÙ…ÙƒÙ†Ù†Ø§ ØªÙ‚Ø¯ÙŠÙ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¹Ø§Ù…Ø©ØŒ Ù„ÙƒÙ† Ø­Ø§Ù„ØªÙƒ ØªØ­ØªØ§Ø¬ Ø±Ø£ÙŠ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ.**""",
            
            'generic_fallback': """â“ **ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„ÙÙ‡Ù…**

Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­ Ø¨Ø¹Ø¯ Ø¹Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø§Øª.

**ÙŠÙØ±Ø¬Ù‰:**
â€¢ Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø¨Ø³Ø·
â€¢ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø£ØµØºØ±
â€¢ Ø¥Ø¶Ø§ÙØ© ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø± Ø¹Ù† Ø§Ù„Ø­Ø§Ù„Ø©

**Ø£Ùˆ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹:**
ðŸ“ž Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡: 19993"""
        }
    
    def _initialize_confidence_analyzers(self) -> Dict:
        """Initialize confidence analysis tools"""
        return {
            'ambiguity_patterns': [
                r'\b(Ø±Ø¨Ù…Ø§|ÙŠÙ…ÙƒÙ†|Ù‚Ø¯|Ù…Ø­ØªÙ…Ù„|ØºØ§Ù„Ø¨)\b',
                r'\b(Ø£Ùˆ|Ø¥Ù…Ø§|Ø³ÙˆØ§Ø¡)\b.*\b(Ø£Ùˆ|Ø¥Ù…Ø§|Ø³ÙˆØ§Ø¡)\b',
                r'\?.*\?',  # Multiple question marks
                r'\b(Ù…Ø´ Ù…ØªØ£ÙƒØ¯|ØºÙŠØ± ÙˆØ§Ø¶Ø­|Ù„Ø§ Ø£Ø¹Ø±Ù)\b'
            ],
            
            'context_indicators': {
                'timeline_markers': [r'\b(Ø£Ù…Ø³|Ø§Ù„ÙŠÙˆÙ…|ØºØ¯Ø§Ù‹|Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹|Ø§Ù„Ø´Ù‡Ø±)\b'],
                'role_markers': [r'\b(Ù…ÙˆØ¸Ù|Ù…Ø¯ÙŠØ±|Ø¹Ù…ÙŠÙ„|Ø²Ø¨ÙˆÙ†|Ù…Ø³ØªÙ‡Ù„Ùƒ)\b'],
                'location_markers': [r'\b(ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶|Ø¨Ø¬Ø¯Ø©|ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ©)\b'],
                'amount_markers': [r'\d+\s*(Ø±ÙŠØ§Ù„|Ø¯Ø±Ù‡Ù…|Ø¯ÙˆÙ„Ø§Ø±)']
            },
            
            'conflict_patterns': [
                ('business_personal', [r'\b(Ø´Ø±ÙƒØ©|Ù…Ø¤Ø³Ø³Ø©)\b', r'\b(Ø´Ø®ØµÙŠ|ÙØ±Ø¯ÙŠ)\b']),
                ('past_future', [r'\b(Ø­Ø¯Ø«|Ø­ØµÙ„|ØªÙ…)\b', r'\b(Ø³Ø£|Ø³ÙˆÙ|Ù…Ø³ØªÙ‚Ø¨Ù„)\b']),
                ('self_other', [r'\b(Ø£Ù†Ø§|Ù„ÙŠ|Ø¹Ù†Ø¯ÙŠ)\b', r'\b(Ù„Ù‡|Ù„Ù‡Ø§|Ø¹Ù†Ø¯Ù‡Ù…)\b'])
            ]
        }
    
    # Analysis helper methods
    async def _analyze_ambiguity(self, query: str) -> float:
        """Analyze linguistic ambiguity in the query"""
        ambiguity_score = 0.0
        
        for pattern in self.confidence_analyzers['ambiguity_patterns']:
            matches = len(re.findall(pattern, query, re.IGNORECASE))
            ambiguity_score += matches * 0.2
        
        # Check for vague terms
        vague_terms = ['Ø´ÙŠØ¡', 'Ø­Ø§Ø¬Ø©', 'Ù…ÙˆØ¶ÙˆØ¹', 'Ù‚Ø¶ÙŠØ©', 'Ù…Ø³Ø£Ù„Ø©']
        vague_count = sum(1 for term in vague_terms if term in query)
        ambiguity_score += vague_count * 0.15
        
        return min(ambiguity_score, 1.0)
    
    def _analyze_context_completeness(self, query: str, context: Optional[List[Dict]]) -> float:
        """Analyze how complete the context information is"""
        completeness_score = 0.0
        
        # Check for context indicators in query
        for category, patterns in self.confidence_analyzers['context_indicators'].items():
            for pattern in patterns:
                if re.search(pattern, query, re.IGNORECASE):
                    completeness_score += 0.2
        
        # Bonus for conversation context
        if context and len(context) > 0:
            completeness_score += 0.3
        
        # Check query length (very short queries often lack context)
        if len(query.split()) > 10:
            completeness_score += 0.2
        
        return min(completeness_score, 1.0)
    
    def _detect_conflicting_indicators(self, query: str, validation_result: Dict) -> float:
        """Detect conflicting indicators in the query"""
        conflict_score = 0.0
        
        for conflict_type, (pattern1, pattern2) in self.confidence_analyzers['conflict_patterns']:
            has_pattern1 = any(re.search(p, query, re.IGNORECASE) for p in pattern1)
            has_pattern2 = any(re.search(p, query, re.IGNORECASE) for p in pattern2)
            
            if has_pattern1 and has_pattern2:
                conflict_score += 0.3
        
        # Check for conflicting intents
        intents = validation_result.get('recommended_intents', [])
        if len(intents) > 2:
            conflict_score += 0.4
        
        return min(conflict_score, 1.0)
    
    def _assess_legal_complexity(self, query: str) -> float:
        """Assess legal complexity requiring clarification"""
        complexity_indicators = [
            'ØªØ­ÙƒÙŠÙ…', 'Ø§Ø³ØªØ¦Ù†Ø§Ù', 'ØªÙ…ÙŠÙŠØ²', 'Ø¯Ø³ØªÙˆØ±ÙŠ', 'Ø¥Ø¯Ø§Ø±ÙŠ',
            'ØªØ¬Ø§Ø±ÙŠ Ù…ØªÙ‚Ø¯Ù…', 'Ø´Ø±ÙƒØ§Øª Ù…Ø³Ø§Ù‡Ù…Ø©', 'Ø§Ù†Ø¯Ù…Ø§Ø¬', 'Ø§Ø³ØªØ­ÙˆØ§Ø°',
            'Ù…Ù„ÙƒÙŠØ© ÙÙƒØ±ÙŠØ©', 'Ø¨Ø±Ø§Ø¡Ø© Ø§Ø®ØªØ±Ø§Ø¹', 'Ø­Ù‚ÙˆÙ‚ Ù…Ø¤Ù„Ù'
        ]
        
        complexity_score = 0.0
        for indicator in complexity_indicators:
            if indicator in query:
                complexity_score += 0.3
        
        return min(complexity_score, 1.0)
    
    def _generate_session_id(self, query: str) -> str:
        """Generate unique session ID"""
        timestamp = str(int(time.time() * 1000))
        query_hash = hashlib.md5(query.encode('utf-8')).hexdigest()[:8]
        return f"clarify_{timestamp}_{query_hash}"
    
    def _get_generic_clarification_fallback(self, trigger: ClarificationTrigger) -> str:
        """Get generic clarification question as last resort"""
        fallbacks = {
            ClarificationTrigger.LOW_CONFIDENCE: "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙˆØ¶ÙŠØ­ Ø³Ø¤Ø§Ù„Ùƒ Ø£ÙƒØ«Ø±ØŸ",
            ClarificationTrigger.AMBIGUOUS_INTENT: "Ù…Ø§ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù…Ù† Ø³Ø¤Ø§Ù„ÙƒØŸ",
            ClarificationTrigger.MULTI_INTERPRETATION: "Ø£ÙŠ Ø¬Ø§Ù†Ø¨ ØªØ±ÙŠØ¯ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„ÙŠÙ‡ Ø£ÙƒØ«Ø±ØŸ",
            ClarificationTrigger.MISSING_CONTEXT: "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŸ",
            ClarificationTrigger.CONFLICTING_INDICATORS: "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ø­Ø§Ù„Ø© Ø¨Ø¯Ù‚Ø© Ø£ÙƒØ«Ø±ØŸ",
            ClarificationTrigger.LEGAL_COMPLEXITY: "Ù‡Ù„ ØªØ­ØªØ§Ø¬ Ø´Ø±Ø­ Ù…Ø¨Ø³Ø· Ø£Ù… ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªÙ‚Ø¯Ù…ØŸ"
        }
        
        return fallbacks.get(trigger, "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„ÙƒØŸ")
    
    # Session management methods
    def get_session_analytics(self, session_id: str) -> Dict:
        """Get analytics for a clarification session"""
        if session_id not in self.active_sessions:
            return {}
        
        session = self.active_sessions[session_id]
        
        return {
            'session_id': session_id,
            'total_attempts': len(session.attempts),
            'confidence_improvement': session.current_confidence - session.initial_confidence,
            'status': session.status.value,
            'resolution_time_ms': sum(a.processing_time_ms for a in session.attempts),
            'triggers_used': [a.trigger.value for a in session.attempts],
            'final_confidence': session.current_confidence,
            'success_rate': len([a for a in session.attempts if a.resolution_success]) / max(len(session.attempts), 1)
        }
    
    def cleanup_completed_sessions(self, max_age_hours: int = 24):
        """Clean up old completed sessions"""
        current_time = time.time()
        max_age_seconds = max_age_hours * 3600
        
        sessions_to_remove = []
        for session_id, session in self.active_sessions.items():
            if session.status in [ClarificationStatus.RESOLVED, ClarificationStatus.FAILED, ClarificationStatus.EXCEEDED_LIMIT]:
                latest_attempt_time = max([a.timestamp for a in session.attempts]) if session.attempts else 0
                if current_time - latest_attempt_time > max_age_seconds:
                    sessions_to_remove.append(session_id)
        
        for session_id in sessions_to_remove:
            del self.active_sessions[session_id]
        
        return len(sessions_to_remove)